{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-02T15:24:19.956512Z",
     "iopub.status.busy": "2025-06-02T15:24:19.956134Z",
     "iopub.status.idle": "2025-06-02T15:24:39.039462Z",
     "shell.execute_reply": "2025-06-02T15:24:39.038608Z",
     "shell.execute_reply.started": "2025-06-02T15:24:19.956483Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=485f1f8d7c354640c82d5917f350c74e3ebc5bae5900fb9a3055ec269b1be44c\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate peft datasets bitsandbytes evaluate -q\n",
    "!pip install rouge_score\n",
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import library and load module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:24:39.041367Z",
     "iopub.status.busy": "2025-06-02T15:24:39.041001Z",
     "iopub.status.idle": "2025-06-02T15:25:02.303215Z",
     "shell.execute_reply": "2025-06-02T15:25:02.302567Z",
     "shell.execute_reply.started": "2025-06-02T15:24:39.041341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    default_data_collator,\n",
    ")\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from peft import PeftModel, PeftConfig\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:02.305103Z",
     "iopub.status.busy": "2025-06-02T15:25:02.304534Z",
     "iopub.status.idle": "2025-06-02T15:25:02.508793Z",
     "shell.execute_reply": "2025-06-02T15:25:02.508132Z",
     "shell.execute_reply.started": "2025-06-02T15:25:02.305080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T13:34:30.489251Z",
     "iopub.status.busy": "2025-06-02T13:34:30.488862Z",
     "iopub.status.idle": "2025-06-02T13:34:30.493421Z",
     "shell.execute_reply": "2025-06-02T13:34:30.492494Z",
     "shell.execute_reply.started": "2025-06-02T13:34:30.489213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T09:06:36.200794Z",
     "iopub.status.busy": "2025-06-01T09:06:36.200407Z",
     "iopub.status.idle": "2025-06-01T09:06:36.222266Z",
     "shell.execute_reply": "2025-06-01T09:06:36.221029Z",
     "shell.execute_reply.started": "2025-06-01T09:06:36.200757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:47:39.765551Z",
     "iopub.status.busy": "2025-05-31T04:47:39.765259Z",
     "iopub.status.idle": "2025-05-31T04:47:39.782880Z",
     "shell.execute_reply": "2025-05-31T04:47:39.782263Z",
     "shell.execute_reply.started": "2025-05-31T04:47:39.765523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"/kaggle/input/llama-continued-pretrain-model/transformers/default/1/llama-continued-pretrain-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:31:22.370981Z",
     "iopub.status.busy": "2025-05-31T13:31:22.370704Z",
     "iopub.status.idle": "2025-05-31T13:31:22.382557Z",
     "shell.execute_reply": "2025-05-31T13:31:22.381889Z",
     "shell.execute_reply.started": "2025-05-31T13:31:22.370962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"/kaggle/input/llama3.2-qa-model/transformers/default/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T01:59:29.170333Z",
     "iopub.status.busy": "2025-06-02T01:59:29.170018Z",
     "iopub.status.idle": "2025-06-02T01:59:29.180598Z",
     "shell.execute_reply": "2025-06-02T01:59:29.179841Z",
     "shell.execute_reply.started": "2025-06-02T01:59:29.170306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"/kaggle/input/llama-finetune-all/transformers/default/1/llama_finetune_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:02.510402Z",
     "iopub.status.busy": "2025-06-02T15:25:02.510152Z",
     "iopub.status.idle": "2025-06-02T15:25:02.965236Z",
     "shell.execute_reply": "2025-06-02T15:25:02.964309Z",
     "shell.execute_reply.started": "2025-06-02T15:25:02.510383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"/kaggle/input/llama-vnd-finetuned-model-epoch-2/transformers/default/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:02.966401Z",
     "iopub.status.busy": "2025-06-02T15:25:02.966154Z",
     "iopub.status.idle": "2025-06-02T15:25:18.138841Z",
     "shell.execute_reply": "2025-06-02T15:25:18.137941Z",
     "shell.execute_reply.started": "2025-06-02T15:25:02.966380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccedc548956841688a6286519ab53f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ffd78202144c549920b3bebf1b7405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c933e6f11f46fabd8ca46eb256eebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# Thiết lập pad_token và padding side\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:18.140153Z",
     "iopub.status.busy": "2025-06-02T15:25:18.139840Z",
     "iopub.status.idle": "2025-06-02T15:25:18.145692Z",
     "shell.execute_reply": "2025-06-02T15:25:18.145047Z",
     "shell.execute_reply.started": "2025-06-02T15:25:18.140129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_masks = [item[\"attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:18.146804Z",
     "iopub.status.busy": "2025-06-02T15:25:18.146507Z",
     "iopub.status.idle": "2025-06-02T15:25:19.432542Z",
     "shell.execute_reply": "2025-06-02T15:25:19.431408Z",
     "shell.execute_reply.started": "2025-06-02T15:25:18.146776Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Continue Pretrain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"vukhai248/vietnamese_news_16k\", split=\"train\")\n",
    "dataset = dataset.select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T03:02:54.891173Z",
     "iopub.status.busy": "2025-05-25T03:02:54.890933Z",
     "iopub.status.idle": "2025-05-25T03:02:54.894619Z",
     "shell.execute_reply": "2025-05-25T03:02:54.893717Z",
     "shell.execute_reply.started": "2025-05-25T03:02:54.891150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return text.replace(\"\\n\", \" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T03:02:54.895648Z",
     "iopub.status.busy": "2025-05-25T03:02:54.895450Z",
     "iopub.status.idle": "2025-05-25T03:03:04.441895Z",
     "shell.execute_reply": "2025-05-25T03:03:04.440976Z",
     "shell.execute_reply.started": "2025-05-25T03:02:54.895632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(text, max_length=2048):\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=False,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "    attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "    labels = input_ids.clone()\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T03:03:04.443066Z",
     "iopub.status.busy": "2025-05-25T03:03:04.442775Z",
     "iopub.status.idle": "2025-05-25T03:03:10.608088Z",
     "shell.execute_reply": "2025-05-25T03:03:10.607451Z",
     "shell.execute_reply.started": "2025-05-25T03:03:04.443043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "texts = dataset[\"content\"]\n",
    "tokenized_data = [tokenize_fn(text) for text in texts]\n",
    "train_loader = DataLoader(\n",
    "    tokenized_data,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T03:03:10.609190Z",
     "iopub.status.busy": "2025-05-25T03:03:10.608887Z",
     "iopub.status.idle": "2025-05-25T10:51:54.609669Z",
     "shell.execute_reply": "2025-05-25T10:51:54.608737Z",
     "shell.execute_reply.started": "2025-05-25T03:03:10.609162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, device, n_epochs=3, lr=1e-5):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\", leave=True)\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # Forward pass with checkpointing\n",
    "            def forward_with_checkpoint(*args, **kwargs):\n",
    "                return torch.utils.checkpoint.checkpoint(\n",
    "                    lambda *args, **kwargs: model(*args, **kwargs),\n",
    "                    *args,\n",
    "                    **kwargs,\n",
    "                    use_reentrant=False\n",
    "                )\n",
    "\n",
    "            outputs = forward_with_checkpoint(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {avg_loss:.4f}\")\n",
    "train(model, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T10:51:54.611200Z",
     "iopub.status.busy": "2025-05-25T10:51:54.610857Z",
     "iopub.status.idle": "2025-05-25T10:51:55.038424Z",
     "shell.execute_reply": "2025-05-25T10:51:55.037648Z",
     "shell.execute_reply.started": "2025-05-25T10:51:54.611169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/kaggle/working/llama3-qlora-continued-pretrain\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"✅ Pretrained model saved at:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T10:51:55.039477Z",
     "iopub.status.busy": "2025-05-25T10:51:55.039197Z",
     "iopub.status.idle": "2025-05-25T10:51:55.626208Z",
     "shell.execute_reply": "2025-05-25T10:51:55.625554Z",
     "shell.execute_reply.started": "2025-05-25T10:51:55.039447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Đường dẫn tới thư mục chứa mô hình\n",
    "model_dir = '/kaggle/working/llama3-qlora-continued-pretrain'\n",
    "\n",
    "# Tạo file nén .zip từ thư mục\n",
    "zip_name = 'llama3-qlora-continued-pretrain'  # Tên file nén (không cần đuôi .zip)\n",
    "shutil.make_archive(zip_name, 'zip', model_dir)\n",
    "\n",
    "# Tạo liên kết tải xuống cho file .zip\n",
    "display(FileLink(f'{zip_name}.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finetune with QA dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T10:51:55.627282Z",
     "iopub.status.busy": "2025-05-25T10:51:55.626977Z",
     "iopub.status.idle": "2025-05-25T10:51:55.630429Z",
     "shell.execute_reply": "2025-05-25T10:51:55.629811Z",
     "shell.execute_reply.started": "2025-05-25T10:51:55.627251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model_id = \"/kaggle/input/llama-qa-partially-finetune/transformers/default/1/llama-qa-finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:47:59.291864Z",
     "iopub.status.busy": "2025-05-31T04:47:59.291537Z",
     "iopub.status.idle": "2025-05-31T04:48:03.535775Z",
     "shell.execute_reply": "2025-05-31T04:48:03.534479Z",
     "shell.execute_reply.started": "2025-05-31T04:47:59.291835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/vietnamese-squad/train-v2.0-translated.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vi_squad_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:48:03.537072Z",
     "iopub.status.busy": "2025-05-31T04:48:03.536759Z",
     "iopub.status.idle": "2025-05-31T04:48:03.544935Z",
     "shell.execute_reply": "2025-05-31T04:48:03.542417Z",
     "shell.execute_reply.started": "2025-05-31T04:48:03.537042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = vi_squad_data[:10000]\n",
    "\n",
    "# Lấy 2k mẫu tiếp theo cho validation\n",
    "val_data = vi_squad_data[10000:12000]\n",
    "\n",
    "print(f\"📦 Train samples: {len(train_data)}\")\n",
    "print(f\"📦 Validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:48:03.546266Z",
     "iopub.status.busy": "2025-05-31T04:48:03.545857Z",
     "iopub.status.idle": "2025-05-31T04:48:06.930020Z",
     "shell.execute_reply": "2025-05-31T04:48:06.929222Z",
     "shell.execute_reply.started": "2025-05-31T04:48:03.546242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"📦 Train samples: {train_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:48:06.931157Z",
     "iopub.status.busy": "2025-05-31T04:48:06.930840Z",
     "iopub.status.idle": "2025-05-31T04:48:07.134045Z",
     "shell.execute_reply": "2025-05-31T04:48:07.133405Z",
     "shell.execute_reply.started": "2025-05-31T04:48:06.931132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_list([{\"context\": item[0], \"question\": item[1], \"answer\": item[2]} for item in train_data])\n",
    "val_dataset = Dataset.from_list([{\"context\": item[0], \"question\": item[1], \"answer\": item[2]} for item in val_data])\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:48:07.134968Z",
     "iopub.status.busy": "2025-05-31T04:48:07.134755Z",
     "iopub.status.idle": "2025-05-31T04:48:07.145990Z",
     "shell.execute_reply": "2025-05-31T04:48:07.145368Z",
     "shell.execute_reply.started": "2025-05-31T04:48:07.134950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"1. {dataset_dict['train'][0]}\")\n",
    "print(f\"2. {dataset_dict['train'][0]['context']}\")\n",
    "print(f\"3. {dataset_dict['train'][0]['question']}\")\n",
    "print(f\"4. {dataset_dict['train'][0]['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:48:07.147238Z",
     "iopub.status.busy": "2025-05-31T04:48:07.146924Z",
     "iopub.status.idle": "2025-05-31T04:48:24.323118Z",
     "shell.execute_reply": "2025-05-31T04:48:24.322086Z",
     "shell.execute_reply.started": "2025-05-31T04:48:07.147208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_qa(example, max_length=512):\n",
    "    context = example[\"context\"]\n",
    "    question = example[\"question\"]\n",
    "    answer = example[\"answer\"]\n",
    "    prompt = f\"### Đây là dạng câu hỏi và trả lời dựa trên nội dung ###\\n\\nCâu hỏi: {question}\\n\\nNội dung: {context}\\n\\nTrả lời:\"\n",
    "    completion = f\" {answer}\"\n",
    "    \n",
    "    prompt_ids = tokenizer(prompt, add_special_tokens=False).input_ids\n",
    "    completion_ids = tokenizer(completion, add_special_tokens=False).input_ids\n",
    "\n",
    "    input_ids = prompt_ids + completion_ids\n",
    "\n",
    "    labels = [-100] * len(prompt_ids) + completion_ids\n",
    "\n",
    "    if len(input_ids) > max_length:\n",
    "        input_ids = input_ids[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    padding_length = max_length - len(input_ids)\n",
    "    \n",
    "    input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "    attention_mask = attention_mask + [0] * padding_length\n",
    "    labels = labels + [-100] * padding_length\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"attention_mask\": torch.tensor(attention_mask),\n",
    "        \"labels\": torch.tensor(labels)\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset_dict.map(preprocess_qa)\n",
    "\n",
    "tokenized_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:48:24.324181Z",
     "iopub.status.busy": "2025-05-31T04:48:24.323947Z",
     "iopub.status.idle": "2025-05-31T04:48:24.328237Z",
     "shell.execute_reply": "2025-05-31T04:48:24.327567Z",
     "shell.execute_reply.started": "2025-05-31T04:48:24.324161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"], batch_size=4, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], batch_size=4, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T04:48:24.329401Z",
     "iopub.status.busy": "2025-05-31T04:48:24.329069Z",
     "iopub.status.idle": "2025-05-31T11:22:10.859713Z",
     "shell.execute_reply": "2025-05-31T11:22:10.858838Z",
     "shell.execute_reply.started": "2025-05-31T04:48:24.329371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "n_epochs = 2\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\", leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"✅ Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"📊 Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T11:22:10.860777Z",
     "iopub.status.busy": "2025-05-31T11:22:10.860551Z",
     "iopub.status.idle": "2025-05-31T11:22:11.355922Z",
     "shell.execute_reply": "2025-05-31T11:22:11.355189Z",
     "shell.execute_reply.started": "2025-05-31T11:22:10.860748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/kaggle/working/llama3-qlora-qa-finetune\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"✅ Pretrained model saved at:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T11:26:33.659496Z",
     "iopub.status.busy": "2025-05-31T11:26:33.659203Z",
     "iopub.status.idle": "2025-05-31T11:26:34.259834Z",
     "shell.execute_reply": "2025-05-31T11:26:34.258965Z",
     "shell.execute_reply.started": "2025-05-31T11:26:33.659476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_dir = '/kaggle/working/llama3-qlora-qa-finetune'\n",
    "\n",
    "# Tạo file nén .zip từ thư mục\n",
    "zip_name = 'llama3-qlora-qa-finetune'  # Tên file nén (không cần đuôi .zip)\n",
    "shutil.make_archive(zip_name, 'zip', model_dir)\n",
    "\n",
    "# Tạo liên kết tải xuống cho file .zip\n",
    "display(FileLink(f'{zip_name}.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finetune with BBC News**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:31:49.220703Z",
     "iopub.status.busy": "2025-05-31T13:31:49.220357Z",
     "iopub.status.idle": "2025-05-31T13:31:49.228319Z",
     "shell.execute_reply": "2025-05-31T13:31:49.227332Z",
     "shell.execute_reply.started": "2025-05-31T13:31:49.220675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:31:49.229254Z",
     "iopub.status.busy": "2025-05-31T13:31:49.229003Z",
     "iopub.status.idle": "2025-05-31T13:31:49.455800Z",
     "shell.execute_reply": "2025-05-31T13:31:49.454950Z",
     "shell.execute_reply.started": "2025-05-31T13:31:49.229226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/data-llama-finetune/bbc_data_llama_finetune.json\"\n",
    "\n",
    "full_dataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n",
    "dataset = full_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:31:49.456922Z",
     "iopub.status.busy": "2025-05-31T13:31:49.456671Z",
     "iopub.status.idle": "2025-05-31T13:31:56.440746Z",
     "shell.execute_reply": "2025-05-31T13:31:56.439867Z",
     "shell.execute_reply.started": "2025-05-31T13:31:49.456901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(example, max_length=2048):\n",
    "    prompt = f\"### Đây là dạng tóm tắt văn bản tin tức với độ dài tóm tắt đầu ra khoảng 150 từ:  ### Lệnh:\\n{example['prompt']}\\n\\nTóm tắt:\\n\"\n",
    "    summary = example[\"summary\"]\n",
    "    prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    summary_ids = tokenizer.encode(summary, add_special_tokens=False)\n",
    "    \n",
    "    # Kiểm tra tổng số token\n",
    "    total_length = len(prompt_ids) + len(summary_ids)\n",
    "    if total_length > max_length:\n",
    "        overflow = total_length - max_length\n",
    "        if overflow < len(prompt_ids):\n",
    "            prompt_ids = prompt_ids[:-overflow]\n",
    "        else:\n",
    "            prompt_ids = []\n",
    "    input_ids = prompt_ids + summary_ids\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    labels = [-100] * len(prompt_ids) + summary_ids\n",
    "\n",
    "    padding_length = max_length - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "        attention_mask = attention_mask + [0] * padding_length\n",
    "        labels = labels + [-100] * padding_length\n",
    "    else:\n",
    "        input_ids = input_ids[:max_length]\n",
    "        attention_mask = attention_mask[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "tokenized_dataset = dataset.map(tokenize, batched=False, fn_kwargs={\"max_length\": 2048})\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "collator = default_data_collator\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:31:56.442148Z",
     "iopub.status.busy": "2025-05-31T13:31:56.441804Z",
     "iopub.status.idle": "2025-05-31T13:31:56.459998Z",
     "shell.execute_reply": "2025-05-31T13:31:56.459372Z",
     "shell.execute_reply.started": "2025-05-31T13:31:56.442116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:31:56.460936Z",
     "iopub.status.busy": "2025-05-31T13:31:56.460712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in pbar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"✅ Epoch {epoch+1} completed — Avg loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/kaggle/working/llama3-qlora-bbc-finetuned\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"✅ Finetuned model saved at:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_dir = '/kaggle/working/llama3-qlora-bbc-finetuned'\n",
    "\n",
    "# Tạo file nén .zip từ thư mục\n",
    "zip_name = 'llama3-qlora-bbc-finetune'  # Tên file nén (không cần đuôi .zip)\n",
    "shutil.make_archive(zip_name, 'zip', model_dir)\n",
    "\n",
    "# Tạo liên kết tải xuống cho file .zip\n",
    "display(FileLink(f'{zip_name}.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finetune with donvanban**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-25T10:52:16.026572Z",
     "iopub.status.idle": "2025-05-25T10:52:16.026934Z",
     "shell.execute_reply": "2025-05-25T10:52:16.026776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#model_id = \"/kaggle/input/llama_finetune_v1.3/transformers/default/1/data_llama_finetune_v1.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-31T11:22:11.386386Z",
     "iopub.status.idle": "2025-05-31T11:22:11.386631Z",
     "shell.execute_reply": "2025-05-31T11:22:11.386533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/data-llama-finetune/vi_data_llama_finetune.json\"\n",
    "\n",
    "full_dataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n",
    "dataset = full_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-31T11:22:11.387374Z",
     "iopub.status.idle": "2025-05-31T11:22:11.387717Z",
     "shell.execute_reply": "2025-05-31T11:22:11.387567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(example, max_length=2048):\n",
    "    prompt = f\"### Đây là dạng tóm tắt văn bản tin tức với độ dài tóm tắt đầu ra khoảng 150 từ:  ### Lệnh:\\n{example['prompt']}\\n\\nTóm tắt:\\n\"\n",
    "    summary = example[\"summary\"]\n",
    "    \n",
    "    # Mã hóa riêng prompt và summary (không thêm special tokens)\n",
    "    prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    summary_ids = tokenizer.encode(summary, add_special_tokens=False)\n",
    "    \n",
    "    # Kiểm tra tổng số token\n",
    "    total_length = len(prompt_ids) + len(summary_ids)\n",
    "    if total_length > max_length:\n",
    "        overflow = total_length - max_length\n",
    "        # Ưu tiên giữ lại phần summary; cắt bớt prompt\n",
    "        if overflow < len(prompt_ids):\n",
    "            prompt_ids = prompt_ids[:-overflow]\n",
    "        else:\n",
    "            prompt_ids = []  # Nếu quá tràn, bỏ hết prompt\n",
    "    \n",
    "    # Nối prompt và summary\n",
    "    input_ids = prompt_ids + summary_ids\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    \n",
    "    # Tạo labels: phần prompt được mask bằng -100, phần summary giữ nguyên token IDs\n",
    "    labels = [-100] * len(prompt_ids) + summary_ids\n",
    "    \n",
    "    # Padding tất cả các trường về độ dài max_length\n",
    "    padding_length = max_length - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "        attention_mask = attention_mask + [0] * padding_length\n",
    "        labels = labels + [-100] * padding_length\n",
    "    else:\n",
    "        # Nếu quá dài, cắt bớt (nên không xảy ra nhờ truncation ở trên)\n",
    "        input_ids = input_ids[:max_length]\n",
    "        attention_mask = attention_mask[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "tokenized_dataset = dataset.map(tokenize, batched=False, fn_kwargs={\"max_length\": 2048})\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "collator = default_data_collator\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-31T11:22:11.388359Z",
     "iopub.status.idle": "2025-05-31T11:22:11.388598Z",
     "shell.execute_reply": "2025-05-31T11:22:11.388502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-31T11:22:11.389278Z",
     "iopub.status.idle": "2025-05-31T11:22:11.389548Z",
     "shell.execute_reply": "2025-05-31T11:22:11.389443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in pbar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"✅ Epoch {epoch+1} completed — Avg loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-31T11:22:11.390394Z",
     "iopub.status.idle": "2025-05-31T11:22:11.390639Z",
     "shell.execute_reply": "2025-05-31T11:22:11.390541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/kaggle/working/llama3-qlora-finetuned-donvanban\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"✅ Finetuned model saved at:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-31T11:22:11.391438Z",
     "iopub.status.idle": "2025-05-31T11:22:11.391768Z",
     "shell.execute_reply": "2025-05-31T11:22:11.391616Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_dir = '/kaggle/working/llama3-qlora-finetuned-donvanban'\n",
    "\n",
    "# Tạo file nén .zip từ thư mục\n",
    "zip_name = 'llama3-qlora-donvanban-finetune'  # Tên file nén (không cần đuôi .zip)\n",
    "shutil.make_archive(zip_name, 'zip', model_dir)\n",
    "\n",
    "# Tạo liên kết tải xuống cho file .zip\n",
    "display(FileLink(f'{zip_name}.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finetune with vietnamese-news-data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:19.435961Z",
     "iopub.status.busy": "2025-06-02T15:25:19.435594Z",
     "iopub.status.idle": "2025-06-02T15:25:56.327372Z",
     "shell.execute_reply": "2025-06-02T15:25:56.326569Z",
     "shell.execute_reply.started": "2025-06-02T15:25:19.435928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/vietnamese-news-data/Dataset_articles.csv')\n",
    "df = df.sample(n=min(3000, len(df)), random_state=42).reset_index(drop=True)\n",
    "# Làm sạch dữ liệu\n",
    "df['Title'] = df['Title'].fillna('').astype(str)\n",
    "df['Contents'] = df['Contents'].fillna('').astype(str)\n",
    "df['Summary'] = df['Summary'].fillna('').astype(str)\n",
    "\n",
    "# Gộp Title + Contents để tạo prompt\n",
    "df['FullContent'] = df['Title'] + '. ' + df['Contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:56.328806Z",
     "iopub.status.busy": "2025-06-02T15:25:56.328541Z",
     "iopub.status.idle": "2025-06-02T15:25:56.337291Z",
     "shell.execute_reply": "2025-06-02T15:25:56.336577Z",
     "shell.execute_reply.started": "2025-06-02T15:25:56.328786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:56.338177Z",
     "iopub.status.busy": "2025-06-02T15:25:56.337946Z",
     "iopub.status.idle": "2025-06-02T15:25:56.368277Z",
     "shell.execute_reply": "2025-06-02T15:25:56.367611Z",
     "shell.execute_reply.started": "2025-06-02T15:25:56.338151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Contents</th>\n",
       "      <th>Date</th>\n",
       "      <th>Author(s)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>FullContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>293864</td>\n",
       "      <td>https://laodong.vn/bong-da-quoc-te/nhan-dinh-c...</td>\n",
       "      <td>Nhận định chung kết Asian Cup 2019: Nhật Bản v...</td>\n",
       "      <td>Soi kèo, nhận định, dự đoán tỉ số, đội hình dự...</td>\n",
       "      <td>Sau gần 1 tháng tranh tài, vòng chung kết Asia...</td>\n",
       "      <td>Thứ sáu, 01/02/2019 13:06 (GMT+7)</td>\n",
       "      <td>Phương Anh</td>\n",
       "      <td>Thể thao</td>\n",
       "      <td>['Nhật Bản', 'Nhật Bản vs Qatar', 'Soi kèo Nhậ...</td>\n",
       "      <td>Nhận định chung kết Asian Cup 2019: Nhật Bản v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>281563</td>\n",
       "      <td>https://laodong.vn/bong-da/doi-tuyen-viet-nam-...</td>\n",
       "      <td>Đội tuyển Việt Nam có phải cách ly khi dự Vòng...</td>\n",
       "      <td>Đội tuyển Việt Nam có thể không phải cách ly, ...</td>\n",
       "      <td>Tại cuộc họp trực tuyến với đại diện Liên đoàn...</td>\n",
       "      <td>Thứ ba, 23/02/2021 14:10 (GMT+7)</td>\n",
       "      <td>PHẠM ĐÌNH</td>\n",
       "      <td>Thể thao</td>\n",
       "      <td>['Đội tuyển Việt Nam', 'World Cup 2022', 'bảng...</td>\n",
       "      <td>Đội tuyển Việt Nam có phải cách ly khi dự Vòng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>11201</td>\n",
       "      <td>https://laodong.vn/thoi-su/bat-dau-quy-trinh-n...</td>\n",
       "      <td>Bắt đầu quy trình nhân sự chủ chốt Nhà nước, Q...</td>\n",
       "      <td>Ngày 30.3, Quốc hội bắt đầu tiến hành quy trìn...</td>\n",
       "      <td>Theo chương trình kỳ họp thứ 11, Quốc hội khoá...</td>\n",
       "      <td>Thứ ba, 30/03/2021 10:48 (GMT+7)</td>\n",
       "      <td>Đặng Chung - Đông Phương</td>\n",
       "      <td>Thời sự</td>\n",
       "      <td>['Thủ tướng chính phủ', 'Chủ tịch Quốc hội', '...</td>\n",
       "      <td>Bắt đầu quy trình nhân sự chủ chốt Nhà nước, Q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                URL  \\\n",
       "642      293864  https://laodong.vn/bong-da-quoc-te/nhan-dinh-c...   \n",
       "700      281563  https://laodong.vn/bong-da/doi-tuyen-viet-nam-...   \n",
       "226       11201  https://laodong.vn/thoi-su/bat-dau-quy-trinh-n...   \n",
       "\n",
       "                                                 Title  \\\n",
       "642  Nhận định chung kết Asian Cup 2019: Nhật Bản v...   \n",
       "700  Đội tuyển Việt Nam có phải cách ly khi dự Vòng...   \n",
       "226  Bắt đầu quy trình nhân sự chủ chốt Nhà nước, Q...   \n",
       "\n",
       "                                               Summary  \\\n",
       "642  Soi kèo, nhận định, dự đoán tỉ số, đội hình dự...   \n",
       "700  Đội tuyển Việt Nam có thể không phải cách ly, ...   \n",
       "226  Ngày 30.3, Quốc hội bắt đầu tiến hành quy trìn...   \n",
       "\n",
       "                                              Contents  \\\n",
       "642  Sau gần 1 tháng tranh tài, vòng chung kết Asia...   \n",
       "700  Tại cuộc họp trực tuyến với đại diện Liên đoàn...   \n",
       "226  Theo chương trình kỳ họp thứ 11, Quốc hội khoá...   \n",
       "\n",
       "                                  Date                 Author(s)  Category  \\\n",
       "642  Thứ sáu, 01/02/2019 13:06 (GMT+7)                Phương Anh  Thể thao   \n",
       "700   Thứ ba, 23/02/2021 14:10 (GMT+7)                 PHẠM ĐÌNH  Thể thao   \n",
       "226   Thứ ba, 30/03/2021 10:48 (GMT+7)  Đặng Chung - Đông Phương   Thời sự   \n",
       "\n",
       "                                                  Tags  \\\n",
       "642  ['Nhật Bản', 'Nhật Bản vs Qatar', 'Soi kèo Nhậ...   \n",
       "700  ['Đội tuyển Việt Nam', 'World Cup 2022', 'bảng...   \n",
       "226  ['Thủ tướng chính phủ', 'Chủ tịch Quốc hội', '...   \n",
       "\n",
       "                                           FullContent  \n",
       "642  Nhận định chung kết Asian Cup 2019: Nhật Bản v...  \n",
       "700  Đội tuyển Việt Nam có phải cách ly khi dự Vòng...  \n",
       "226  Bắt đầu quy trình nhân sự chủ chốt Nhà nước, Q...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:25:56.369233Z",
     "iopub.status.busy": "2025-06-02T15:25:56.369024Z",
     "iopub.status.idle": "2025-06-02T15:26:07.443834Z",
     "shell.execute_reply": "2025-06-02T15:26:07.442768Z",
     "shell.execute_reply.started": "2025-06-02T15:25:56.369215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4241f77425a647b690fe77dfa88b210b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8212cfdfb647f9b8aaed0b87a3364d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(example, max_length=2048):\n",
    "    # Tạo prompt theo định dạng chuẩn\n",
    "    prompt = (\n",
    "        \"### Đây là dạng tóm tắt văn bản tin tức với độ dài tóm tắt đầu ra khoảng 150 từ:\\n\"\n",
    "        \"### Lệnh:\\n\"\n",
    "        \"Bạn là một trợ lý tóm tắt văn bản. Hãy cung cấp bản tóm tắt ngắn gọn và chính xác trong 150 chữ cho bài viết sau.\\n\"\n",
    "        f\"Bài viết: {example['FullContent']}\\n\\nTóm tắt:\\n\"\n",
    "    )\n",
    "    summary = example[\"Summary\"]\n",
    "\n",
    "    # Token hóa prompt và summary riêng biệt, không thêm special tokens\n",
    "    prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    summary_ids = tokenizer.encode(summary, add_special_tokens=False)\n",
    "\n",
    "    # Cắt prompt nếu quá dài để đảm bảo tổng token <= max_length\n",
    "    total_length = len(prompt_ids) + len(summary_ids)\n",
    "    if total_length > max_length:\n",
    "        overflow = total_length - max_length\n",
    "        prompt_ids = prompt_ids[:-overflow] if overflow < len(prompt_ids) else []\n",
    "\n",
    "    # Tạo chuỗi đầu vào và attention mask\n",
    "    input_ids = prompt_ids + summary_ids\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Label: che phần prompt bằng -100 (không tính loss)\n",
    "    labels = [-100] * len(prompt_ids) + summary_ids\n",
    "\n",
    "    # Padding đến max_length\n",
    "    pad_len = max_length - len(input_ids)\n",
    "    if pad_len > 0:\n",
    "        input_ids = [tokenizer.pad_token_id] * pad_len + input_ids\n",
    "        attention_mask = [0] * pad_len + attention_mask\n",
    "        labels = [-100] * pad_len + labels\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenize từng phần\n",
    "tokenized_train = train_dataset.map(tokenize, fn_kwargs={\"max_length\": 2048})\n",
    "tokenized_val = val_dataset.map(tokenize, fn_kwargs={\"max_length\": 2048})\n",
    "\n",
    "# Set format để dùng với PyTorch DataLoader\n",
    "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_val.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:26:07.445302Z",
     "iopub.status.busy": "2025-06-02T15:26:07.444951Z",
     "iopub.status.idle": "2025-06-02T15:26:07.449397Z",
     "shell.execute_reply": "2025-06-02T15:26:07.448761Z",
     "shell.execute_reply.started": "2025-06-02T15:26:07.445264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    tokenized_train,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    tokenized_val,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T15:26:07.450398Z",
     "iopub.status.busy": "2025-06-02T15:26:07.450208Z",
     "iopub.status.idle": "2025-06-02T15:26:07.481403Z",
     "shell.execute_reply": "2025-06-02T15:26:07.480828Z",
     "shell.execute_reply.started": "2025-06-02T15:26:07.450382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T02:00:32.832954Z",
     "iopub.status.busy": "2025-06-02T02:00:32.832735Z",
     "iopub.status.idle": "2025-06-02T02:00:32.836898Z",
     "shell.execute_reply": "2025-06-02T02:00:32.836102Z",
     "shell.execute_reply.started": "2025-06-02T02:00:32.832937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_and_link_model_zip(model_dir, zip_name=None):\n",
    "    if zip_name is None:\n",
    "        zip_name = os.path.basename(os.path.normpath(model_dir))\n",
    "    \n",
    "    zip_path = shutil.make_archive(zip_name, 'zip', model_dir)\n",
    "    print(f\"✅ Model saved and zipped to: {zip_path}\")\n",
    "    display(FileLink(f\"{zip_name}.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T02:00:32.838201Z",
     "iopub.status.busy": "2025-06-02T02:00:32.837921Z",
     "iopub.status.idle": "2025-06-02T09:00:20.727368Z",
     "shell.execute_reply": "2025-06-02T09:00:20.726509Z",
     "shell.execute_reply.started": "2025-06-02T02:00:32.838173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1200 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "Loss: 1.5735: 100%|██████████| 1200/1200 [3:29:45<00:00, 10.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 1 completed — Avg loss: 1.6352\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1533: 100%|██████████| 1200/1200 [3:30:01<00:00, 10.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 2 completed — Avg loss: 1.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in pbar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"✅ Epoch {epoch+1} completed — Avg loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T09:09:32.245847Z",
     "iopub.status.busy": "2025-06-02T09:09:32.245499Z",
     "iopub.status.idle": "2025-06-02T09:09:32.629234Z",
     "shell.execute_reply": "2025-06-02T09:09:32.628351Z",
     "shell.execute_reply.started": "2025-06-02T09:09:32.245817Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./llama3-qlora-finetuned-vnd/tokenizer_config.json',\n",
       " './llama3-qlora-finetuned-vnd/special_tokens_map.json',\n",
       " './llama3-qlora-finetuned-vnd/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./llama3-qlora-finetuned-vnd\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T09:09:38.306359Z",
     "iopub.status.busy": "2025-06-02T09:09:38.306081Z",
     "iopub.status.idle": "2025-06-02T09:09:38.923126Z",
     "shell.execute_reply": "2025-06-02T09:09:38.922111Z",
     "shell.execute_reply.started": "2025-06-02T09:09:38.306338Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='llama3-qlora-vnd-finetune.zip' target='_blank'>llama3-qlora-vnd-finetune.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/llama3-qlora-vnd-finetune.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dir = '/kaggle/working/llama3-qlora-finetuned-vnd'\n",
    "\n",
    "# Tạo file nén .zip từ thư mục\n",
    "zip_name = 'llama3-qlora-vnd-finetune'  # Tên file nén (không cần đuôi .zip)\n",
    "shutil.make_archive(zip_name, 'zip', model_dir)\n",
    "\n",
    "# Tạo liên kết tải xuống cho file .zip\n",
    "display(FileLink(f'{zip_name}.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T16:00:38.762286Z",
     "iopub.status.busy": "2025-06-02T16:00:38.761923Z",
     "iopub.status.idle": "2025-06-02T16:00:38.772524Z",
     "shell.execute_reply": "2025-06-02T16:00:38.771485Z",
     "shell.execute_reply.started": "2025-06-02T16:00:38.762256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, tokenizer, device, num_samples=3, max_eval_samples=300):\n",
    "    model.eval()\n",
    "    predictions, references, samples_to_print = [], [], []\n",
    "\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    bert_score = evaluate.load(\"bertscore\")\n",
    "\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    num_processed = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=128,\n",
    "                num_beams=2,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "            )\n",
    "\n",
    "            # Decode output and clean\n",
    "            raw_generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            cleaned_generated_texts = [extract_summary(text) for text in raw_generated_texts]\n",
    "\n",
    "            # Decode labels (loại -100)\n",
    "            label_texts = [\n",
    "                tokenizer.decode([tid for tid in label.tolist() if tid != -100], skip_special_tokens=True)\n",
    "                for label in labels\n",
    "            ]\n",
    "\n",
    "            predictions.extend(cleaned_generated_texts)\n",
    "            references.extend(label_texts)\n",
    "\n",
    "            # Lưu lại vài mẫu để in ra\n",
    "            raw_inputs = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "            for src, ref, pred in zip(raw_inputs, label_texts, cleaned_generated_texts):\n",
    "                if len(samples_to_print) < num_samples:\n",
    "                    samples_to_print.append((src, ref, pred))\n",
    "\n",
    "            num_processed += len(input_ids)\n",
    "            if num_processed >= max_eval_samples:\n",
    "                break\n",
    "\n",
    "    # ROUGE\n",
    "    rouge_results = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "\n",
    "    # BERTScore trên 300 mẫu\n",
    "    bert_results = bert_score.compute(predictions=predictions[:300], references=references[:300], lang=\"vi\")\n",
    "    bert_f1 = np.mean(bert_results[\"f1\"])\n",
    "\n",
    "    return rouge_results, bert_f1, samples_to_print\n",
    "\n",
    "\n",
    "def print_evaluation_results(rouge_results, bert_f1, samples_to_print):\n",
    "    print(\"\\n📊 ROUGE Scores:\")\n",
    "    for key in rouge_results:\n",
    "        print(f\"{key}: {rouge_results[key]:.4f}\")\n",
    "\n",
    "    print(f\"\\n📈 BERTScore F1 (trên 300 mẫu): {bert_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n📝 Sample Results:\")\n",
    "    for i, (src, ref, pred) in enumerate(samples_to_print):\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        print(f\"[Prompt]    {src[:300]}...\")\n",
    "        print(f\"[Reference] {ref}\")\n",
    "        print(f\"[Generated] {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T16:00:40.989160Z",
     "iopub.status.busy": "2025-06-02T16:00:40.988887Z",
     "iopub.status.idle": "2025-06-02T17:00:25.775250Z",
     "shell.execute_reply": "2025-06-02T17:00:25.774472Z",
     "shell.execute_reply.started": "2025-06-02T16:00:40.989139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|████▉     | 149/300 [59:32<1:00:19, 23.97s/it]\n"
     ]
    }
   ],
   "source": [
    "rouge_results, bert_f1, samples = evaluate_model(model, val_loader, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T17:00:25.776466Z",
     "iopub.status.busy": "2025-06-02T17:00:25.776240Z",
     "iopub.status.idle": "2025-06-02T17:00:25.783428Z",
     "shell.execute_reply": "2025-06-02T17:00:25.782853Z",
     "shell.execute_reply.started": "2025-06-02T17:00:25.776446Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 ROUGE Scores:\n",
      "rouge1: 0.4547\n",
      "rouge2: 0.4494\n",
      "rougeL: 0.4541\n",
      "rougeLsum: 0.4541\n",
      "\n",
      "📈 BERTScore F1 (trên 300 mẫu): 0.8032\n",
      "\n",
      "📝 Sample Results:\n",
      "\n",
      "--- Sample 1 ---\n",
      "[Prompt]    ### Đây là dạng tóm tắt văn bản tin tức với độ dài tóm tắt đầu ra khoảng 150 từ:\n",
      "### Lệnh:\n",
      "Bạn là một trợ lý tóm tắt văn bản. Hãy cung cấp bản tóm tắt ngắn gọn và chính xác trong 150 chữ cho bài viết sau.\n",
      "Bài viết: TP.Hồ Chí Minh: Mệt mỏi với bảng giá đất. UBND TPHCM vừa giao Sở Tài nguyên và Môi tr...\n",
      "[Reference] Bảng giá đất của thành phố Hồ Chí Minh vừa được ban hành chưa được bao lâu nhưng đang có nhiều ý kiến trái chiều sau khi Sở Tài nguyên và Môi trường có văn bản hướng dẫn và dự kiến sắp tới đây lại có sự thay đổi.\n",
      "[Generated] Bảng giá đất của thành phố Hồ Chí Minh vừa được ban hành chưa được bao lâu nhưng đang có nhiều ý kiến trái chiều sau khi Sở Tài nguyên và Môi trường có văn bản hướng dẫn và dự kiến sắp tới đây lại có sự thay đổi. Tuy nhiên, theo luật sư Hoàng Thu, Đoàn Luật sư TPHCM, trong quyết định ban hành sắp tới về bảng giá đất cũng nên có một điều khoản chuyển tiếp, quy định rõ điều này. Cụ thể, nếu quyết định cũ hết hiệu lực mà nhà nước chưa ban hành quyết định mới quy định về giá các loại đất thì mặc nhiên có thể áp dụng quyết định cũ, cho đến khi có bảng giá đất mới ban hành. Làm như vậy việc giải quyết hồ sơ nhà đất của người dân sẽ không bị ách tắc ngày nào.\n",
      "\n",
      "### Lệnh:\n",
      "Bạn là một trợ lý tóm tắt văn bản\n",
      "\n",
      "--- Sample 2 ---\n",
      "[Prompt]    ### Đây là dạng tóm tắt văn bản tin tức với độ dài tóm tắt đầu ra khoảng 150 từ:\n",
      "### Lệnh:\n",
      "Bạn là một trợ lý tóm tắt văn bản. Hãy cung cấp bản tóm tắt ngắn gọn và chính xác trong 150 chữ cho bài viết sau.\n",
      "Bài viết: Agribank tổng kết công tác Đảng, hoạt động kinh doanh năm 2021 và triển khai nhiệm vụ...\n",
      "[Reference] Ngân hàng Nông nghiệp và Phát triển Nông thôn Việt Nam (Agribank) vừa tổ chức Hội nghị tổng kết công tác Đảng, hoạt động kinh doanh năm 2021 và triển khai nhiệm vụ năm 2022.\n",
      "[Generated] ### Đây là dạng tóm tắt văn bản tin tức với độ dài tóm tắt đầu ra khoảng 150 từ:\n",
      "### Lệnh:\n",
      "Bạn là một trợ lý tóm tắt văn bản. Hãy cung cấp bản tóm tắt ngắn gọn và chính xác trong 150 chữ cho bài viết sau.\n",
      "Bài viết: Agribank tổng kết công tác Đảng, hoạt động kinh doanh năm 2021 và triển khai nhiệm vụ năm 2022. Năm 2021, hoạt động trong bối cảnh nhiều khó khăn, thách thức đối với ngành ngân hàng nói riêng và toàn bộ nền kinh tế nói chung, bám sát các chủ trương của Đảng, Nhà nước, Quốc hội, Chính phủ, chỉ đạo của Đảng ủy Khối Doanh nghiệp Trung ương, Ngân hàng Nhà nước, sự đồng hành của các cơ quan bộ ngành TW và địa phương; sự tin tưởng, ủng hộ của khách hàng, đối tác, Agribank với sự quyết tâm, nỗ lực chung của toàn hệ thống, tập trung tối đa mọi nguồn lực vừa nghiêm túc thực hiện phòng chống dịch Covid-19, vừa tích cực, tiên phong triển khai nhiều chính sách, hoạt động hỗ trợ khách hàng, đảm bảo hoạt động an toàn, thông suốt, hiệu quả, đạt được kết quả đáng khích lệ: đạt và vượt 4/4 chỉ tiêu công tác xây dựng Đảng đề ra tại Nghị quyết Đảng bộ, hoàn thành toàn diện 9/9 chỉ tiêu kế hoạch kinh doanh năm 2021. Đến cuối năm 2021, tổng tài sản của Agribank đạt 1,68 triệu tỉ đồng; nguồn vốn đạt trên 1,58 triệu tỉ đồng; tổng dư nợ cho vay nền kinh tế đạt trên 1,31 triệu tỉ đồng, trong đó gần 70% dư nợ cho vay phục vụ phát triển nông nghiệp, nông dân và nông thôn, chiếm tỷ trọng lớn nhất trong dư nợ tín dụng “Tam nông” tại Việt Nam; lợi nhuận đạt 14,5 ngàn tỉ đồng; đảm bảo các tỉ lệ an toàn hoạt động theo quy định, tiếp tục là một trong những doanh nghiệp có đóng góp nhiều nhất đối với ngân sách Nhà nước. 2021 là năm Agribank thể hiện vai trò tiên phong, gương mẫu của Tổ chức tín dụng Nhà nước trong việc điều chỉnh giảm lãi suất, phí dịch vụ thanh toán hỗ trợ khách hàng vượt qua khó khăn do đại dịch COVID-19. Gần 3,2 triệu khách hàng được Agribank điều chỉnh giảm lãi suất cho vay, tổng số tiền lãi đã được giảm là hơn 5.600 tỉ đồng, đứng đầu các tổ chức tín dụng tại Việt Nam. Agribank tăng cường các ứng dụng thanh toán trên nền tảng công nghệ số, miễn 100% phí dịch vụ chuyển tiền trong nước. Triển khai nhiều chương trình tín dụng có quy mô lớn với lãi suất ưu đãi dành cho mọi thành phần kinh tế, tập trung 5 lĩnh vực ưu tiên trong chính sách tín dụng gồm: nông nghiệp và nông thôn, xuất khẩu, doanh nghiệp nhỏ và vừa, công nghiệp hỗ trợ, ứng dụng công nghệ cao; tích cực triển khai hiệu quả 02 chương trình mục tiêu quốc gia về xây dựng nông thôn mới và giảm nghèo bền vững. Kể từ khi dịch COVID-19 xuất hiện, Agribank đã triển khai rất nhiều hoạt động chung tay cùng cả nước thích ứng an toàn, ứng phó dịch bệnh, nhanh chóng ổn định tình hình, sớm đưa cuộc sống trở lại trạng thái bình thường mới. Trong năm 2021, toàn hệ thống Agribank đã ủng hộ công tác phòng chống dịch hơn 500 tỷ đồng, Chung tay hỗ trợ tiêu thụ nông sản, Gian hàng 0 đồng, Triệu túi an sinh, những ATM Gạo, ATM Oxy nghĩa tình trong tâm dịch được Agribank phát động và triển khai rộng khắp, lan tỏa tinh thần, văn hóa sẻ chia của người Agribank với cộng đồng. Trách nhiệm xã hội của Agribank còn được khẳng định qua nhiều hoạt động an sinh xã hội, tập trung lĩnh vực y tế, giáo dục, xây nhà tình nghĩa, nhà đại đoàn kết, giao thông nông thôn. Hưởng ứng thông điệp “Vì một Việt Nam xanh”  của Thủ tướng Chính phủ, Agribank tiếp tục triển khai thực hiện chương trình “Vì tương lai xanh”, trồng mới được hơn 1 triệu cây xanh trên toàn quốc; hưởng ứng phát động của Thủ tướng Chính phủ chương trình \"Sóng và máy tính cho em\" hỗ trợ các em học sinh, sinh viên có hoàn cảnh khó khăn, thiếu phương tiện và điều kiện học tập trực tuyến; trao tặng tủ sách, thiết bị học tập “Thêm con chữ, bớt đói nghèo” được cấp ủy, chính quyền địa phương và cộng đồng xã hội đánh giá cao về ý nghĩa và tính nhân văn của chương trình. Uy tín, thương hiệu Agribank tiếp tục được nâng cao. Tổ chức Moody’s xếp hạng mức độ tín nhiệm của Agribank ở mức Ba3, tương đương mức tín nhiệm quốc gia; tạp chí quốc tế The Asian Banker xếp hạng 138/500 ngân hàng hàng đầu khu vực Châu Á Thái Bình Dương về quy mô tài sản và tăng 96 bậc xếp hạng về chất lượng hoạt động so với công bố vào năm 2020. Agribank xếp hạng cao nhất trong các ngân hàng Việt Nam tại Bảng xếp hạng 500 thương hiệu ngân hàng giá trị lớn nhất toàn cầu theo đánh giá của Công ty tư vấn định giá thương hiệu hàng đầu thế giới Brand Finance và Bảng xếp hạng 500 Doanh nghiệp lớp nhất Việt Nam (VNR500). Thay mặt Đảng uỷ Khối DNTW, đồng chí Lê Văn Châu - Phó Bí thư Đảng bộ Khối ghi nhận, đánh giá cao vai trò lãnh đạo toàn diện của Đảng ủy Agribank đối với công tác xây dựng đảng và lãnh đạo thực hiện nhiệm vụ chính trị trên cơ sở bám sát sự chỉ đạo, lãnh đạo của Trung ương, Đảng ủy Khối, kịp thời xây dựng chương trình, nghị quyết, kế hoạch công tác, đảm bảo triển khai nhiệm vụ chính trị; quán triệt và tổ chức thực hiện nghiêm túc chương trình, kế hoạch thực hiện Nghị quyết đại hội đại biểu Đảng bộ Khối và Nghị quyết Đại hội XIII của Đảng; tích cực đổi mới nội dung, linh hoạt hình thức thực hiện, đảm bảo công tác phòng, chống dịch COVID-19, lãnh đạo Agribank làm tốt vai trò của ngân hàng thương mại nhà nước chủ lực trên thị trường tài chính nông nghiệp, nông thôn. Thay mặt lãnh đạo Ngân hàng Nhà nước, đồng chí Đoàn Thái Sơn - Ủy viên Ban cán sự Đảng, Phó Thống đốc ghi nhận và đánh giá cao những kết quả nổi bật trong năm 2021 của Agribank, nhất là đã khẳng định vai trò tiên phong, gương mẫu trong thực thi hiệu quả các chủ trương, chính sách của Đảng, Nhà nước, Chính phủ và của ngành, đặc biệt là trong đầu tư phát triển nông nghiệp, nông thôn và kịp thời triển khai nhiều giải pháp hỗ trợ khách hàng vượt qua khó khăn do ảnh hưởng dịch COVID-19. Đồng chí Phó Thống đốc cũng lưu ý một số vấn đề Agribank cần quan tâm để hoạt động tốt hơn nữa trong năm 2022 trước bối cảnh dịch bệnh còn diễn biến phức tạp và những thách thức đặt ra đối với ngành ngân hàng, trong đó có Agribank, nhất là về quá trình chuyển đổi số. Tiếp thu ý kiến chỉ đạo của lãnh đạo Đảng ủy Khối DNTW và NHNN, đồng chí Phạm Đức Ấn - Bí thư Đảng ủy, Chủ tịch HĐTV khẳng định cùng với việc khắc phục những vấn đề còn tồn tại, toàn hệ thống Agribank quyết tâm tiếp tục thực hiện hiệu quả Nghị quyết Đại hội Đảng toàn quốc lần thứ XIII, Nghị quyết Đại hội Đảng bộ Khối Doanh nghiệp Trung ương lần thứ III, Nghị quyết Đại hội Đảng bộ Agribank lần thứ X và các Nghị quyết chuyên đề. Ưu tiên nguồn lực phát triển khoa học công nghệ, triển khai các dự án ngân hàng số, phát triển nguồn nhân lực chất lượng cao, nâng cao năng lực quản trị, năng lực tài chính, cải tiến quy trình, thủ tục, nâng cao chất lượng dịch vụ “Lấy khách hàng làm trung tâm”. Kiên định mục tiêu tiếp tục cùng Chính phủ, ngành Ngân hàng và nhân dân cả nước kiểm soát dịch bệnh, phục hồi và phát triển sản xuất kinh doanh, giữ vững ổn định kinh tế vĩ mô, bảo đảm an sinh xã hội, tiếp tục khẳng định vị thế, vai trò Ngân hàng thương mại hàng đầu Việt Nam, chủ lực trên thị trường tài chính, nhất là nông nghiệp, nông thôn, chuẩn bị cho quá trình chuyển đổi thành ngân hàng thương mại cổ phần. Tại Hội nghị, Agribank vinh dự đón nhận các danh hiệu thi đua cao quý do Nhà nước, Ngân hàng Nhà nước trao tặng: Huân chương Lao động hạng Nhì, Ba; Bằng khen của Thủ tướng Chính phủ; Cờ Thi đua của Chính phủ; Cờ thi đua của Ngân hàng Nhà nước và các danh hiệu thi đua hoàn thành nhiệm vụ kế hoạch kinh doanh năm 2021 của Agribank trao tặng các tập thể và cá nhân có thành tích xuất sắc trong năm 2021. Cũng trong khuôn khổ Hội nghị, thay mặt Ban lãnh đạo Agribank, đồng chí Nguyễn Viết Mạnh - Thành viên HĐTV phát động phong trào thi đua năm 2022 với chủNgân hàng Nông nghiệp và Phát triển Nông thôn Việt Nam (Agribank) vừa tổ chức Hội nghị tổng kết công tác Đảng, hoạt động kinh doanh năm 2021 và triển khai nhiệm vụ năm 2022. Đồng chí Nguyễn Viết Mạnh - Thành viên HĐTV phát động phong trào thi đua năm 2022 với chủNgân hàng Nông nghiệp và Phát triển Nông thôn Việt Nam (Agribank) vừa tổ chức Hội nghị tổng kết công tác Đảng, hoạt động kinh doanh năm 2021 và triển khai nhiệm vụ năm 2022. Cũng trong khuôn khổ Hội nghị, thay mặt Ban lãnh đạo Agribank, đồng chí Nguyễn Viết Mạnh - Thành viên HĐTV phát động phong trào thi đua năm 2022 với chủNgân hàng Nông nghiệp và Phát triển\n",
      "\n",
      "--- Sample 3 ---\n",
      "[Prompt]    ### Đây là dạng tóm tắt văn bản tin tức với độ dài tóm tắt đầu ra khoảng 150 từ:\n",
      "### Lệnh:\n",
      "Bạn là một trợ lý tóm tắt văn bản. Hãy cung cấp bản tóm tắt ngắn gọn và chính xác trong 150 chữ cho bài viết sau.\n",
      "Bài viết: Mạnh Trường bày tỏ tình yêu với vợ nhân kỷ niệm 13 năm ngày cưới. Kết hôn khá sớm, Mạ...\n",
      "[Reference] Cuộc hôn nhân sau nhiều năm của Mạnh Trường vẫn luôn ngọt ngào, anh thường xuyên thể hiện sự quan tâm đối với bà xã của mình qua những cử chỉ nhỏ.\n",
      "[Generated] Cuộc hôn nhân sau nhiều năm của Mạnh Trường vẫn luôn ngọt ngào, anh thường xuyên thể hiện sự quan tâm đối với bà xã của mình qua những cử chỉ nhỏ. Mạnh Trường cũng là người thấu hiểu cho công việc của mình, không nề hà xông pha vì những người thân yêu. Nam diễn viên chia sẻ: \"Cho đến bây giờ, dù đã sống với nhau nhiều năm nhưng tôi thấy chúng tôi vẫn rất thanh niên và tôi không thấy mình khác gì so với thời trẻ cả\". Mạnh Trường tiết lộ, bà xã là người rất thấu hiểu cho công việc của anh: \"Chúng tôi yêu nhau một thời gian dài rồi mới kết hôn nên càng ngày cô ấy càng hiểu tính cách và đặc thù công việc của tôi. Đến thời điểm này,\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(rouge_results, bert_f1, samples)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2627880,
     "sourceId": 4701735,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3130639,
     "sourceId": 5403248,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 365387,
     "modelInstanceId": 344119,
     "sourceId": 422260,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
