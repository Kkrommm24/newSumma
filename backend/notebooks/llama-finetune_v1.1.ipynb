{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-25T02:10:25.783461Z",
     "iopub.status.busy": "2025-03-25T02:10:25.783260Z",
     "iopub.status.idle": "2025-03-25T02:10:33.736812Z",
     "shell.execute_reply": "2025-03-25T02:10:33.735930Z",
     "shell.execute_reply.started": "2025-03-25T02:10:25.783442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install accelerate peft datasets bitsandbytes evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:10:33.737868Z",
     "iopub.status.busy": "2025-03-25T02:10:33.737639Z",
     "iopub.status.idle": "2025-03-25T02:10:39.187484Z",
     "shell.execute_reply": "2025-03-25T02:10:39.186395Z",
     "shell.execute_reply.started": "2025-03-25T02:10:33.737848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=b44f75b663fb9ebf0e65e584ac55191497922d9b834594ed30e9399703136486\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:10:39.188919Z",
     "iopub.status.busy": "2025-03-25T02:10:39.188514Z",
     "iopub.status.idle": "2025-03-25T02:11:03.391476Z",
     "shell.execute_reply": "2025-03-25T02:11:03.390572Z",
     "shell.execute_reply.started": "2025-03-25T02:10:39.188827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    default_data_collator,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:11:03.392991Z",
     "iopub.status.busy": "2025-03-25T02:11:03.392471Z",
     "iopub.status.idle": "2025-03-25T02:11:03.538835Z",
     "shell.execute_reply": "2025-03-25T02:11:03.537893Z",
     "shell.execute_reply.started": "2025-03-25T02:11:03.392967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:11:03.539872Z",
     "iopub.status.busy": "2025-03-25T02:11:03.539666Z",
     "iopub.status.idle": "2025-03-25T02:11:19.857240Z",
     "shell.execute_reply": "2025-03-25T02:11:19.856583Z",
     "shell.execute_reply.started": "2025-03-25T02:11:03.539853Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37908b368e274554915128bb1e936b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b34f4ff1da2466ebfc3fef79d0ba28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270409ddc08249f38de2b9ccb6d5654a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a5b4538f98482f8cc4d7093cadf2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dae23b201c412b9319f0c1540c4956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec4d46c2f714ebe8b75e8f44b5fd327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token or tokenizer.bos_token or tokenizer.unk_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "\n",
    "# 4. QLoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:12:17.479794Z",
     "iopub.status.busy": "2025-03-25T02:12:17.479467Z",
     "iopub.status.idle": "2025-03-25T02:12:17.972363Z",
     "shell.execute_reply": "2025-03-25T02:12:17.971488Z",
     "shell.execute_reply.started": "2025-03-25T02:12:17.479771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a086be18d9864b5d94cf40ab2b080047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"/kaggle/input/data-llama-finetune/bbc_data_llama_finetune.json\"\n",
    "\n",
    "full_dataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n",
    "dataset = full_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:12:19.742486Z",
     "iopub.status.busy": "2025-03-25T02:12:19.742173Z",
     "iopub.status.idle": "2025-03-25T02:12:25.782990Z",
     "shell.execute_reply": "2025-03-25T02:12:25.782035Z",
     "shell.execute_reply.started": "2025-03-25T02:12:19.742463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcb089559994bf58258c75e1a14237c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1914 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5762df9f885146f891bcf8c288f975bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(example, max_length=1024):\n",
    "    # T·∫°o chu·ªói input theo ƒë·ªãnh d·∫°ng:\n",
    "    # \"### Prompt:\\n<prompt>\\n\\n### Summary:\\n\" + summary\n",
    "    prompt = f\"### Prompt:\\n{example['prompt']}\\n\\n### Summary:\\n\"\n",
    "    summary = example[\"summary\"]\n",
    "    \n",
    "    # M√£ h√≥a ri√™ng prompt v√† summary (kh√¥ng th√™m special tokens)\n",
    "    prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    summary_ids = tokenizer.encode(summary, add_special_tokens=False)\n",
    "    \n",
    "    # Ki·ªÉm tra t·ªïng s·ªë token\n",
    "    total_length = len(prompt_ids) + len(summary_ids)\n",
    "    if total_length > max_length:\n",
    "        overflow = total_length - max_length\n",
    "        # ∆Øu ti√™n gi·ªØ l·∫°i ph·∫ßn summary; c·∫Øt b·ªõt prompt\n",
    "        if overflow < len(prompt_ids):\n",
    "            prompt_ids = prompt_ids[:-overflow]\n",
    "        else:\n",
    "            prompt_ids = []  # N·∫øu qu√° tr√†n, b·ªè h·∫øt prompt\n",
    "    \n",
    "    # N·ªëi prompt v√† summary\n",
    "    input_ids = prompt_ids + summary_ids\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    \n",
    "    # T·∫°o labels: ph·∫ßn prompt ƒë∆∞·ª£c mask b·∫±ng -100, ph·∫ßn summary gi·ªØ nguy√™n token IDs\n",
    "    labels = [-100] * len(prompt_ids) + summary_ids\n",
    "    \n",
    "    # Padding t·∫•t c·∫£ c√°c tr∆∞·ªùng v·ªÅ ƒë·ªô d√†i max_length\n",
    "    padding_length = max_length - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "        attention_mask = attention_mask + [0] * padding_length\n",
    "        labels = labels + [-100] * padding_length\n",
    "    else:\n",
    "        # N·∫øu qu√° d√†i, c·∫Øt b·ªõt (n√™n kh√¥ng x·∫£y ra nh·ªù truncation ·ªü tr√™n)\n",
    "        input_ids = input_ids[:max_length]\n",
    "        attention_mask = attention_mask[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "tokenized_dataset = dataset.map(tokenize, batched=False, fn_kwargs={\"max_length\": 1024})\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "collator = default_data_collator\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:12:35.734023Z",
     "iopub.status.busy": "2025-03-25T02:12:35.733625Z",
     "iopub.status.idle": "2025-03-25T02:12:35.752306Z",
     "shell.execute_reply": "2025-03-25T02:12:35.751314Z",
     "shell.execute_reply.started": "2025-03-25T02:12:35.733992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T02:12:38.372824Z",
     "iopub.status.busy": "2025-03-25T02:12:38.372486Z",
     "iopub.status.idle": "2025-03-25T05:59:21.517935Z",
     "shell.execute_reply": "2025-03-25T05:59:21.517143Z",
     "shell.execute_reply.started": "2025-03-25T02:12:38.372799Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/479 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "Loss: 0.1117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 479/479 [1:15:30<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 1 completed ‚Äî Avg loss: 0.3874\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6455: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 479/479 [1:15:40<00:00,  9.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 2 completed ‚Äî Avg loss: 0.3336\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5744: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 479/479 [1:15:32<00:00,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 3 completed ‚Äî Avg loss: 0.3229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in pbar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"‚úÖ Epoch {epoch+1} completed ‚Äî Avg loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T06:17:45.913939Z",
     "iopub.status.busy": "2025-03-25T06:17:45.913605Z",
     "iopub.status.idle": "2025-03-25T06:17:46.415225Z",
     "shell.execute_reply": "2025-03-25T06:17:46.414471Z",
     "shell.execute_reply.started": "2025-03-25T06:17:45.913913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finetuned model saved at: /kaggle/working/llama3-qlora-finetuned\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/kaggle/working/llama3-qlora-finetuned\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"‚úÖ Finetuned model saved at:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T06:17:48.975310Z",
     "iopub.status.busy": "2025-03-25T06:17:48.974907Z",
     "iopub.status.idle": "2025-03-25T06:17:48.989617Z",
     "shell.execute_reply": "2025-03-25T06:17:48.988750Z",
     "shell.execute_reply.started": "2025-03-25T06:17:48.975272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_after_training(model, val_loader, tokenizer, device, num_samples=5):\n",
    "    import evaluate\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    samples_to_print = []\n",
    "\n",
    "    # Load ROUGE\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "\n",
    "    def left_pad(inputs, pad_token_id):\n",
    "        \"\"\"Chuy·ªÉn batch input th√†nh left-padded\"\"\"\n",
    "        max_len = max(len(seq) for seq in inputs)\n",
    "        return torch.stack([\n",
    "            torch.cat([torch.full((max_len - len(seq),), pad_token_id, dtype=torch.long), seq])\n",
    "            for seq in inputs\n",
    "        ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Chuy·ªÉn sang left padding th·ªß c√¥ng\n",
    "            input_ids = left_pad([x[x != tokenizer.pad_token_id] for x in input_ids], tokenizer.pad_token_id).to(device)\n",
    "            attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "\n",
    "            # Generate\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=128,\n",
    "                num_beams=4,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode\n",
    "            generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "            label_texts = []\n",
    "            for label in labels:\n",
    "                label_ids = [token_id for token_id in label.tolist() if token_id != -100]\n",
    "                label_texts.append(tokenizer.decode(label_ids, skip_special_tokens=True))\n",
    "\n",
    "            predictions.extend(generated_texts)\n",
    "            references.extend(label_texts)\n",
    "\n",
    "            if len(samples_to_print) < num_samples:\n",
    "                src_texts = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "                for src, ref, pred in zip(src_texts, label_texts, generated_texts):\n",
    "                    samples_to_print.append((src, ref, pred))\n",
    "                    if len(samples_to_print) >= num_samples:\n",
    "                        break\n",
    "\n",
    "    # T√≠nh ROUGE\n",
    "    results = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "\n",
    "    print(\"\\nüìä ROUGE Scores:\")\n",
    "    for key in results:\n",
    "        print(f\"{key}: {results[key]:.4f}\")\n",
    "\n",
    "    print(\"\\nüìù Sample Results:\")\n",
    "    for i, (src, ref, pred) in enumerate(samples_to_print):\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        print(f\"[Prompt]    {src}\")\n",
    "        print(f\"[Reference] {ref}\")\n",
    "        print(f\"[Generated] {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T06:17:58.126195Z",
     "iopub.status.busy": "2025-03-25T06:17:58.125880Z",
     "iopub.status.idle": "2025-03-25T06:46:46.971858Z",
     "shell.execute_reply": "2025-03-25T06:46:46.970856Z",
     "shell.execute_reply.started": "2025-03-25T06:17:58.126168Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8049e6ddbc1648669000bda4cdc31214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [28:22<00:00, 31.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä ROUGE Scores:\n",
      "rouge1: 0.4274\n",
      "rouge2: 0.4257\n",
      "rougeL: 0.4274\n",
      "rougeLsum: 0.4271\n",
      "\n",
      "üìù Sample Results:\n",
      "\n",
      "--- Sample 1 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "Norway upholds 'Napster' ruling\n",
      "\n",
      "A Norwegian student who ran a website which linked to downloadable MP3 files has been ordered to pay compensation by the country's Supreme Court.\n",
      "\n",
      "Frank Allan Bruvik was ordered to pay 100,000 kroner (¬£8,000) to the music industry in Norway. He was a student when he set up his napster.no site, which allowed users to submit and receive links to MP3 files. Bruvik had earlier been cleared on appeal after a lower court had found for the music industry. Music industry bosses in Norway said the ruling would help build confidence in the internet as a distribution medium.\n",
      "\n",
      "Frank Allan Bruvik set up the napster.no website as part of a school project in 2001 while studying computer engineering in the Norwegian town of Lillehammer. The website was not associated with the napster.com site in the USA, which had been operating since 1999 and was already facing legal action.\n",
      "\n",
      "Bruvik's site was online between August and November 2001, and while it did not host any music, at its peak it was providing links to more than 170 free files on other servers. As well as providing links, the site allowed those visiting it to submit links that could later be accessed by other visitors. A legal complaint for copyright violation was filed by groups including Norway's performing rights society, Tono, and the Norwegian branches of Sony Music and Universal Music, who saw it as an important test of principle.\n",
      "\n",
      "A Norwegian court ruled in 2003 that Bruvik would have to pay 100,000 kroner to the music industry, but the country's Court of Appeal cleared him, saying that the copyright violation occurred when others posted the music. However, the Supreme Court stated that the music was clearly published in violation of copyright law It added that the case was decided based on the responsibility for abetting an illegal act, and that Bruvik's actions were premeditated. Norway's music industry said it was satisfied with the ruling, because showed that music piracy would not be accepted.\n",
      "\n",
      "Meanwhile, in the USA a further 717 lawsuits against people alleged to have traded copyrighted songs were filed this week by the Recording Industry Association of America. The suits, brought on behalf of the major record companies, cite the individuals for illegally distributing music via unauthorized peer-to-peer services such as KaZaa and eDonkey. As with preceding cases, the fresh action was made against so-called \"John Doe\" defendants, who are identified only by the codes given to their computers' internet connections.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "Frank Allan Bruvik was ordered to pay 100,000 kroner (¬£8,000) to the music industry in Norway.Norway's music industry said it was satisfied with the ruling, because showed that music piracy would not be accepted.A Norwegian court ruled in 2003 that Bruvik would have to pay 100,000 kroner to the music industry, but the country's Court of Appeal cleared him, saying that the copyright violation occurred when others posted the music.Bruvik's site was online between August and November 2001, and while it did not host any music, at its peak it was providing links to more than 170 free files on other servers.However, the Supreme Court stated that the music was clearly published in violation of copyright law It added that the case was decided based on the responsibility for abetting an illegal act, and that Bruvik's actions were premeditated.A legal complaint for copyright violation was filed by groups including Norway's performing rights society, Tono, and the Norwegian branches of Sony Music and Universal Music, who saw it as an important test of principle.Bruvik had earlier been cleared on appeal after a lower court had found for the music industry.\n",
      "[Reference] Frank Allan Bruvik was ordered to pay 100,000 kroner (¬£8,000) to the music industry in Norway.Norway's music industry said it was satisfied with the ruling, because showed that music piracy would not be accepted.A Norwegian court ruled in 2003 that Bruvik would have to pay 100,000 kroner to the music industry, but the country's Court of Appeal cleared him, saying that the copyright violation occurred when others posted the music.Bruvik's site was online between August and November 2001, and while it did not host any music, at its peak it was providing links to more than 170 free files on other servers.However, the Supreme Court stated that the music was clearly published in violation of copyright law It added that the case was decided based on the responsibility for abetting an illegal act, and that Bruvik's actions were premeditated.A legal complaint for copyright violation was filed by groups including Norway's performing rights society, Tono, and the Norwegian branches of Sony Music and Universal Music, who saw it as an important test of principle.Bruvik had earlier been cleared on appeal after a lower court had found for the music industry.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "Norway upholds 'Napster' ruling\n",
      "\n",
      "A Norwegian student who ran a website which linked to downloadable MP3 files has been ordered to pay compensation by the country's Supreme Court.\n",
      "\n",
      "Frank Allan Bruvik was ordered to pay 100,000 kroner (¬£8,000) to the music industry in Norway. He was a student when he set up his napster.no site, which allowed users to submit and receive links to MP3 files. Bruvik had earlier been cleared on appeal after a lower court had found for the music industry. Music industry bosses in Norway said the ruling would help build confidence in the internet as a distribution medium.\n",
      "\n",
      "Frank Allan Bruvik set up the napster.no website as part of a school project in 2001 while studying computer engineering in the Norwegian town of Lillehammer. The website was not associated with the napster.com site in the USA, which had been operating since 1999 and was already facing legal action.\n",
      "\n",
      "Bruvik's site was online between August and November 2001, and while it did not host any music, at its peak it was providing links to more than 170 free files on other servers. As well as providing links, the site allowed those visiting it to submit links that could later be accessed by other visitors. A legal complaint for copyright violation was filed by groups including Norway's performing rights society, Tono, and the Norwegian branches of Sony Music and Universal Music, who saw it as an important test of principle.\n",
      "\n",
      "A Norwegian court ruled in 2003 that Bruvik would have to pay 100,000 kroner to the music industry, but the country's Court of Appeal cleared him, saying that the copyright violation occurred when others posted the music. However, the Supreme Court stated that the music was clearly published in violation of copyright law It added that the case was decided based on the responsibility for abetting an illegal act, and that Bruvik's actions were premeditated. Norway's music industry said it was satisfied with the ruling, because showed that music piracy would not be accepted.\n",
      "\n",
      "Meanwhile, in the USA a further 717 lawsuits against people alleged to have traded copyrighted songs were filed this week by the Recording Industry Association of America. The suits, brought on behalf of the major record companies, cite the individuals for illegally distributing music via unauthorized peer-to-peer services such as KaZaa and eDonkey. As with preceding cases, the fresh action was made against so-called \"John Doe\" defendants, who are identified only by the codes given to their computers' internet connections.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "Frank Allan Bruvik was ordered to pay 100,000 kroner (¬£8,000) to the music industry in Norway.Norway's music industry said it was satisfied with the ruling, because showed that music piracy would not be accepted.A Norwegian court ruled in 2003 that Bruvik would have to pay 100,000 kroner to the music industry, but the country's Court of Appeal cleared him, saying that the copyright violation occurred when others posted the music.Bruvik's site was online between August and November 2001, and while it did not host any music, at its peak it was providing links to more than 170 free files on other servers.However, the Supreme Court stated that the music was clearly published in violation of copyright law It added that the case was decided based on the responsibility for abetting an illegal act, and that Bruvik's actions were premeditated.A legal complaint for copyright violation was filed by groups including Norway's performing rights society, Tono, and the Norwegian branches of Sony Music and Universal Music, who saw it as an important test of principle.Bruvik had earlier been cleared on appeal after a lower court had found for the music industry.  Music industry bosses in Norway said the ruling would help build confidence in the internet as a distribution medium.  As with preceding cases, the fresh action was made against so-called \"John Doe\" defendants, who are identified only by the codes given to their computers' internet connections.\n",
      "\n",
      "--- Sample 2 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "Films on war triumph at Sundance\n",
      "\n",
      "A study of the United States at war in the past 50 years has picked up one of the main awards at the 2005 Sundance Film Festival in Utah, in the US.\n",
      "\n",
      "Why We Fight scooped the grand jury prize for documentaries at the world's leading independent film festival. British director Sean McAllister's The Liberace of Baghdad - about a pianist in war-torn Iraq - won a special prize in the world documentary category. Both Why We Fight and The Liberace of Baghdad were made for the BBC. Why We Fight is due to be screened on BBC Four in March.\n",
      "\n",
      "The Sundance festival was founded by actor Robert Redford in 1981. This year's festival - which ended on Sunday after a 11-day run - has been dominated by the themes of war and politics. In the new world cinema drama category, the Angolan film The Hero triumphed to win the grand jury prize. The film - an Angolan/French/Portuguese production - tells the story of a veteran of the country's civil war who returns home to face a new battle of survival. Twelve films competing in the new world cinema documentary category focused on countries and people under siege.\n",
      "\n",
      "Finnish film The Three Rooms of Melancholia looks at the war in Chechnya and Shake Hands With The Devil: The Journey of Romeo Dallaire tells the story of a UN mission to Rwanda during the 1994 genocide. But it was Dutch documentary Shape of the Moon - a study of an extended family in Indonesia - which took the top prize. Meanwhile, French-Israeli production Wall, which looks at Israel's controversial security wall separating it from the Palestinian territories, picked up a world cinema special jury prize for documentaries. In the main drama category, Forty Shades of Blue was named winner of the grand jury prize. The film tells the tale of a forbidden tug-of-love between a father, his Russian immigrant girlfriend and his son.\n",
      "\n",
      "During its 24-year history, the Sundance Film Festival has showcased successes such as Reservoir Dogs, The Blair Witch Project and The Full Monty. Last year's festival provided a platform for hits such as Open Water, Napoleon Dynamite, Garden State and Super-Size Me. The festival is held in the mountain resort of Park City, east of Salt Lake City, which sees its population rise from 7,500 to 45,000 during the festival.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "Why We Fight scooped the grand jury prize for documentaries at the world's leading independent film festival.In the new world cinema drama category, the Angolan film The Hero triumphed to win the grand jury prize.A study of the United States at war in the past 50 years has picked up one of the main awards at the 2005 Sundance Film Festival in Utah, in the US.Twelve films competing in the new world cinema documentary category focused on countries and people under siege.During its 24-year history, the Sundance Film Festival has showcased successes such as Reservoir Dogs, The Blair Witch Project and The Full Monty.British director Sean McAllister's The Liberace of Baghdad - about a pianist in war-torn Iraq - won a special prize in the world documentary category.In the main drama category, Forty Shades of Blue was named winner of the grand jury prize.The Sundance festival was founded by actor Robert Redford in 1981.\n",
      "[Reference] Why We Fight scooped the grand jury prize for documentaries at the world's leading independent film festival.In the new world cinema drama category, the Angolan film The Hero triumphed to win the grand jury prize.A study of the United States at war in the past 50 years has picked up one of the main awards at the 2005 Sundance Film Festival in Utah, in the US.Twelve films competing in the new world cinema documentary category focused on countries and people under siege.During its 24-year history, the Sundance Film Festival has showcased successes such as Reservoir Dogs, The Blair Witch Project and The Full Monty.British director Sean McAllister's The Liberace of Baghdad - about a pianist in war-torn Iraq - won a special prize in the world documentary category.In the main drama category, Forty Shades of Blue was named winner of the grand jury prize.The Sundance festival was founded by actor Robert Redford in 1981.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "Films on war triumph at Sundance\n",
      "\n",
      "A study of the United States at war in the past 50 years has picked up one of the main awards at the 2005 Sundance Film Festival in Utah, in the US.\n",
      "\n",
      "Why We Fight scooped the grand jury prize for documentaries at the world's leading independent film festival. British director Sean McAllister's The Liberace of Baghdad - about a pianist in war-torn Iraq - won a special prize in the world documentary category. Both Why We Fight and The Liberace of Baghdad were made for the BBC. Why We Fight is due to be screened on BBC Four in March.\n",
      "\n",
      "The Sundance festival was founded by actor Robert Redford in 1981. This year's festival - which ended on Sunday after a 11-day run - has been dominated by the themes of war and politics. In the new world cinema drama category, the Angolan film The Hero triumphed to win the grand jury prize. The film - an Angolan/French/Portuguese production - tells the story of a veteran of the country's civil war who returns home to face a new battle of survival. Twelve films competing in the new world cinema documentary category focused on countries and people under siege.\n",
      "\n",
      "Finnish film The Three Rooms of Melancholia looks at the war in Chechnya and Shake Hands With The Devil: The Journey of Romeo Dallaire tells the story of a UN mission to Rwanda during the 1994 genocide. But it was Dutch documentary Shape of the Moon - a study of an extended family in Indonesia - which took the top prize. Meanwhile, French-Israeli production Wall, which looks at Israel's controversial security wall separating it from the Palestinian territories, picked up a world cinema special jury prize for documentaries. In the main drama category, Forty Shades of Blue was named winner of the grand jury prize. The film tells the tale of a forbidden tug-of-love between a father, his Russian immigrant girlfriend and his son.\n",
      "\n",
      "During its 24-year history, the Sundance Film Festival has showcased successes such as Reservoir Dogs, The Blair Witch Project and The Full Monty. Last year's festival provided a platform for hits such as Open Water, Napoleon Dynamite, Garden State and Super-Size Me. The festival is held in the mountain resort of Park City, east of Salt Lake City, which sees its population rise from 7,500 to 45,000 during the festival.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "Why We Fight scooped the grand jury prize for documentaries at the world's leading independent film festival.In the new world cinema drama category, the Angolan film The Hero triumphed to win the grand jury prize.A study of the United States at war in the past 50 years has picked up one of the main awards at the 2005 Sundance Film Festival in Utah, in the US.Twelve films competing in the new world cinema documentary category focused on countries and people under siege.During its 24-year history, the Sundance Film Festival has showcased successes such as Reservoir Dogs, The Blair Witch Project and The Full Monty.British director Sean McAllister's The Liberace of Baghdad - about a pianist in war-torn Iraq - won a special prize in the world documentary category.In the main drama category, Forty Shades of Blue was named winner of the grand jury prize.The Sundance festival was founded by actor Robert Redford in 1981.Both Why We Fight and The Liberace of Baghdad were made for the BBC.Finnish film The Three Rooms of Melancholia looks at the war in Chechnya and Shake Hands With The Devil: The Journey of Romeo Dallaire tells the story of a UN mission to Rwanda during the 1994 genocide.\n",
      "\n",
      "--- Sample 3 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "EMI shares hit by profit warning\n",
      "\n",
      "Shares in music giant EMI have sunk by more than 16% after the firm issued a profit warning following disappointing sales and delays to two album releases.\n",
      "\n",
      "EMI said music sales for the year to March will fall 8-9% from the year before, with profits set to be 15% lower than analysts had expected. It blamed poor sales since Christmas and delays to the releases of new albums by Coldplay and Gorillaz. By 1200 GMT on Monday, EMI shares were down 16.2% at 235.75 pence.\n",
      "\n",
      "EMI said two major albums scheduled for release before the end of the financial year in March - one by Coldplay and one by Gorillaz - have now had their release dates put back.\n",
      "\n",
      "\"EMI Music's sales, particularly re-orders, in January have also been lower than anticipated and this is expected to continue through February and March,\" the company added. \"Therefore, for the full year, at constant currency, EMI Music's sales are now expected to be 8% to 9% lower than the prior year.\" The company said it expected profits to be about ¬£138m ($259.8m). Alain Levy, chairman and chief executive of EMI Music, described the performance as \"disappointing\", but added that he remained optimistic over future trends in the industry. \"The physical music market is showing signs of stabilisation in many parts of the world and digital music, in all its forms, continues to develop at a rapid pace,\" he said.\n",
      "\n",
      "Commenting on the delay to the release of the Coldplay and Gorillaz albums, Mr Levy said that \"creating and marketing music is not an exact science and cannot always coincide with our reporting periods\". \"While this rescheduling and recent softness is disappointing, it does not change my views of the improving health of the global recorded music industry,\" he added. Paul Richards, an analyst at Numis Securities, said the market would be focusing on the slump in music sales rather than the timing of the two albums. \"It's unusual to see this much of a downgrade just because of phasing,\" he said.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "EMI said music sales for the year to March will fall 8-9% from the year before, with profits set to be 15% lower than analysts had expected.Shares in music giant EMI have sunk by more than 16% after the firm issued a profit warning following disappointing sales and delays to two album releases.EMI said two major albums scheduled for release before the end of the financial year in March - one by Coldplay and one by Gorillaz - have now had their release dates put back.\"Therefore, for the full year, at constant currency, EMI Music's sales are now expected to be 8% to 9% lower than the prior year.\"The company said it expected profits to be about ¬£138m ($259.8m).Commenting on the delay to the release of the Coldplay and Gorillaz albums, Mr Levy said that \"creating and marketing music is not an exact science and cannot always coincide with our reporting periods\".\n",
      "[Reference] EMI said music sales for the year to March will fall 8-9% from the year before, with profits set to be 15% lower than analysts had expected.Shares in music giant EMI have sunk by more than 16% after the firm issued a profit warning following disappointing sales and delays to two album releases.EMI said two major albums scheduled for release before the end of the financial year in March - one by Coldplay and one by Gorillaz - have now had their release dates put back.\"Therefore, for the full year, at constant currency, EMI Music's sales are now expected to be 8% to 9% lower than the prior year.\"The company said it expected profits to be about ¬£138m ($259.8m).Commenting on the delay to the release of the Coldplay and Gorillaz albums, Mr Levy said that \"creating and marketing music is not an exact science and cannot always coincide with our reporting periods\".\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "EMI shares hit by profit warning\n",
      "\n",
      "Shares in music giant EMI have sunk by more than 16% after the firm issued a profit warning following disappointing sales and delays to two album releases.\n",
      "\n",
      "EMI said music sales for the year to March will fall 8-9% from the year before, with profits set to be 15% lower than analysts had expected. It blamed poor sales since Christmas and delays to the releases of new albums by Coldplay and Gorillaz. By 1200 GMT on Monday, EMI shares were down 16.2% at 235.75 pence.\n",
      "\n",
      "EMI said two major albums scheduled for release before the end of the financial year in March - one by Coldplay and one by Gorillaz - have now had their release dates put back.\n",
      "\n",
      "\"EMI Music's sales, particularly re-orders, in January have also been lower than anticipated and this is expected to continue through February and March,\" the company added. \"Therefore, for the full year, at constant currency, EMI Music's sales are now expected to be 8% to 9% lower than the prior year.\" The company said it expected profits to be about ¬£138m ($259.8m). Alain Levy, chairman and chief executive of EMI Music, described the performance as \"disappointing\", but added that he remained optimistic over future trends in the industry. \"The physical music market is showing signs of stabilisation in many parts of the world and digital music, in all its forms, continues to develop at a rapid pace,\" he said.\n",
      "\n",
      "Commenting on the delay to the release of the Coldplay and Gorillaz albums, Mr Levy said that \"creating and marketing music is not an exact science and cannot always coincide with our reporting periods\". \"While this rescheduling and recent softness is disappointing, it does not change my views of the improving health of the global recorded music industry,\" he added. Paul Richards, an analyst at Numis Securities, said the market would be focusing on the slump in music sales rather than the timing of the two albums. \"It's unusual to see this much of a downgrade just because of phasing,\" he said.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "EMI said music sales for the year to March will fall 8-9% from the year before, with profits set to be 15% lower than analysts had expected.Shares in music giant EMI have sunk by more than 16% after the firm issued a profit warning following disappointing sales and delays to two album releases.EMI said two major albums scheduled for release before the end of the financial year in March - one by Coldplay and one by Gorillaz - have now had their release dates put back.\"Therefore, for the full year, at constant currency, EMI Music's sales are now expected to be 8% to 9% lower than the prior year.\"The company said it expected profits to be about ¬£138m ($259.8m).Commenting on the delay to the release of the Coldplay and Gorillaz albums, Mr Levy said that \"creating and marketing music is not an exact science and cannot always coincide with our reporting periods\".EMI said music sales for the year to March will fall 8-9% from the year before, with profits set to be 15% lower than analysts had expected.Paul Richards, an analyst at Numis Securities, said the market would be focusing on the slump in music sales rather than the timing of the two albums.EMI said two major albums scheduled for release before the end of the financial year in March - one by Coldplay and one by Gorillaz - have now had their release dates put back.\n",
      "\n",
      "--- Sample 4 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "Honda wins China copyright ruling\n",
      "\n",
      "Japan's Honda has won a copyright case in Beijing, further evidence that China is taking a tougher line on protecting intellectual property rights.\n",
      "\n",
      "A court ruled that Chongqing Lifan Industry Group must stop selling Honda brand motorbikes and said it must pay 1.47m yuan ($177,600) in compensation. Internationally recognized regulation is now a key part of China's plans for developing its economy, analysts said. Beijing also has been threatened with sanctions if it fails to clamp down.\n",
      "\n",
      "Chinese firms copy products ranging from computer software and spark plugs to baby milk and compact discs. Despite the fact that product piracy is a major problem, foreign companies have only occasionally won cases and the compensation awarded has usually been small. Still, recent rulings and announcements will have boosted optimism that attitudes are changing. Earlier this week China said that in future it will punish violators of intellectual property rights with up to seven years in jail. And on Tuesday, Paws Incorporated - the owner of the rights to Garfield the cat - won a court battle against a publishing house that violated its copyright. Other firms that have taken legal action in China, with varying degrees of success, include Yamaha, General Motors and Toyota.\n",
      "\n",
      "The problem of piracy is not limited to China, however, and the potential for profit is huge. The European Union estimates that the global trade in pirated wares is worth more than 200bn euros a year (¬£140bn; $258bn), or about 5% of total world trade. And it is growing. Between 1998 and 2002, the number of counterfeit or pirated goods intercepted at the EU's external borders increased by more than 800%, it said. Last month the EU said it will start monitoring China, Ukraine and Russia to ensure they are going after pirated goods. Other countries on the EU's hit list include Thailand, Brazil, South Korea and Indonesia. Any countries that are not making enough of an effort could be dragged to the World Trade Organisation (WTO), a step that could trigger economic sanctions, the EU warned.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "Japan's Honda has won a copyright case in Beijing, further evidence that China is taking a tougher line on protecting intellectual property rights.Earlier this week China said that in future it will punish violators of intellectual property rights with up to seven years in jail.Last month the EU said it will start monitoring China, Ukraine and Russia to ensure they are going after pirated goods.Between 1998 and 2002, the number of counterfeit or pirated goods intercepted at the EU's external borders increased by more than 800%, it said.Despite the fact that product piracy is a major problem, foreign companies have only occasionally won cases and the compensation awarded has usually been small.The problem of piracy is not limited to China, however, and the potential for profit is huge.Other firms that have taken legal action in China, with varying degrees of success, include Yamaha, General Motors and Toyota.\n",
      "[Reference] Japan's Honda has won a copyright case in Beijing, further evidence that China is taking a tougher line on protecting intellectual property rights.Earlier this week China said that in future it will punish violators of intellectual property rights with up to seven years in jail.Last month the EU said it will start monitoring China, Ukraine and Russia to ensure they are going after pirated goods.Between 1998 and 2002, the number of counterfeit or pirated goods intercepted at the EU's external borders increased by more than 800%, it said.Despite the fact that product piracy is a major problem, foreign companies have only occasionally won cases and the compensation awarded has usually been small.The problem of piracy is not limited to China, however, and the potential for profit is huge.Other firms that have taken legal action in China, with varying degrees of success, include Yamaha, General Motors and Toyota.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "Honda wins China copyright ruling\n",
      "\n",
      "Japan's Honda has won a copyright case in Beijing, further evidence that China is taking a tougher line on protecting intellectual property rights.\n",
      "\n",
      "A court ruled that Chongqing Lifan Industry Group must stop selling Honda brand motorbikes and said it must pay 1.47m yuan ($177,600) in compensation. Internationally recognized regulation is now a key part of China's plans for developing its economy, analysts said. Beijing also has been threatened with sanctions if it fails to clamp down.\n",
      "\n",
      "Chinese firms copy products ranging from computer software and spark plugs to baby milk and compact discs. Despite the fact that product piracy is a major problem, foreign companies have only occasionally won cases and the compensation awarded has usually been small. Still, recent rulings and announcements will have boosted optimism that attitudes are changing. Earlier this week China said that in future it will punish violators of intellectual property rights with up to seven years in jail. And on Tuesday, Paws Incorporated - the owner of the rights to Garfield the cat - won a court battle against a publishing house that violated its copyright. Other firms that have taken legal action in China, with varying degrees of success, include Yamaha, General Motors and Toyota.\n",
      "\n",
      "The problem of piracy is not limited to China, however, and the potential for profit is huge. The European Union estimates that the global trade in pirated wares is worth more than 200bn euros a year (¬£140bn; $258bn), or about 5% of total world trade. And it is growing. Between 1998 and 2002, the number of counterfeit or pirated goods intercepted at the EU's external borders increased by more than 800%, it said. Last month the EU said it will start monitoring China, Ukraine and Russia to ensure they are going after pirated goods. Other countries on the EU's hit list include Thailand, Brazil, South Korea and Indonesia. Any countries that are not making enough of an effort could be dragged to the World Trade Organisation (WTO), a step that could trigger economic sanctions, the EU warned.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "Japan's Honda has won a copyright case in Beijing, further evidence that China is taking a tougher line on protecting intellectual property rights.Earlier this week China said that in future it will punish violators of intellectual property rights with up to seven years in jail.Last month the EU said it will start monitoring China, Ukraine and Russia to ensure they are going after pirated goods.Between 1998 and 2002, the number of counterfeit or pirated goods intercepted at the EU's external borders increased by more than 800%, it said.Despite the fact that product piracy is a major problem, foreign companies have only occasionally won cases and the compensation awarded has usually been small.The problem of piracy is not limited to China, however, and the potential for profit is huge.Other firms that have taken legal action in China, with varying degrees of success, include Yamaha, General Motors and Toyota. Still, recent rulings and announcements will have boosted optimism that attitudes are changing.A court ruled that Chongqing Lifan Industry Group must stop selling Honda brand motorbikes and said it must pay 1.47m yuan ($177,600) in compensation. And on Tuesday, Paws Incorporated - the owner of the rights to Garfield the cat - won a court battle against a publishing house that violated its copyright.\n",
      "\n",
      "--- Sample 5 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "No half measures with Half-Life 2\n",
      "\n",
      "Could Half-Life 2 possibly live up to the hype? After almost two years of tantalising previews and infuriating delays it's safe to say that this is the most highly-anticipated computer game of all time.\n",
      "\n",
      "Fortunately, it doesn't merely live up to its promise, but exceeds it. No-one who plays the finished product will wonder why it took so long. The impression is of a game that has been endlessly refined to get as close to perfection as could realistically be hoped. All the money - or indeed time - is on the screen. The player sees things through the eyes of Gordon Freeman, the bespectacled scientist who starred in the original 1998 Half-Life. Having survived that skirmish in an desolate monster-infested research facility, he's back in another foreboding troublespot - the enigmatic City 17. It has the look of a beautiful Eastern European city, but as soon as your train pulls in to the station, it's clear that all is not well here. Sinister police patrol the unkempt streets, and the oppressive atmosphere clobbers you like a sledgehammer. A casual smattering of the nightmarish creatures from the first game makes this an even less pleasant place to be.\n",
      "\n",
      "You are herded around like a prisoner and have to mingle with a few freedom-fighting civilians to gather information and progress in your task. It is not immediately explained what your objectives are, nor precisely why everything is so ravaged. Finding out step-by-step is all part of the experience, although you never fully get to understand what it was all about. That does not really matter. HL2 does not waste energy blinding you with plot. Underplaying the narrative in this way is gloriously effective, and immerses the player in the most vivid, convincing and impressive virtual world they are likely to have seen. There are no cut-scenes to interrupt the flow. Exposition is accomplished by other characters stopping to talk directly to you.\n",
      "\n",
      "Whereas the highly impressive Doom III felt like a top-notch theme park thrill-ride, wandering through Half-Life's world truly does feel like being part of a movie.\n",
      "\n",
      "Considering its sophistication, the game runs surprisingly well on computers that only just match the modest minimum specifications. But if ever there was an incentive to upgradeAt times Half-Life 2 feels like one of those annoying people who are unfeasibly brilliant at everything they turn their hand to, and in a curious way, its unrelenting goodness actually becomes almost tiresome.The game does have a couple of problems.Whereas the highly impressive Doom III felt like a top-notch theme park thrill-ride, wandering through Half-Life's world truly does feel like being part of a movie.The impression is of a game that has been endlessly refined to get as close to perfection as could realistically be hoped.Developer Valve has rashly assumed that everyone wanting to play the game will have an internet connection and it forces you to go online to authenticate your copy.After almost two years of tantalising previews and infuriating delays it's safe to say that this is the most highly-anticipated computer game of all time.The bar has been raised, and so far out of sight that you have to sympathise with any game that tries to do anything remotely similar in the near future.Could Half-Life 2 possibly live up to the hype?It has the look of a beautiful Eastern European city, but as soon as your train pulls in to the station, it's clear that all is not well here.The player sees things through the eyes of Gordon Freeman, the bespectacled scientist who starred in the original 1998 Half-Life.Considering its sophistication, the game runs surprisingly well on computers that only just match the modest minimum specifications.It would take a mighty piece of work to feel worthwhile after such annoyances - but luckily, Half-Life 2 is up to the challenge.The box does warn you of this anti-piracy measure, but does not say just how many components have to be downloaded.But the real downside is the hassle of getting the game to run.In gameplay terms, HL2 somehow gets almost everything perfect.Luckily you get time to pause mid-task and marvel at the awesome graphical flourishes of your surroundings.The time spent doing this will depend on your connection speed, the temperamental Valve servers and the time of day, but it can take hours.If you like things open-ended and free-ranging, Far Cry will be a lot more pleasing.A casual smattering of the nightmarish creatures from the first game makes this an even less pleasant place to be.Half-Life 2 is out now for the PCOn our test machine - an Alienware system with an Athlon 3500+ processor and ATI's Radeon X800 video card - everything ran at full quality without trouble, and the visual experience was simply jaw-dropping.\n",
      "[Reference] At times Half-Life 2 feels like one of those annoying people who are unfeasibly brilliant at everything they turn their hand to, and in a curious way, its unrelenting goodness actually becomes almost tiresome.The game does have a couple of problems.Whereas the highly impressive Doom III felt like a top-notch theme park thrill-ride, wandering through Half-Life's world truly does feel like being part of a movie.The impression is of a game that has been endlessly refined to get as close to perfection as could realistically be hoped.Developer Valve has rashly assumed that everyone wanting to play the game will have an internet connection and it forces you to go online to authenticate your copy.After almost two years of tantalising previews and infuriating delays it's safe to say that this is the most highly-anticipated computer game of all time.The bar has been raised, and so far out of sight that you have to sympathise with any game that tries to do anything remotely similar in the near future.Could Half-Life 2 possibly live up to the hype?It has the look of a beautiful Eastern European city, but as soon as your train pulls in to the station, it's clear that all is not well here.The player sees things through the eyes of Gordon Freeman, the bespectacled scientist who starred in the original 1998 Half-Life.Considering its sophistication, the game runs surprisingly well on computers that only just match the modest minimum specifications.It would take a mighty piece of work to feel worthwhile after such annoyances - but luckily, Half-Life 2 is up to the challenge.The box does warn you of this anti-piracy measure, but does not say just how many components have to be downloaded.But the real downside is the hassle of getting the game to run.In gameplay terms, HL2 somehow gets almost everything perfect.Luckily you get time to pause mid-task and marvel at the awesome graphical flourishes of your surroundings.The time spent doing this will depend on your connection speed, the temperamental Valve servers and the time of day, but it can take hours.If you like things open-ended and free-ranging, Far Cry will be a lot more pleasing.A casual smattering of the nightmarish creatures from the first game makes this an even less pleasant place to be.Half-Life 2 is out now for the PCOn our test machine - an Alienware system with an Athlon 3500+ processor and ATI's Radeon X800 video card - everything ran at full quality without trouble, and the visual experience was simply jaw-dropping.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "You are a helpful summarization assistant. Provide a concise and accurate summary of the article.\n",
      "user\n",
      "Summarize the following article:\n",
      "No half measures with Half-Life 2\n",
      "\n",
      "Could Half-Life 2 possibly live up to the hype? After almost two years of tantalising previews and infuriating delays it's safe to say that this is the most highly-anticipated computer game of all time.\n",
      "\n",
      "Fortunately, it doesn't merely live up to its promise, but exceeds it. No-one who plays the finished product will wonder why it took so long. The impression is of a game that has been endlessly refined to get as close to perfection as could realistically be hoped. All the money - or indeed time - is on the screen. The player sees things through the eyes of Gordon Freeman, the bespectacled scientist who starred in the original 1998 Half-Life. Having survived that skirmish in an desolate monster-infested research facility, he's back in another foreboding troublespot - the enigmatic City 17. It has the look of a beautiful Eastern European city, but as soon as your train pulls in to the station, it's clear that all is not well here. Sinister police patrol the unkempt streets, and the oppressive atmosphere clobbers you like a sledgehammer. A casual smattering of the nightmarish creatures from the first game makes this an even less pleasant place to be.\n",
      "\n",
      "You are herded around like a prisoner and have to mingle with a few freedom-fighting civilians to gather information and progress in your task. It is not immediately explained what your objectives are, nor precisely why everything is so ravaged. Finding out step-by-step is all part of the experience, although you never fully get to understand what it was all about. That does not really matter. HL2 does not waste energy blinding you with plot. Underplaying the narrative in this way is gloriously effective, and immerses the player in the most vivid, convincing and impressive virtual world they are likely to have seen. There are no cut-scenes to interrupt the flow. Exposition is accomplished by other characters stopping to talk directly to you.\n",
      "\n",
      "Whereas the highly impressive Doom III felt like a top-notch theme park thrill-ride, wandering through Half-Life's world truly does feel like being part of a movie.\n",
      "\n",
      "Considering its sophistication, the game runs surprisingly well on computers that only just match the modest minimum specifications. But if ever there was an incentive to upgradeAt times Half-Life 2 feels like one of those annoying people who are unfeasibly brilliant at everything they turn their hand to, and in a curious way, its unrelenting goodness actually becomes almost tiresome.The game does have a couple of problems.Whereas the highly impressive Doom III felt like a top-notch theme park thrill-ride, wandering through Half-Life's world truly does feel like being part of a movie.The impression is of a game that has been endlessly refined to get as close to perfection as could realistically be hoped.Developer Valve has rashly assumed that everyone wanting to play the game will have an internet connection and it forces you to go online to authenticate your copy.After almost two years of tantalising previews and infuriating delays it's safe to say that this is the most highly-anticipated computer game of all time.The bar has been raised, and so far out of sight that you have to sympathise with any game that tries to do anything remotely similar in the near future.Could Half-Life 2 possibly live up to the hype?It has the look of a beautiful Eastern European city, but as soon as your train pulls in to the station, it's clear that all is not well here.The player sees things through the eyes of Gordon Freeman, the bespectacled scientist who starred in the original 1998 Half-Life.Considering its sophistication, the game runs surprisingly well on computers that only just match the modest minimum specifications.It would take a mighty piece of work to feel worthwhile after such annoyances - but luckily, Half-Life 2 is up to the challenge.The box does warn you of this anti-piracy measure, but does not say just how many components have to be downloaded.But the real downside is the hassle of getting the game to run.In gameplay terms, HL2 somehow gets almost everything perfect.Luckily you get time to pause mid-task and marvel at the awesome graphical flourishes of your surroundings.The time spent doing this will depend on your connection speed, the temperamental Valve servers and the time of day, but it can take hours.If you like things open-ended and free-ranging, Far Cry will be a lot more pleasing.A casual smattering of the nightmarish creatures from the first game makes this an even less pleasant place to be.Half-Life 2 is out now for the PCOn our test machine - an Alienware system with an Athlon 3500+ processor and ATI's Radeon X800 video card - everything ran at full quality without trouble, and the visual experience was simply jaw-dropping.HL2 does not waste energy blinding you with plot.The game does have a couple of problems.Whereas the highly impressive Doom III felt like a top-notch theme park thrill-ride, wandering through Half-Life's world truly does feel like being part of a movie.Developer Valve has rashly assumed that everyone wanting to play the game will have an internet connection and it forces you to go online to authenticate your copy.After almost two years of tantalising previews and infuriating delays it's safe to say that this is the most highly-anticipated computer game of all time.The bar has been raised, and so far out of sight that you have to\n"
     ]
    }
   ],
   "source": [
    "evaluate_after_training(model, val_loader, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-25T02:11:20.443225Z",
     "iopub.status.idle": "2025-03-25T02:11:20.443635Z",
     "shell.execute_reply": "2025-03-25T02:11:20.443450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C·∫•u h√¨nh quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "# Load config PEFT\n",
    "adapter_dir = \"/kaggle/working/llama3-qlora-finetuned\"\n",
    "peft_config = PeftConfig.from_pretrained(adapter_dir)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load m√¥ h√¨nh g·ªëc v√† g·∫Øn adapter\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, adapter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T06:50:09.592831Z",
     "iopub.status.busy": "2025-03-25T06:50:09.592467Z",
     "iopub.status.idle": "2025-03-25T06:50:09.948834Z",
     "shell.execute_reply": "2025-03-25T06:50:09.948124Z",
     "shell.execute_reply.started": "2025-03-25T06:50:09.592806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551ff79ee89143619145cf8c0d0c04af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"/kaggle/input/data-llama-finetune/vi_data_llama_finetune.json\"\n",
    "\n",
    "full_dataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n",
    "dataset = full_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T06:50:12.772525Z",
     "iopub.status.busy": "2025-03-25T06:50:12.772245Z",
     "iopub.status.idle": "2025-03-25T06:50:13.718793Z",
     "shell.execute_reply": "2025-03-25T06:50:13.717854Z",
     "shell.execute_reply.started": "2025-03-25T06:50:12.772505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477903fa38ad46eca7d5b89fcd5af96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e4331c2cc741429cd5d821f89449dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(example, max_length=1024):\n",
    "    # T·∫°o chu·ªói input theo ƒë·ªãnh d·∫°ng:\n",
    "    # \"### Prompt:\\n<prompt>\\n\\n### Summary:\\n\" + summary\n",
    "    prompt = f\"### Prompt:\\n{example['prompt']}\\n\\n### Summary:\\n\"\n",
    "    summary = example[\"summary\"]\n",
    "    \n",
    "    # M√£ h√≥a ri√™ng prompt v√† summary (kh√¥ng th√™m special tokens)\n",
    "    prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    summary_ids = tokenizer.encode(summary, add_special_tokens=False)\n",
    "    \n",
    "    # Ki·ªÉm tra t·ªïng s·ªë token\n",
    "    total_length = len(prompt_ids) + len(summary_ids)\n",
    "    if total_length > max_length:\n",
    "        overflow = total_length - max_length\n",
    "        # ∆Øu ti√™n gi·ªØ l·∫°i ph·∫ßn summary; c·∫Øt b·ªõt prompt\n",
    "        if overflow < len(prompt_ids):\n",
    "            prompt_ids = prompt_ids[:-overflow]\n",
    "        else:\n",
    "            prompt_ids = []  # N·∫øu qu√° tr√†n, b·ªè h·∫øt prompt\n",
    "    \n",
    "    # N·ªëi prompt v√† summary\n",
    "    input_ids = prompt_ids + summary_ids\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    \n",
    "    # T·∫°o labels: ph·∫ßn prompt ƒë∆∞·ª£c mask b·∫±ng -100, ph·∫ßn summary gi·ªØ nguy√™n token IDs\n",
    "    labels = [-100] * len(prompt_ids) + summary_ids\n",
    "    \n",
    "    # Padding t·∫•t c·∫£ c√°c tr∆∞·ªùng v·ªÅ ƒë·ªô d√†i max_length\n",
    "    padding_length = max_length - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "        attention_mask = attention_mask + [0] * padding_length\n",
    "        labels = labels + [-100] * padding_length\n",
    "    else:\n",
    "        # N·∫øu qu√° d√†i, c·∫Øt b·ªõt (n√™n kh√¥ng x·∫£y ra nh·ªù truncation ·ªü tr√™n)\n",
    "        input_ids = input_ids[:max_length]\n",
    "        attention_mask = attention_mask[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "tokenized_dataset = dataset.map(tokenize, batched=False, fn_kwargs={\"max_length\": 1024})\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "collator = default_data_collator\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T06:50:28.366697Z",
     "iopub.status.busy": "2025-03-25T06:50:28.366359Z",
     "iopub.status.idle": "2025-03-25T06:50:28.383582Z",
     "shell.execute_reply": "2025-03-25T06:50:28.382765Z",
     "shell.execute_reply.started": "2025-03-25T06:50:28.366669Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T06:51:02.440793Z",
     "iopub.status.busy": "2025-03-25T06:51:02.440323Z",
     "iopub.status.idle": "2025-03-25T07:08:20.440857Z",
     "shell.execute_reply": "2025-03-25T07:08:20.439970Z",
     "shell.execute_reply.started": "2025-03-25T06:51:02.440758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4241: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [05:46<00:00,  9.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 1 completed ‚Äî Avg loss: 0.8198\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6029: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [05:45<00:00,  9.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 2 completed ‚Äî Avg loss: 0.7560\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5810: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [05:45<00:00,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 3 completed ‚Äî Avg loss: 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in pbar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"‚úÖ Epoch {epoch+1} completed ‚Äî Avg loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:08:33.667543Z",
     "iopub.status.busy": "2025-03-25T07:08:33.667223Z",
     "iopub.status.idle": "2025-03-25T07:08:34.214209Z",
     "shell.execute_reply": "2025-03-25T07:08:34.213446Z",
     "shell.execute_reply.started": "2025-03-25T07:08:33.667517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finetuned model saved at: /kaggle/working/llama3-qlora-finetuned-all\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/kaggle/working/llama3-qlora-finetuned-all\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"‚úÖ Finetuned model saved at:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:08:36.821632Z",
     "iopub.status.busy": "2025-03-25T07:08:36.821301Z",
     "iopub.status.idle": "2025-03-25T07:08:36.829313Z",
     "shell.execute_reply": "2025-03-25T07:08:36.828461Z",
     "shell.execute_reply.started": "2025-03-25T07:08:36.821605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_after_training(model, val_loader, tokenizer, device, num_samples=5):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    samples_to_print = []\n",
    "\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Sinh vƒÉn b·∫£n\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens=128,\n",
    "                num_beams=4,\n",
    "                do_sample=False\n",
    "            )\n",
    "\n",
    "            # Gi·∫£i m√£\n",
    "            generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            label_texts = []\n",
    "            for label in labels:\n",
    "                label_ids = [token_id for token_id in label.tolist() if token_id != -100]\n",
    "                label_texts.append(tokenizer.decode(label_ids, skip_special_tokens=True))\n",
    "\n",
    "            predictions.extend(generated_texts)\n",
    "            references.extend(label_texts)\n",
    "\n",
    "            # In ra v√≠ d·ª•\n",
    "            if len(samples_to_print) < num_samples:\n",
    "                for src, ref, pred in zip(tokenizer.batch_decode(input_ids, skip_special_tokens=True), label_texts, generated_texts):\n",
    "                    samples_to_print.append((src, ref, pred))\n",
    "                    if len(samples_to_print) >= num_samples:\n",
    "                        break\n",
    "\n",
    "    # T√≠nh ROUGE\n",
    "    results = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "\n",
    "    print(\"\\nüìä ROUGE Scores:\")\n",
    "    for key in results:\n",
    "        print(f\"{key}: {results[key]:.4f}\")\n",
    "\n",
    "    print(\"\\nüìù Sample Results:\")\n",
    "    for i, (src, ref, pred) in enumerate(samples_to_print):\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        print(f\"[Prompt]    {src}\")\n",
    "        print(f\"[Reference] {ref}\")\n",
    "        print(f\"[Generated] {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:08:59.621188Z",
     "iopub.status.busy": "2025-03-25T07:08:59.620851Z",
     "iopub.status.idle": "2025-03-25T07:11:37.091939Z",
     "shell.execute_reply": "2025-03-25T07:11:37.091073Z",
     "shell.execute_reply.started": "2025-03-25T07:08:59.621158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Evaluating:  20%|‚ñà‚ñà        | 1/5 [00:34<02:17, 34.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [01:08<01:43, 34.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [01:42<01:08, 34.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Evaluating:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [02:17<00:34, 34.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:33<00:00, 30.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä ROUGE Scores:\n",
      "rouge1: 0.2803\n",
      "rouge2: 0.2793\n",
      "rougeL: 0.2804\n",
      "rougeLsum: 0.2803\n",
      "\n",
      "üìù Sample Results:\n",
      "\n",
      "--- Sample 1 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøHaÃÉi huÃÄng nhiÃÄn \"ch·∫°ch l∆∞∆°n\" ∆°Ãâ ƒëi√™Ãâm noÃÅng tai n·∫°n th·∫£m kh·ªëc\n",
      "H√¨nh ·∫£nh PV D√¢n tr√≠ ghi l·∫°i d∆∞·ªõi ƒë√¢y lyÃÅ gi·∫£i v√¨ sao qu·ªëc l·ªô 1A ƒëo·∫°n qua ƒë·ªãa b√†n huy·ªán K·ª≥ Anh (H√† Tƒ©nh) biÃ£ xem l√† cung ƒë∆∞∆°ÃÄng xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc nh·∫•t tr√™n c·∫£ n∆∞·ªõc.\n",
      "Nhi·ªÅu th√°ng qua, gi·ªõi t√†i x·∫ø v√† ng∆∞·ªùi d√¢n th∆∞·ªùng xuy√™n qua l·∫°i tuy·∫øn qu·ªëc l·ªô 1A ƒëo·∫°n qua huy·ªán K·ª≥ Anh - m·ªôt trong nh·ªØng ƒë·ªãa b√†n xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc -lu√¥n n∆°m n·ªõp lo s·ª£ tai n·∫°n b·∫•t ng·ªù ·∫≠p ƒë·∫øn. Nguy√™n nh√¢n do ƒëoaÃ£n ƒë∆∞∆°ÃÄng n√†y ƒëaÃÉ xu·ªëng c·∫•p tr·∫ßm tr·ªçng.\n",
      "C√≥ m·∫∑t tr√™n tuy·∫øn ƒë∆∞·ªùng n√†y ch√∫ng t√¥i kh√¥ng kh·ªèi gi·∫≠t m√¨nh tr∆∞·ªõc th·∫£m tr·∫°ng, nhi·ªÅu ƒëo·∫°n m·∫∑t ƒë∆∞·ªùng b·ªã l√∫n s√¢u t·∫°o th√†nh v√¥ s·ªë \"con ch·∫°ch\", n·∫±m ch√¨nh √¨nh tr·ªü th√†nh nh·ªØng c√°i b·∫´y h·∫øt s·ª©c nguy hi·ªÉm. ƒê·∫øn ƒëo·∫°n ƒë∆∞·ªùng n√†y, h·∫ßu h·∫øt c√°c t√†i x·∫ø ph·∫£i gi·∫£m t·ªëc ƒë·ªô ƒë·∫øn m·ª©c th·∫•p nh·∫•t v√† b·∫•t ƒë·∫Øc dƒ© ƒë·ªÉ cho xe ch·∫°y theo l·∫±n ƒë∆∞·ªùng l√∫n s·ª•t. V∆°ÃÅi nh·ªØng xe g·∫ßm th·∫•p, t√†i x·∫ø bu·ªôc ph·∫£i cho xe ch·∫°y tr√™n hai \"con l∆∞∆°n\" song song ƒë·ªÉ tr√°nh va qu·ªát g√¢ÃÄm v·ªõi m·∫∑t ƒë∆∞·ªùng g·ªì gh·ªÅ.\n",
      "Anh B√πi Xu√¢n Lu·∫≠n (B√¨nh ƒê·ªãnh), t√†i x·∫ø ƒëang d·ª´ng xe, nh∆∞·ªùng ƒë∆∞·ªùng cho m·ªôt chi·∫øc xe t·∫£i tr·ªçng l·ªõn ch·∫°y ng∆∞·ª£c chi·ªÅu ƒëi qua ƒëi·ªÉm ƒë∆∞·ªùng xu·ªëng c·∫•p nh·∫•t t·∫°i x√£ K·ª≥ Th·ªãnh, kh√¥ng gi·∫•u n·ªói b∆∞ÃÅc xuÃÅc: ‚Äúƒê∆∞·ªùng s√° th·∫ø n√†y qu√° nguy hi·ªÉm, kh√¥ng c·∫©n th·∫≠n l√† tai n·∫°n ngay. C·ª© m·ªói l·∫ßn qua K·ª≥ Anh l√† c√°nh t√†i x·∫ø ch√∫ng t√¥i c·ª© n∆°m n·ªõp lo tai n·∫°n‚Äù.\n",
      "Nhi·ªÅu ng∆∞·ªùi d√¢n s·ªëng t·∫°i cung ƒë∆∞·ªùng xu·ªëng c·∫•p n√†y ph·∫£n √°nh, th·ª±c tr·∫°ng qu·ªëc l·ªô 1A xu·ªëng c·∫•p ƒë√£ xaÃây ra nhi·ªÅu nƒÉm nay, l√† m·ªôt trong nh·ªØng nguy√™n nh√¢n d·∫´n ƒë·∫øn c√°c v·ª• tai n·∫°n l·ªõn nh·ªè tr√™n ƒë·ªãa b√†n. ƒê√£ c√≥ nhi·ªÅu v·ª• t√†i x·∫ø, ng∆∞·ªùi d√¢n v√¨ kh√¥ng nh∆∞·ªùng ƒë∆∞·ªùng, va qu·ªát ƒë√£ d·∫´n ƒë·∫øn ·∫©u ƒëaÃâ.\n",
      "Sau khi ƒëi th·ª±c t·∫ø cung ƒë∆∞·ªùng l·∫Øm ‚Äúl∆∞∆°n, ch·∫°ch‚Äù nguy hi·ªÉm n√†y, PV D√¢n tr√≠ƒë√£ c√≥ bu·ªïi l√†m vi·ªác v·ªõi √¥ng L√™ Ng·ªçc Minh ‚Äì Ph√≥ T·ªïng gi√°m ƒë·ªëc Khu qu·∫£n l√Ω ƒë∆∞·ªùng b·ªô IV, ƒë∆°n v·ªã ch·ªãu tr√°ch nhi·ªám qu·∫£n l√Ω, duy tu, b·∫£o d∆∞·ª°ng tuy·∫øn qu·ªëc l·ªô 1A khu v·ª±c B·∫Øc mi·ªÅn Trung. Theo √¥ng Minh, nguy√™n nh√¢n khi·∫øn ƒëoaÃ£n qu·ªëc l·ªô 1A naÃÄy xu·ªëng c·∫•p l√† do t·∫ßn su·∫•t, l∆∞u l∆∞·ª£ng xe qu√° t·∫£i l∆∞u th√¥ng nhi√™ÃÄu. ‚Äúƒê√¢y l√† ƒë·ªãa b√†n c√≥ khu c√¥ng nghi·ªáp V≈©ng √Ång. Ngo√†i xe t·∫£i tr·ªçng l·ªõn B·∫Øc Nam, xe v·∫≠n t·∫£i ph·ª•c v·ª• x√¢y d·ª±ng khu c√¥ng nghi·ªáp V≈©ng √Ång ƒë√£ \"g√≥p ph·∫ßn\" khi·∫øn qu·ªëc l·ªô 1A xu·ªëng c·∫•p‚Äù- √¥ng Minh n√≥i.\n",
      "√îng Minh cho bi·∫øt, Khu qu·∫£n l√Ω ƒë∆∞·ªùng b·ªô IV ƒë√£ nhi·ªÅu l·∫ßn c√≥ vƒÉn b·∫£n, th·∫≠m ch√≠ c√° nh√¢n √¥ng ƒë√£ t·ª´ng nh·∫Øn tin cho Ch·ªß t·ªãch UBND t·ªânh H√† Tƒ©nh V√µ Kim C·ª± ƒë·ªÉ ‚Äúc·∫ßu c·ª©u‚Äù, chung tay ngƒÉn ch·∫∑n t√¨nh tr·∫°ng xe qu√° t·∫£i ph√° n√°t ƒë∆∞·ªùng, nh∆∞ng tiÃÄnh hiÃÄnh kh√¥ng thay ƒë√¥Ãâi.\n",
      "√îng Minh c≈©ng cho bi·∫øt, vi·ªác duy tu, s·ª≠a ch·ªØa tuy·∫øn qu·ªëc l·ªô 1A v√† nhi·ªÅu tuy·∫øn qu·ªëc l·ªô kh√°c tr√™n ƒë·ªãa b√†n l√† tr√°ch nhi·ªám c·ªßa Khu qu·∫£n l√Ω ƒë∆∞·ªùng b·ªô IV, nh∆∞ng n·∫øu t√¨nh tr·∫°ng xe qu√° t·∫£i ch∆∞a ƒë∆∞·ª£c ngƒÉn ch·∫∑n th√¨ s·ª≠a xong ƒë∆∞∆°ÃÄng l·∫°i h·ªèng.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "ÔªøNhi·ªÅu th√°ng qua, gi·ªõi t√†i x·∫ø v√† ng∆∞·ªùi d√¢n th∆∞·ªùng xuy√™n qua l·∫°i tuy·∫øn qu·ªëc l·ªô 1A ƒëo·∫°n qua huy·ªán K·ª≥ Anh - m·ªôt trong nh·ªØng ƒë·ªãa b√†n xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc -lu√¥n n∆°m n·ªõp lo s·ª£ tai n·∫°n b·∫•t ng·ªù ·∫≠p ƒë·∫øn. Nguy√™n nh√¢n do ƒëoaÃ£n ƒë∆∞∆°ÃÄng n√†y ƒëaÃÉ xu·ªëng c·∫•p tr·∫ßm tr·ªçng.Nhi·ªÅu ƒëo·∫°n m·∫∑t ƒë∆∞·ªùng b·ªã l√∫n s√¢u t·∫°o th√†nh v√¥ s·ªë \"con ch·∫°ch\", n·∫±m ch√¨nh √¨nh tr·ªü th√†nh nh·ªØng c√°i b·∫´y h·∫øt s·ª©c nguy hi·ªÉm.Tth·ª±c tr·∫°ng qu·ªëc l·ªô 1A xu·ªëng c·∫•p ƒë√£ xaÃây ra nhi·ªÅu nƒÉm nay, l√† m·ªôt trong nh·ªØng nguy√™n nh√¢n d·∫´n ƒë·∫øn c√°c v·ª• tai n·∫°n l·ªõn nh·ªè tr√™n ƒë·ªãa b√†n.\n",
      "[Reference] ÔªøNhi·ªÅu th√°ng qua, gi·ªõi t√†i x·∫ø v√† ng∆∞·ªùi d√¢n th∆∞·ªùng xuy√™n qua l·∫°i tuy·∫øn qu·ªëc l·ªô 1A ƒëo·∫°n qua huy·ªán K·ª≥ Anh - m·ªôt trong nh·ªØng ƒë·ªãa b√†n xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc -lu√¥n n∆°m n·ªõp lo s·ª£ tai n·∫°n b·∫•t ng·ªù ·∫≠p ƒë·∫øn. Nguy√™n nh√¢n do ƒëoaÃ£n ƒë∆∞∆°ÃÄng n√†y ƒëaÃÉ xu·ªëng c·∫•p tr·∫ßm tr·ªçng.Nhi·ªÅu ƒëo·∫°n m·∫∑t ƒë∆∞·ªùng b·ªã l√∫n s√¢u t·∫°o th√†nh v√¥ s·ªë \"con ch·∫°ch\", n·∫±m ch√¨nh √¨nh tr·ªü th√†nh nh·ªØng c√°i b·∫´y h·∫øt s·ª©c nguy hi·ªÉm.Tth·ª±c tr·∫°ng qu·ªëc l·ªô 1A xu·ªëng c·∫•p ƒë√£ xaÃây ra nhi·ªÅu nƒÉm nay, l√† m·ªôt trong nh·ªØng nguy√™n nh√¢n d·∫´n ƒë·∫øn c√°c v·ª• tai n·∫°n l·ªõn nh·ªè tr√™n ƒë·ªãa b√†n.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøHaÃÉi huÃÄng nhiÃÄn \"ch·∫°ch l∆∞∆°n\" ∆°Ãâ ƒëi√™Ãâm noÃÅng tai n·∫°n th·∫£m kh·ªëc\n",
      "H√¨nh ·∫£nh PV D√¢n tr√≠ ghi l·∫°i d∆∞·ªõi ƒë√¢y lyÃÅ gi·∫£i v√¨ sao qu·ªëc l·ªô 1A ƒëo·∫°n qua ƒë·ªãa b√†n huy·ªán K·ª≥ Anh (H√† Tƒ©nh) biÃ£ xem l√† cung ƒë∆∞∆°ÃÄng xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc nh·∫•t tr√™n c·∫£ n∆∞·ªõc.\n",
      "Nhi·ªÅu th√°ng qua, gi·ªõi t√†i x·∫ø v√† ng∆∞·ªùi d√¢n th∆∞·ªùng xuy√™n qua l·∫°i tuy·∫øn qu·ªëc l·ªô 1A ƒëo·∫°n qua huy·ªán K·ª≥ Anh - m·ªôt trong nh·ªØng ƒë·ªãa b√†n xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc -lu√¥n n∆°m n·ªõp lo s·ª£ tai n·∫°n b·∫•t ng·ªù ·∫≠p ƒë·∫øn. Nguy√™n nh√¢n do ƒëoaÃ£n ƒë∆∞∆°ÃÄng n√†y ƒëaÃÉ xu·ªëng c·∫•p tr·∫ßm tr·ªçng.\n",
      "C√≥ m·∫∑t tr√™n tuy·∫øn ƒë∆∞·ªùng n√†y ch√∫ng t√¥i kh√¥ng kh·ªèi gi·∫≠t m√¨nh tr∆∞·ªõc th·∫£m tr·∫°ng, nhi·ªÅu ƒëo·∫°n m·∫∑t ƒë∆∞·ªùng b·ªã l√∫n s√¢u t·∫°o th√†nh v√¥ s·ªë \"con ch·∫°ch\", n·∫±m ch√¨nh √¨nh tr·ªü th√†nh nh·ªØng c√°i b·∫´y h·∫øt s·ª©c nguy hi·ªÉm. ƒê·∫øn ƒëo·∫°n ƒë∆∞·ªùng n√†y, h·∫ßu h·∫øt c√°c t√†i x·∫ø ph·∫£i gi·∫£m t·ªëc ƒë·ªô ƒë·∫øn m·ª©c th·∫•p nh·∫•t v√† b·∫•t ƒë·∫Øc dƒ© ƒë·ªÉ cho xe ch·∫°y theo l·∫±n ƒë∆∞·ªùng l√∫n s·ª•t. V∆°ÃÅi nh·ªØng xe g·∫ßm th·∫•p, t√†i x·∫ø bu·ªôc ph·∫£i cho xe ch·∫°y tr√™n hai \"con l∆∞∆°n\" song song ƒë·ªÉ tr√°nh va qu·ªát g√¢ÃÄm v·ªõi m·∫∑t ƒë∆∞·ªùng g·ªì gh·ªÅ.\n",
      "Anh B√πi Xu√¢n Lu·∫≠n (B√¨nh ƒê·ªãnh), t√†i x·∫ø ƒëang d·ª´ng xe, nh∆∞·ªùng ƒë∆∞·ªùng cho m·ªôt chi·∫øc xe t·∫£i tr·ªçng l·ªõn ch·∫°y ng∆∞·ª£c chi·ªÅu ƒëi qua ƒëi·ªÉm ƒë∆∞·ªùng xu·ªëng c·∫•p nh·∫•t t·∫°i x√£ K·ª≥ Th·ªãnh, kh√¥ng gi·∫•u n·ªói b∆∞ÃÅc xuÃÅc: ‚Äúƒê∆∞·ªùng s√° th·∫ø n√†y qu√° nguy hi·ªÉm, kh√¥ng c·∫©n th·∫≠n l√† tai n·∫°n ngay. C·ª© m·ªói l·∫ßn qua K·ª≥ Anh l√† c√°nh t√†i x·∫ø ch√∫ng t√¥i c·ª© n∆°m n·ªõp lo tai n·∫°n‚Äù.\n",
      "Nhi·ªÅu ng∆∞·ªùi d√¢n s·ªëng t·∫°i cung ƒë∆∞·ªùng xu·ªëng c·∫•p n√†y ph·∫£n √°nh, th·ª±c tr·∫°ng qu·ªëc l·ªô 1A xu·ªëng c·∫•p ƒë√£ xaÃây ra nhi·ªÅu nƒÉm nay, l√† m·ªôt trong nh·ªØng nguy√™n nh√¢n d·∫´n ƒë·∫øn c√°c v·ª• tai n·∫°n l·ªõn nh·ªè tr√™n ƒë·ªãa b√†n. ƒê√£ c√≥ nhi·ªÅu v·ª• t√†i x·∫ø, ng∆∞·ªùi d√¢n v√¨ kh√¥ng nh∆∞·ªùng ƒë∆∞·ªùng, va qu·ªát ƒë√£ d·∫´n ƒë·∫øn ·∫©u ƒëaÃâ.\n",
      "Sau khi ƒëi th·ª±c t·∫ø cung ƒë∆∞·ªùng l·∫Øm ‚Äúl∆∞∆°n, ch·∫°ch‚Äù nguy hi·ªÉm n√†y, PV D√¢n tr√≠ƒë√£ c√≥ bu·ªïi l√†m vi·ªác v·ªõi √¥ng L√™ Ng·ªçc Minh ‚Äì Ph√≥ T·ªïng gi√°m ƒë·ªëc Khu qu·∫£n l√Ω ƒë∆∞·ªùng b·ªô IV, ƒë∆°n v·ªã ch·ªãu tr√°ch nhi·ªám qu·∫£n l√Ω, duy tu, b·∫£o d∆∞·ª°ng tuy·∫øn qu·ªëc l·ªô 1A khu v·ª±c B·∫Øc mi·ªÅn Trung. Theo √¥ng Minh, nguy√™n nh√¢n khi·∫øn ƒëoaÃ£n qu·ªëc l·ªô 1A naÃÄy xu·ªëng c·∫•p l√† do t·∫ßn su·∫•t, l∆∞u l∆∞·ª£ng xe qu√° t·∫£i l∆∞u th√¥ng nhi√™ÃÄu. ‚Äúƒê√¢y l√† ƒë·ªãa b√†n c√≥ khu c√¥ng nghi·ªáp V≈©ng √Ång. Ngo√†i xe t·∫£i tr·ªçng l·ªõn B·∫Øc Nam, xe v·∫≠n t·∫£i ph·ª•c v·ª• x√¢y d·ª±ng khu c√¥ng nghi·ªáp V≈©ng √Ång ƒë√£ \"g√≥p ph·∫ßn\" khi·∫øn qu·ªëc l·ªô 1A xu·ªëng c·∫•p‚Äù- √¥ng Minh n√≥i.\n",
      "√îng Minh cho bi·∫øt, Khu qu·∫£n l√Ω ƒë∆∞·ªùng b·ªô IV ƒë√£ nhi·ªÅu l·∫ßn c√≥ vƒÉn b·∫£n, th·∫≠m ch√≠ c√° nh√¢n √¥ng ƒë√£ t·ª´ng nh·∫Øn tin cho Ch·ªß t·ªãch UBND t·ªânh H√† Tƒ©nh V√µ Kim C·ª± ƒë·ªÉ ‚Äúc·∫ßu c·ª©u‚Äù, chung tay ngƒÉn ch·∫∑n t√¨nh tr·∫°ng xe qu√° t·∫£i ph√° n√°t ƒë∆∞·ªùng, nh∆∞ng tiÃÄnh hiÃÄnh kh√¥ng thay ƒë√¥Ãâi.\n",
      "√îng Minh c≈©ng cho bi·∫øt, vi·ªác duy tu, s·ª≠a ch·ªØa tuy·∫øn qu·ªëc l·ªô 1A v√† nhi·ªÅu tuy·∫øn qu·ªëc l·ªô kh√°c tr√™n ƒë·ªãa b√†n l√† tr√°ch nhi·ªám c·ªßa Khu qu·∫£n l√Ω ƒë∆∞·ªùng b·ªô IV, nh∆∞ng n·∫øu t√¨nh tr·∫°ng xe qu√° t·∫£i ch∆∞a ƒë∆∞·ª£c ngƒÉn ch·∫∑n th√¨ s·ª≠a xong ƒë∆∞∆°ÃÄng l·∫°i h·ªèng.\n",
      "assistant\n",
      "\n",
      "\n",
      "### Summary:\n",
      "ÔªøNhi·ªÅu th√°ng qua, gi·ªõi t√†i x·∫ø v√† ng∆∞·ªùi d√¢n th∆∞·ªùng xuy√™n qua l·∫°i tuy·∫øn qu·ªëc l·ªô 1A ƒëo·∫°n qua huy·ªán K·ª≥ Anh - m·ªôt trong nh·ªØng ƒë·ªãa b√†n xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc -lu√¥n n∆°m n·ªõp lo s·ª£ tai n·∫°n b·∫•t ng·ªù ·∫≠p ƒë·∫øn. Nguy√™n nh√¢n do ƒëoaÃ£n ƒë∆∞∆°ÃÄng n√†y ƒëaÃÉ xu·ªëng c·∫•p tr·∫ßm tr·ªçng.Nhi·ªÅu ƒëo·∫°n m·∫∑t ƒë∆∞·ªùng b·ªã l√∫n s√¢u t·∫°o th√†nh v√¥ s·ªë \"con ch·∫°ch\", n·∫±m ch√¨nh √¨nh tr·ªü th√†nh nh·ªØng c√°i b·∫´y h·∫øt s·ª©c nguy hi·ªÉm.Tth·ª±c tr·∫°ng qu·ªëc l·ªô 1A xu·ªëng c·∫•p ƒë√£ xaÃây ra nhi·ªÅu nƒÉm nay, l√† m·ªôt trong nh·ªØng nguy√™n nh√¢n d·∫´n ƒë·∫øn c√°c v·ª• tai n·∫°n l·ªõn nh·ªè tr√™n ƒë·ªãa b√†n.Question: What is the purpose of this article?Answer: The purpose of this article is to provide a t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.H√¨nh ·∫£nh PV D√¢n tr√≠ ghi l·∫°i d∆∞·ªõi ƒë√¢y lyÃÅ gi·∫£i v√¨ sao qu·ªëc l·ªô 1A ƒëo·∫°n qua ƒë·ªãa b√†n huy·ªán K·ª≥ Anh (H√† Tƒ©nh) biÃ£ xem l√† cung ƒë∆∞∆°ÃÄng xaÃây ra nhi·ªÅu v·ª• tai n·∫°n th·∫£m kh·ªëc nh·∫•t tr√™n c·∫£ n∆∞·ªõc.Anh B√πi Xu√¢n Lu·∫≠n (B√¨nh ƒê·ªãnh), t√†i x·∫ø ƒëang d·ª´ng xe, nh∆∞·ªùng ƒë∆∞·ªùng cho m·ªôt chi·∫øc xe t·∫£i tr·ªçng l·ªõn ch·∫°y ng∆∞·ª£c chi·ªÅu ƒëi qua ƒëi·ªÉm ƒë∆∞·ªùng\n",
      "\n",
      "--- Sample 2 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøCh·ªß t·ªãch Hanoimilk b·ªã c·ªï ƒë√¥ng 'truy' chuy·ªán l∆∞∆°ng th∆∞·ªüng\n",
      "Ch·ªâ ho√†n th√†nh g·∫ßn 40% k·∫ø ho·∫°ch, l√£i sau thu·∫ø ch∆∞a ƒë·ªß b√π l·ªó l≈©y k·∫ø... n√™n m·ª©c l∆∞∆°ng 50 tri·ªáu ƒë·ªìng m·ªôt th√°ng c·ªßa Ch·ªß t·ªãch Hanoimilk - H√† Quang Tu·∫•n khi·∫øn nhi·ªÅu c·ªï ƒë√¥ng th·∫Øc m·∫Øc. \n",
      "NƒÉm 2012, Hanoimilk thu l√£i sau thu·∫ø h∆°n 1,2 t·ª∑ ƒë·ªìng, ch·ªâ ho√†n th√†nh 39,3% k·∫ø ho·∫°ch. T·ªïng doanh thu c≈©ng th·∫•p h∆°n m·ª•c ti√™u g·∫ßn 75%, ch·ªâ ƒë·∫°t kho·∫£ng 250 t·ª∑ ƒë·ªìng. L√£i c∆° b·∫£n tr√™n m·ªôt c·ªï ph·∫ßn gi·∫£m t·ª´ 126 ƒë·ªìng (nƒÉm 2011) xu·ªëng 97 ƒë·ªìng.\n",
      "Tr∆∞·ªõc ƒë√≥, l·ªó l≈©y k·∫ø ƒë·∫øn h·∫øt nƒÉm 2011 c·ªßa Hanoimilk l√† 61,5 t·ª∑ ƒë·ªìng. Trong bu·ªïi ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th∆∞·ªùng ni√™n 2013 v·ª´a t·ªï ch·ª©c, H·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk cho bi·∫øt kho·∫£n l√£i sau thu·∫ø 2012 ch∆∞a th·ªÉ b√π ƒë·∫Øp l·ªó l≈©y k·∫ø, do v·∫≠y c√¥ng ty kh√¥ng c√≥ l·ª£i nhu·∫≠n chia c·ªï t·ª©c 2012.\n",
      "Quy·∫øt ƒë·ªãnh tr√™n tr·ªü n√™n cƒÉng th·∫≥ng khi Hanoimilk tr√¨nh th√™m m·ª©c th√π lao cho th√†nh vi√™n H·ªôi ƒë·ªìng qu·∫£n tr·ªã, trong ƒë√≥ Ch·ªß t·ªãch H√† Quang Tu·∫•n ƒë∆∞·ª£c h∆∞·ªüng l∆∞∆°ng 50 tri·ªáu ƒë·ªìng m·ªôt th√°ng, nhi·ªám k·ª≥ 2013. C√°c th√†nh vi√™n c√≤n l·∫°i h∆∞·ªüng l∆∞∆°ng 8 tri·ªáu ƒë·ªìng c√≤n ban ki·ªÉm so√°t ƒë∆∞·ª£c nh·∫≠n 4,5 tri·ªáu m·ªói th√°ng.\n",
      "C·ªï ƒë√¥ng c√≥ t√™n Ph·∫°m ƒê·ª©c B·∫£o b√†y t·ªè lo ng·∫°i khi c√¥ng ty ƒëang l√†m ƒÉn thua l·ªó, gi√° c·ªï phi·∫øu trong 2 nƒÉm ƒë√£ m·∫•t t·ªõi hai ph·∫ßn ba gi√° tr·ªã. Vi·ªác l∆∞∆°ng ch·ªß t·ªãch 50 tri·ªáu, theo √¥ng B·∫£o, l√† b·∫•t h·ª£p l√Ω.\n",
      "Tr·∫£ l·ªùi v·∫•n ƒë·ªÅ n√†y, √¥ng H√† Quang Tu·∫•n, Ch·ªß t·ªãch H·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk nh·∫≠n ƒë·ªãnh con s·ªë 50 tri·ªáu ch∆∞a ph·∫£i m·ª©c qu√° l·ªõn. ‚ÄúCh√∫ng t√¥i l√† nh·ªØng ng∆∞·ªùi c√≥ tr√¨nh ƒë·ªô v√† kinh nghi·ªám, n·∫øu c√≥ ph·∫£i ƒëi l√†m thu√™ c≈©ng s·∫Ω ƒë∆∞·ª£c h∆∞·ªüng m·ª©c l∆∞∆°ng h√†ng ch·ª•c ngh√¨n ƒë√¥la m·ªôt th√°ng‚Äù, √¥ng Tu·∫•n gi·∫£i th√≠ch.\n",
      "Tuy v·∫≠y, c≈©ng c√≥ √Ω ki·∫øn c·ªï ƒë√¥ng nh·∫≠n ƒë·ªãnh, m·ª©c l∆∞∆°ng c·ªßa ch·ªß t·ªãch l√† x·ª©ng ƒë√°ng. ‚ÄúCh·ªâ trong hai nƒÉm, c√¥ng ty ƒë√£ ho·∫°t ƒë·ªông c√≥ l√£i d√π tr∆∞·ªõc ƒë√≥ l·ªó n·∫∑ng, c√°c kho·∫£n vay ng√¢n h√†ng c≈©ng gi·∫£m ƒëi ƒë√°ng k·ªÉ, ng∆∞·ªùi l√£nh ƒë·∫°o cao nh·∫•t c≈©ng c·∫ßn c√≥ ƒë·ªông vi√™n b·∫±ng l∆∞∆°ng th∆∞·ªüng ƒë·ªÉ h·ªç t·∫≠p trung c·ª©u doanh nghi·ªáp‚Äù, m·ªôt c·ªï ƒë√¥ng g√≥p √Ω.\n",
      "Trao ƒë·ªïi v·ªõi VnExpress.net, √¥ng H√† Quang Tu·∫•n chia s·∫ª d√π ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th√†nh c√¥ng, √¥ng v·∫´n r·∫•t bu·ªìn v√¨ c√≤n nhi·ªÅu √Ω ki·∫øn tr√°i chi·ªÅu h∆∞·ªõng ƒë·∫øn √¥ng v√† Hanoimilk. Trong khi ƒë√≥, theo √¥ng Tu·∫•n, cu·ªôc c·∫°nh tranh ng√†nh s·ªØa ƒëang ng√†y m·ªôt kh·ªëc li·ªát, c√°c ƒë·ªëi th·ªß l·ªõn ƒë√£ chi·∫øm t·ªõi 80% th·ªã ph·∫ßn.\n",
      "‚ÄúC√≥ c√¥ng ty c√≤n ƒë·∫ßu t∆∞ trang tr·∫°i l√™n t·ªõi h√†ng ngh√¨n t·ª∑ ƒë·ªìng, chi ph√≠ marketing nƒÉm ƒë·∫ßu nh·ªØng 17 tri·ªáu USD. Hanoimilk kh√¥ng c√≥ t√†i s·∫£n h√†ng t·ª∑ USD, c≈©ng kh√¥ng c√≥ ti·∫øng th∆°m t·ª´ nh·ªØng nƒÉm tr∆∞·ªõc, ng√¢n s√°ch l·∫°i h·∫°n h·∫πp, ch·ªâ c√≥ th·ªÉ c·∫°nh tranh b·∫±ng ch·∫•t l∆∞·ª£ng v√† nh·ªØng chi·∫øn l∆∞·ª£c ƒë∆∞·ªùng d√†i. Nh∆∞ng trong b·ªëi c·∫£nh hi·ªán nay v·∫´n c√≤n qu√° nhi·ªÅu kh√≥ khƒÉn‚Äù, Ch·ªß t·ªãch Hanoimilk lo √¢u.\n",
      "Nh·ªØng nƒÉm t·ªõi, ch·ªß t·ªãch Hanoimilk cho r·∫±ng c√¥ng ty v·∫´n s·∫Ω c√≤n g·∫∑p nhi·ªÅu kh√≥ khƒÉn. Tr∆∞·ªõc ƒë√≥, d∆∞ lu·∫≠n t·ª´ng d·∫•y l√™n tin ƒë·ªìn Hanoimilk chu·∫©n b·ªã s√°p nh·∫≠p c√πng doanh nghi·ªáp kh√°c. Tuy nhi√™n, Ch·ªß t·ªãch H√† Quang Tu·∫•n kh·∫≥ng ƒë·ªãnh v·ªõi VnExpress.net ƒë√¢y ch·ªâ l√† tin ƒë·ªìn, nh·∫±m m·ª•c ƒë√≠ch ch·ªëng ph√° c√°c chi·∫øn l∆∞·ª£c trong th·ªùi gian t·ªõi c·ªßa c√¥ng ty.\n",
      "Sang nƒÉmÔªøH·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk cho bi·∫øt kho·∫£n l√£i sau thu·∫ø 2012 ch∆∞a th·ªÉ b√π ƒë·∫Øp l·ªó l≈©y k·∫ø, c√¥ng ty kh√¥ng c√≥ l·ª£i nhu·∫≠n chia c·ªï t·ª©c 2012.\n",
      "Quy·∫øt ƒë·ªãnh tr√™n tr·ªü n√™n cƒÉng th·∫≥ng khi Hanoimilk tr√¨nh th√™m m·ª©c th√π lao cho th√†nh vi√™n H·ªôi ƒë·ªìng qu·∫£n tr·ªã,  trong ƒë√≥ Ch·ªß t·ªãch H√† Quang Tu·∫•n ƒë∆∞·ª£c h∆∞·ªüng l∆∞∆°ng 50 tri·ªáu ƒë·ªìng m·ªôt th√°ng. \n",
      "D√π ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th√†nh c√¥ng, √¥ng Tu·∫•n v·∫´n r·∫•t bu·ªìn v√¨ c√≤n nhi·ªÅu √Ω ki·∫øn tr√°i chi·ªÅu h∆∞·ªõng ƒë·∫øn √¥ng v√† Hanoimilk. \n",
      "Nh·ªØng nƒÉm t·ªõi, ch·ªß t·ªãch Hanoimilk cho r·∫±ng c√¥ng ty v·∫´n s·∫Ω c√≤n g·∫∑p nhi·ªÅu kh√≥ khƒÉn. Sang nƒÉm 2013, Hanoimilk ƒë·∫∑t m·ª•c ti√™u doanh thu h∆°n 300 t·ª∑ ƒë·ªìng, l√£i tr∆∞·ªõc thu·∫ø 3,1 t·ª∑ ƒë·ªìng.\n",
      "[Reference] ÔªøH·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk cho bi·∫øt kho·∫£n l√£i sau thu·∫ø 2012 ch∆∞a th·ªÉ b√π ƒë·∫Øp l·ªó l≈©y k·∫ø, c√¥ng ty kh√¥ng c√≥ l·ª£i nhu·∫≠n chia c·ªï t·ª©c 2012.\n",
      "Quy·∫øt ƒë·ªãnh tr√™n tr·ªü n√™n cƒÉng th·∫≥ng khi Hanoimilk tr√¨nh th√™m m·ª©c th√π lao cho th√†nh vi√™n H·ªôi ƒë·ªìng qu·∫£n tr·ªã,  trong ƒë√≥ Ch·ªß t·ªãch H√† Quang Tu·∫•n ƒë∆∞·ª£c h∆∞·ªüng l∆∞∆°ng 50 tri·ªáu ƒë·ªìng m·ªôt th√°ng. \n",
      "D√π ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th√†nh c√¥ng, √¥ng Tu·∫•n v·∫´n r·∫•t bu·ªìn v√¨ c√≤n nhi·ªÅu √Ω ki·∫øn tr√°i chi·ªÅu h∆∞·ªõng ƒë·∫øn √¥ng v√† Hanoimilk. \n",
      "Nh·ªØng nƒÉm t·ªõi, ch·ªß t·ªãch Hanoimilk cho r·∫±ng c√¥ng ty v·∫´n s·∫Ω c√≤n g·∫∑p nhi·ªÅu kh√≥ khƒÉn. Sang nƒÉm 2013, Hanoimilk ƒë·∫∑t m·ª•c ti√™u doanh thu h∆°n 300 t·ª∑ ƒë·ªìng, l√£i tr∆∞·ªõc thu·∫ø 3,1 t·ª∑ ƒë·ªìng.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøCh·ªß t·ªãch Hanoimilk b·ªã c·ªï ƒë√¥ng 'truy' chuy·ªán l∆∞∆°ng th∆∞·ªüng\n",
      "Ch·ªâ ho√†n th√†nh g·∫ßn 40% k·∫ø ho·∫°ch, l√£i sau thu·∫ø ch∆∞a ƒë·ªß b√π l·ªó l≈©y k·∫ø... n√™n m·ª©c l∆∞∆°ng 50 tri·ªáu ƒë·ªìng m·ªôt th√°ng c·ªßa Ch·ªß t·ªãch Hanoimilk - H√† Quang Tu·∫•n khi·∫øn nhi·ªÅu c·ªï ƒë√¥ng th·∫Øc m·∫Øc. \n",
      "NƒÉm 2012, Hanoimilk thu l√£i sau thu·∫ø h∆°n 1,2 t·ª∑ ƒë·ªìng, ch·ªâ ho√†n th√†nh 39,3% k·∫ø ho·∫°ch. T·ªïng doanh thu c≈©ng th·∫•p h∆°n m·ª•c ti√™u g·∫ßn 75%, ch·ªâ ƒë·∫°t kho·∫£ng 250 t·ª∑ ƒë·ªìng. L√£i c∆° b·∫£n tr√™n m·ªôt c·ªï ph·∫ßn gi·∫£m t·ª´ 126 ƒë·ªìng (nƒÉm 2011) xu·ªëng 97 ƒë·ªìng.\n",
      "Tr∆∞·ªõc ƒë√≥, l·ªó l≈©y k·∫ø ƒë·∫øn h·∫øt nƒÉm 2011 c·ªßa Hanoimilk l√† 61,5 t·ª∑ ƒë·ªìng. Trong bu·ªïi ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th∆∞·ªùng ni√™n 2013 v·ª´a t·ªï ch·ª©c, H·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk cho bi·∫øt kho·∫£n l√£i sau thu·∫ø 2012 ch∆∞a th·ªÉ b√π ƒë·∫Øp l·ªó l≈©y k·∫ø, do v·∫≠y c√¥ng ty kh√¥ng c√≥ l·ª£i nhu·∫≠n chia c·ªï t·ª©c 2012.\n",
      "Quy·∫øt ƒë·ªãnh tr√™n tr·ªü n√™n cƒÉng th·∫≥ng khi Hanoimilk tr√¨nh th√™m m·ª©c th√π lao cho th√†nh vi√™n H·ªôi ƒë·ªìng qu·∫£n tr·ªã, trong ƒë√≥ Ch·ªß t·ªãch H√† Quang Tu·∫•n ƒë∆∞·ª£c h∆∞·ªüng l∆∞∆°ng 50 tri·ªáu ƒë·ªìng m·ªôt th√°ng, nhi·ªám k·ª≥ 2013. C√°c th√†nh vi√™n c√≤n l·∫°i h∆∞·ªüng l∆∞∆°ng 8 tri·ªáu ƒë·ªìng c√≤n ban ki·ªÉm so√°t ƒë∆∞·ª£c nh·∫≠n 4,5 tri·ªáu m·ªói th√°ng.\n",
      "C·ªï ƒë√¥ng c√≥ t√™n Ph·∫°m ƒê·ª©c B·∫£o b√†y t·ªè lo ng·∫°i khi c√¥ng ty ƒëang l√†m ƒÉn thua l·ªó, gi√° c·ªï phi·∫øu trong 2 nƒÉm ƒë√£ m·∫•t t·ªõi hai ph·∫ßn ba gi√° tr·ªã. Vi·ªác l∆∞∆°ng ch·ªß t·ªãch 50 tri·ªáu, theo √¥ng B·∫£o, l√† b·∫•t h·ª£p l√Ω.\n",
      "Tr·∫£ l·ªùi v·∫•n ƒë·ªÅ n√†y, √¥ng H√† Quang Tu·∫•n, Ch·ªß t·ªãch H·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk nh·∫≠n ƒë·ªãnh con s·ªë 50 tri·ªáu ch∆∞a ph·∫£i m·ª©c qu√° l·ªõn. ‚ÄúCh√∫ng t√¥i l√† nh·ªØng ng∆∞·ªùi c√≥ tr√¨nh ƒë·ªô v√† kinh nghi·ªám, n·∫øu c√≥ ph·∫£i ƒëi l√†m thu√™ c≈©ng s·∫Ω ƒë∆∞·ª£c h∆∞·ªüng m·ª©c l∆∞∆°ng h√†ng ch·ª•c ngh√¨n ƒë√¥la m·ªôt th√°ng‚Äù, √¥ng Tu·∫•n gi·∫£i th√≠ch.\n",
      "Tuy v·∫≠y, c≈©ng c√≥ √Ω ki·∫øn c·ªï ƒë√¥ng nh·∫≠n ƒë·ªãnh, m·ª©c l∆∞∆°ng c·ªßa ch·ªß t·ªãch l√† x·ª©ng ƒë√°ng. ‚ÄúCh·ªâ trong hai nƒÉm, c√¥ng ty ƒë√£ ho·∫°t ƒë·ªông c√≥ l√£i d√π tr∆∞·ªõc ƒë√≥ l·ªó n·∫∑ng, c√°c kho·∫£n vay ng√¢n h√†ng c≈©ng gi·∫£m ƒëi ƒë√°ng k·ªÉ, ng∆∞·ªùi l√£nh ƒë·∫°o cao nh·∫•t c≈©ng c·∫ßn c√≥ ƒë·ªông vi√™n b·∫±ng l∆∞∆°ng th∆∞·ªüng ƒë·ªÉ h·ªç t·∫≠p trung c·ª©u doanh nghi·ªáp‚Äù, m·ªôt c·ªï ƒë√¥ng g√≥p √Ω.\n",
      "Trao ƒë·ªïi v·ªõi VnExpress.net, √¥ng H√† Quang Tu·∫•n chia s·∫ª d√π ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th√†nh c√¥ng, √¥ng v·∫´n r·∫•t bu·ªìn v√¨ c√≤n nhi·ªÅu √Ω ki·∫øn tr√°i chi·ªÅu h∆∞·ªõng ƒë·∫øn √¥ng v√† Hanoimilk. Trong khi ƒë√≥, theo √¥ng Tu·∫•n, cu·ªôc c·∫°nh tranh ng√†nh s·ªØa ƒëang ng√†y m·ªôt kh·ªëc li·ªát, c√°c ƒë·ªëi th·ªß l·ªõn ƒë√£ chi·∫øm t·ªõi 80% th·ªã ph·∫ßn.\n",
      "‚ÄúC√≥ c√¥ng ty c√≤n ƒë·∫ßu t∆∞ trang tr·∫°i l√™n t·ªõi h√†ng ngh√¨n t·ª∑ ƒë·ªìng, chi ph√≠ marketing nƒÉm ƒë·∫ßu nh·ªØng 17 tri·ªáu USD. Hanoimilk kh√¥ng c√≥ t√†i s·∫£n h√†ng t·ª∑ USD, c≈©ng kh√¥ng c√≥ ti·∫øng th∆°m t·ª´ nh·ªØng nƒÉm tr∆∞·ªõc, ng√¢n s√°ch l·∫°i h·∫°n h·∫πp, ch·ªâ c√≥ th·ªÉ c·∫°nh tranh b·∫±ng ch·∫•t l∆∞·ª£ng v√† nh·ªØng chi·∫øn l∆∞·ª£c ƒë∆∞·ªùng d√†i. Nh∆∞ng trong b·ªëi c·∫£nh hi·ªán nay v·∫´n c√≤n qu√° nhi·ªÅu kh√≥ khƒÉn‚Äù, Ch·ªß t·ªãch Hanoimilk lo √¢u.\n",
      "Nh·ªØng nƒÉm t·ªõi, ch·ªß t·ªãch Hanoimilk cho r·∫±ng c√¥ng ty v·∫´n s·∫Ω c√≤n g·∫∑p nhi·ªÅu kh√≥ khƒÉn. Tr∆∞·ªõc ƒë√≥, d∆∞ lu·∫≠n t·ª´ng d·∫•y l√™n tin ƒë·ªìn Hanoimilk chu·∫©n b·ªã s√°p nh·∫≠p c√πng doanh nghi·ªáp kh√°c. Tuy nhi√™n, Ch·ªß t·ªãch H√† Quang Tu·∫•n kh·∫≥ng ƒë·ªãnh v·ªõi VnExpress.net ƒë√¢y ch·ªâ l√† tin ƒë·ªìn, nh·∫±m m·ª•c ƒë√≠ch ch·ªëng ph√° c√°c chi·∫øn l∆∞·ª£c trong th·ªùi gian t·ªõi c·ªßa c√¥ng ty.\n",
      "Sang nƒÉmÔªøH·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk cho bi·∫øt kho·∫£n l√£i sau thu·∫ø 2012 ch∆∞a th·ªÉ b√π ƒë·∫Øp l·ªó l≈©y k·∫ø, c√¥ng ty kh√¥ng c√≥ l·ª£i nhu·∫≠n chia c·ªï t·ª©c 2012.\n",
      "Quy·∫øt ƒë·ªãnh tr√™n tr·ªü n√™n cƒÉng th·∫≥ng khi Hanoimilk tr√¨nh th√™m m·ª©c th√π lao cho th√†nh vi√™n H·ªôi ƒë·ªìng qu·∫£n tr·ªã,  trong ƒë√≥ Ch·ªß t·ªãch H√† Quang Tu·∫•n ƒë∆∞·ª£c h∆∞·ªüng l∆∞∆°ng 50 tri·ªáu ƒë·ªìng m·ªôt th√°ng. \n",
      "D√π ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th√†nh c√¥ng, √¥ng Tu·∫•n v·∫´n r·∫•t bu·ªìn v√¨ c√≤n nhi·ªÅu √Ω ki·∫øn tr√°i chi·ªÅu h∆∞·ªõng ƒë·∫øn √¥ng v√† Hanoimilk. \n",
      "Nh·ªØng nƒÉm t·ªõi, ch·ªß t·ªãch Hanoimilk cho r·∫±ng c√¥ng ty v·∫´n s·∫Ω c√≤n g·∫∑p nhi·ªÅu kh√≥ khƒÉn. Sang nƒÉm 2013, Hanoimilk ƒë·∫∑t m·ª•c ti√™u doanh thu h∆°n 300 t·ª∑ ƒë·ªìng, l√£i tr∆∞·ªõc thu·∫ø 3,1 t·ª∑ ƒë·ªìng. Tr∆∞·ªõc ƒë√≥, l·ªó l≈©y k·∫ø ƒë·∫øn h·∫øt nƒÉm 2011 c·ªßa Hanoimilk l√† 61,5 t·ª∑ ƒë·ªìng. Trong bu·ªïi ƒë·∫°i h·ªôi c·ªï ƒë√¥ng th∆∞·ªùng ni√™n 2013 v·ª´a t·ªï ch·ª©c, H·ªôi ƒë·ªìng qu·∫£n tr·ªã Hanoimilk cho bi·∫øt kho·∫£n l√£i sau thu·∫ø 2012 ch∆∞a th·ªÉ b√π ƒë·∫Øp l·ªó l≈©y k·∫ø, do v·∫≠y c√¥ng ty kh√¥ng c√≥ l·ª£i nhu·∫≠n chia c·ªï t·ª©c 2012.\n",
      "C·ªï ƒë√¥ng c√≥ t√™n Ph·∫°m ƒê·ª©c B·∫£o b√†y t·ªè lo ng·∫°i khi c√¥ng ty ƒëang l√†m ƒÉn thua l·ªó, gi√° c·ªï phi·∫øu trong 2 nƒÉm ƒë√£ m·∫•t t·ªõi hai ph·∫ßn ba gi√° tr·ªã. Vi·ªác l∆∞∆°ng ch·ªß\n",
      "\n",
      "--- Sample 3 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "T·∫°m g√°c hu·∫•n luy·ªán, gi√∫p d√¢n ch·ªëng h·∫°n\n",
      "NƒÉm nay, m√πa kh√¥ ·ªü mi·ªÅn Trung kh·∫Øc nghi·ªát h∆°n h·∫≥n m·ªçi nƒÉm. ƒê·ªÉ g√≥p ph·∫ßn ch·ªëng h·∫°n cho h√†ng ngh√¨n h√©c-ta l√∫a, hoa m√†u c·ªßa nh√¢n d√¢n v√πng h·∫° l∆∞u th·ªã x√£ An Nh∆°n v√† 2 x√£ T√¢y Giang, T√¢y Xu√¢n, huy·ªán T√¢y S∆°n (B√¨nh ƒê·ªãnh), t·ª´ ng√†y 4 ƒë·∫øn ng√†y 12-4-2013, h∆°n 100 c√°n b·ªô, chi·∫øn sƒ© c·ªßa Ti·ªÉu ƒëo√†n 1 v√† Ti·ªÉu ƒëo√†n 3 (L·ªØ ƒëo√†n Ph√≤ng kh√¥ng 573, Qu√¢n khu 5) ƒë√£ kh·∫©n tr∆∞∆°ng h√†nh qu√¢n v·ªÅ x√£ Nh∆°n T√¢n, th·ªã x√£ An Nh∆°n n·∫°o v√©t tuy·∫øn k√™nh tr·ª•c ch√≠nh c·ªßa h·ªì N√∫i M·ªôt. ƒêo·∫°n k√™nh n√†y d√†i kho·∫£ng 5km, tr·∫£i qua nhi·ªÅu nƒÉm l√≤ng k√™nh b·ªã l·ªõp b√πn r√°c d√†y tr√™n d∆∞·ªõi n·ª≠a m√©t b·ªìi l·∫•p, ngƒÉn c·∫£n d√≤ng ch·∫£y, trong khi ƒë√≥ do n·∫Øng h·∫°n, m·ª±c n∆∞·ªõc h·ªì N√∫i M·ªôt ƒëang xu·ªëng r·∫•t th·∫•p. Tr∆∞·ªõc y√™u c·∫ßu b·ª©c thi·∫øt c·ªßa ƒë·ªãa ph∆∞∆°ng ph·∫£i g·∫•p r√∫t khai th√¥ng l√≤ng k√™nh ƒë·ªÉ ng√†y 15-4 s·∫Ω m·ªü c·ª≠a h·ªì ƒë∆∞a n∆∞·ªõc v·ªÅ c√°c c√°nh ƒë·ªìng, ƒë∆°n v·ªã ƒë√£ t·∫°m g√°c vi·ªác hu·∫•n luy·ªán, ra qu√¢n gi√∫p d√¢n l√†m th·ªßy l·ª£i.\n",
      "\n",
      "Do l√†m t·ªët c√¥ng t√°c kh·∫£o s√°t t√¨nh h√¨nh, qu√°n tri·ªát nhi·ªám v·ª•, chu·∫©n b·ªã ƒë·∫ßy ƒë·ªß c√¥ng c·ª• lao ƒë·ªông, l√™n ph∆∞·ªõng √°n thi c√¥ng h·ª£p l√Ω n√™n v·ª´a ƒë·∫∑t ba l√¥ xu·ªëng b·ªô ƒë·ªôi ƒë√£ b·∫Øt tay ngay v√†o vi·ªác. Hai ti·ªÉu ƒëo√†n d√†n qu√¢n ‚Äúti·∫øn c√¥ng‚Äù t·ª´ hai ƒë·∫ßu k√™nh b·∫•t ch·∫•p c√°i n·∫Øng nh∆∞ thi√™u nh∆∞ ƒë·ªët t·ª´ tr√™n tr·ªùi d·ªôi xu·ªëng, t·ª´ d∆∞·ªõi m·∫∑t ƒë·∫•t b·ªëc l√™n, nhi·ªát ƒë·ªô c√≥ l√∫c l√™n ƒë·∫øn 380C. Trong nh·ªØng b·ªô qu√¢n ph·ª•c d√£ chi·∫øn v·ªõi chi·∫øc m≈© c·ªëi tr√™n ƒë·∫ßu, c√°n b·ªô, chi·∫øn sƒ© l√†m vi·ªác kh√¥ng ng∆°i tay. T·ªëp ƒë√†o x√∫c ƒë·∫•t c√°t, t·ªëp v·∫≠n chuy·ªÉn ƒëi ƒë·ªï hi·ªáp ƒë·ªìng ƒÉn √Ω. Tr√™n c√¥ng tr∆∞·ªùng, nhi·ªÅu chi·∫øn sƒ© xu·∫•t th√¢n t·ª´ con em th√†nh ph·ªë v·∫´n thao t√°c r·∫•t thu·∫ßn th·ª•c. H·ªèi ra m·ªõi bi·∫øt, m√¥i tr∆∞·ªùng qu√¢n ng≈© ƒë√£ r√®n cho c√°c anh kh√¥ng nh·ªØng ch·∫Øc tay s√∫ng m√† c√≤n v·ªØng tay cu·ªëc, hu·∫•n luy·ªán gi·ªèi m√† tƒÉng gia s·∫£n xu·∫•t c≈©ng c·ª´. Binh nh·∫•t D∆∞∆°ng Duy Th·ª©c x√≤e b√†n tay c·ªôm nhi·ªÅu v·∫øt chai, n√≥i: ‚ÄúM·∫•y b·ªØa ƒë·∫ßu tay ph·ªìng r·ªôp b·ªèng r√°t, l√†m ri·∫øt b√¢y ch·ª´ kh√¥ng c√≤n c·∫£m gi√°c ƒëau n·ªØa. Kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác l·ªõn trong khi ƒë√≥ y√™u c·∫ßu ti·∫øn ƒë·ªô l·∫°i ƒë√≤i h·ªèi g·∫Øt gao n√™n ai c≈©ng x√°c ƒë·ªãnh ph·∫£i tƒÉng t·ªëc. Trong l√≤ng k√™nh n√†y kh√¥ng ch·ªâ c√≥ b√πn ƒë·∫•t, r√°c th·∫£i, ƒë√° s·ªèi, x√°c s√∫c v·∫≠t ch·∫øt m√† c√≤n l·∫´n nhi·ªÅu m·∫£nh s√†nh, s·∫Øt g·ªâ n√™n ch√∫ng t√¥i v·ª´a l√†m v·ª´a nh·∫Øc nh·ªü nhau b·∫£o ƒë·∫£m an to√†n‚Äù.\n",
      "\n",
      "ƒê·ªÉ h·∫°n ch·∫ø t√°c ƒë·ªông c·ªßa n·∫Øng n√≥ng gay g·∫Øt v√†o bu·ªïi tr∆∞a, m·ªói s√°ng ƒë∆°n v·ªã l√†m vi·ªác t·ª´ 6 gi·ªù ƒë·∫øn 10 gi·ªù 15, chi·ªÅu t·ª´ 14 gi·ªù ƒë·∫øn 18 gi·ªù. C√°c ti·ªÉu ƒëo√†n c√≥ s√°ng ki·∫øn kho√°n s·∫£n ph·∫©m ƒë·∫øn t·ª´ng ng√†y lao ƒë·ªông. C√°n b·ªô b√°m b·ªô ƒë·ªôi, b√°m \"c√¥ng tr∆∞·ªùng\" v√† tr·ª±c ti·∫øp x·∫Øn tay v√†o c√πng l√†m n√™n h·∫ßu h·∫øt c√°c ca ƒë·ªÅu v∆∞·ª£t ti·∫øn ƒë·ªô ƒë·ªÅ ra. G·∫°t nh·ªØng d√≤ng m·ªì h√¥i ƒë·∫ßm ƒë√¨a tr√™n m·∫∑t, Trung sƒ©-Kh·∫©u ƒë·ªôi tr∆∞·ªüng Nguy·ªÖn VƒÉn Ch√¢u chia s·∫ª: ‚ÄúL·∫ßn n√†o ƒëi gi√∫p d√¢n ch√∫ng t√¥i c≈©ng d·ªëc s·ª©cƒê·ªÉ g√≥p ph·∫ßn ch·ªëng h·∫°n cho h√†ng ngh√¨n h√©c-ta l√∫a, hoa m√†u c·ªßa nh√¢n d√¢n v√πng h·∫° l∆∞u th·ªã x√£ An Nh∆°n v√† 2 x√£ T√¢y Giang, T√¢y Xu√¢n, huy·ªán T√¢y S∆°n, t·ª´ ng√†y 4 ƒë·∫øn ng√†y 12-4-2013, h∆°n 100 c√°n b·ªô, chi·∫øn sƒ© c·ªßa Ti·ªÉu ƒëo√†n 1 v√† Ti·ªÉu ƒëo√†n 3 ƒë√£ kh·∫©n tr∆∞∆°ng h√†nh qu√¢n v·ªÅ x√£ Nh∆°n T√¢n, th·ªã x√£ An Nh∆°n n·∫°o v√©t tuy·∫øn k√™nh tr·ª•c ch√≠nh c·ªßa h·ªì N√∫i M·ªôt.\n",
      "Tr∆∞·ªõc y√™u c·∫ßu b·ª©c thi·∫øt c·ªßa ƒë·ªãa ph∆∞∆°ng ph·∫£i g·∫•p r√∫t khai th√¥ng l√≤ng k√™nh ƒë·ªÉ ng√†y 15-4 s·∫Ω m·ªü c·ª≠a h·ªì ƒë∆∞a n∆∞·ªõc v·ªÅ c√°c c√°nh ƒë·ªìng, ƒë∆°n v·ªã ƒë√£ t·∫°m g√°c vi·ªác hu·∫•n luy·ªán, ra qu√¢n gi√∫p d√¢n l√†m th·ªßy l·ª£i.\n",
      "Ch·ªâ trong 8 ng√†y, ho√†n th√†nh n·∫°o v√©t 2.000m3 ƒë·∫•t c√°t b·ªìi l·∫•p, l√†m s·∫°ch tuy·∫øn k√™nh d√†i 5km, nhi·ªÅu ƒëo·∫°n b√πn ƒë·∫•t ng·∫≠p s√¢u ƒë·∫øn 0,8m, v∆∞·ª£t 2 ng√†y so v·ªõi ti·∫øn ƒë·ªô ƒë·ªÅ ra.\n",
      "[Reference] ƒê·ªÉ g√≥p ph·∫ßn ch·ªëng h·∫°n cho h√†ng ngh√¨n h√©c-ta l√∫a, hoa m√†u c·ªßa nh√¢n d√¢n v√πng h·∫° l∆∞u th·ªã x√£ An Nh∆°n v√† 2 x√£ T√¢y Giang, T√¢y Xu√¢n, huy·ªán T√¢y S∆°n, t·ª´ ng√†y 4 ƒë·∫øn ng√†y 12-4-2013, h∆°n 100 c√°n b·ªô, chi·∫øn sƒ© c·ªßa Ti·ªÉu ƒëo√†n 1 v√† Ti·ªÉu ƒëo√†n 3 ƒë√£ kh·∫©n tr∆∞∆°ng h√†nh qu√¢n v·ªÅ x√£ Nh∆°n T√¢n, th·ªã x√£ An Nh∆°n n·∫°o v√©t tuy·∫øn k√™nh tr·ª•c ch√≠nh c·ªßa h·ªì N√∫i M·ªôt.\n",
      "Tr∆∞·ªõc y√™u c·∫ßu b·ª©c thi·∫øt c·ªßa ƒë·ªãa ph∆∞∆°ng ph·∫£i g·∫•p r√∫t khai th√¥ng l√≤ng k√™nh ƒë·ªÉ ng√†y 15-4 s·∫Ω m·ªü c·ª≠a h·ªì ƒë∆∞a n∆∞·ªõc v·ªÅ c√°c c√°nh ƒë·ªìng, ƒë∆°n v·ªã ƒë√£ t·∫°m g√°c vi·ªác hu·∫•n luy·ªán, ra qu√¢n gi√∫p d√¢n l√†m th·ªßy l·ª£i.\n",
      "Ch·ªâ trong 8 ng√†y, ho√†n th√†nh n·∫°o v√©t 2.000m3 ƒë·∫•t c√°t b·ªìi l·∫•p, l√†m s·∫°ch tuy·∫øn k√™nh d√†i 5km, nhi·ªÅu ƒëo·∫°n b√πn ƒë·∫•t ng·∫≠p s√¢u ƒë·∫øn 0,8m, v∆∞·ª£t 2 ng√†y so v·ªõi ti·∫øn ƒë·ªô ƒë·ªÅ ra.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "T·∫°m g√°c hu·∫•n luy·ªán, gi√∫p d√¢n ch·ªëng h·∫°n\n",
      "NƒÉm nay, m√πa kh√¥ ·ªü mi·ªÅn Trung kh·∫Øc nghi·ªát h∆°n h·∫≥n m·ªçi nƒÉm. ƒê·ªÉ g√≥p ph·∫ßn ch·ªëng h·∫°n cho h√†ng ngh√¨n h√©c-ta l√∫a, hoa m√†u c·ªßa nh√¢n d√¢n v√πng h·∫° l∆∞u th·ªã x√£ An Nh∆°n v√† 2 x√£ T√¢y Giang, T√¢y Xu√¢n, huy·ªán T√¢y S∆°n (B√¨nh ƒê·ªãnh), t·ª´ ng√†y 4 ƒë·∫øn ng√†y 12-4-2013, h∆°n 100 c√°n b·ªô, chi·∫øn sƒ© c·ªßa Ti·ªÉu ƒëo√†n 1 v√† Ti·ªÉu ƒëo√†n 3 (L·ªØ ƒëo√†n Ph√≤ng kh√¥ng 573, Qu√¢n khu 5) ƒë√£ kh·∫©n tr∆∞∆°ng h√†nh qu√¢n v·ªÅ x√£ Nh∆°n T√¢n, th·ªã x√£ An Nh∆°n n·∫°o v√©t tuy·∫øn k√™nh tr·ª•c ch√≠nh c·ªßa h·ªì N√∫i M·ªôt. ƒêo·∫°n k√™nh n√†y d√†i kho·∫£ng 5km, tr·∫£i qua nhi·ªÅu nƒÉm l√≤ng k√™nh b·ªã l·ªõp b√πn r√°c d√†y tr√™n d∆∞·ªõi n·ª≠a m√©t b·ªìi l·∫•p, ngƒÉn c·∫£n d√≤ng ch·∫£y, trong khi ƒë√≥ do n·∫Øng h·∫°n, m·ª±c n∆∞·ªõc h·ªì N√∫i M·ªôt ƒëang xu·ªëng r·∫•t th·∫•p. Tr∆∞·ªõc y√™u c·∫ßu b·ª©c thi·∫øt c·ªßa ƒë·ªãa ph∆∞∆°ng ph·∫£i g·∫•p r√∫t khai th√¥ng l√≤ng k√™nh ƒë·ªÉ ng√†y 15-4 s·∫Ω m·ªü c·ª≠a h·ªì ƒë∆∞a n∆∞·ªõc v·ªÅ c√°c c√°nh ƒë·ªìng, ƒë∆°n v·ªã ƒë√£ t·∫°m g√°c vi·ªác hu·∫•n luy·ªán, ra qu√¢n gi√∫p d√¢n l√†m th·ªßy l·ª£i.\n",
      "\n",
      "Do l√†m t·ªët c√¥ng t√°c kh·∫£o s√°t t√¨nh h√¨nh, qu√°n tri·ªát nhi·ªám v·ª•, chu·∫©n b·ªã ƒë·∫ßy ƒë·ªß c√¥ng c·ª• lao ƒë·ªông, l√™n ph∆∞·ªõng √°n thi c√¥ng h·ª£p l√Ω n√™n v·ª´a ƒë·∫∑t ba l√¥ xu·ªëng b·ªô ƒë·ªôi ƒë√£ b·∫Øt tay ngay v√†o vi·ªác. Hai ti·ªÉu ƒëo√†n d√†n qu√¢n ‚Äúti·∫øn c√¥ng‚Äù t·ª´ hai ƒë·∫ßu k√™nh b·∫•t ch·∫•p c√°i n·∫Øng nh∆∞ thi√™u nh∆∞ ƒë·ªët t·ª´ tr√™n tr·ªùi d·ªôi xu·ªëng, t·ª´ d∆∞·ªõi m·∫∑t ƒë·∫•t b·ªëc l√™n, nhi·ªát ƒë·ªô c√≥ l√∫c l√™n ƒë·∫øn 380C. Trong nh·ªØng b·ªô qu√¢n ph·ª•c d√£ chi·∫øn v·ªõi chi·∫øc m≈© c·ªëi tr√™n ƒë·∫ßu, c√°n b·ªô, chi·∫øn sƒ© l√†m vi·ªác kh√¥ng ng∆°i tay. T·ªëp ƒë√†o x√∫c ƒë·∫•t c√°t, t·ªëp v·∫≠n chuy·ªÉn ƒëi ƒë·ªï hi·ªáp ƒë·ªìng ƒÉn √Ω. Tr√™n c√¥ng tr∆∞·ªùng, nhi·ªÅu chi·∫øn sƒ© xu·∫•t th√¢n t·ª´ con em th√†nh ph·ªë v·∫´n thao t√°c r·∫•t thu·∫ßn th·ª•c. H·ªèi ra m·ªõi bi·∫øt, m√¥i tr∆∞·ªùng qu√¢n ng≈© ƒë√£ r√®n cho c√°c anh kh√¥ng nh·ªØng ch·∫Øc tay s√∫ng m√† c√≤n v·ªØng tay cu·ªëc, hu·∫•n luy·ªán gi·ªèi m√† tƒÉng gia s·∫£n xu·∫•t c≈©ng c·ª´. Binh nh·∫•t D∆∞∆°ng Duy Th·ª©c x√≤e b√†n tay c·ªôm nhi·ªÅu v·∫øt chai, n√≥i: ‚ÄúM·∫•y b·ªØa ƒë·∫ßu tay ph·ªìng r·ªôp b·ªèng r√°t, l√†m ri·∫øt b√¢y ch·ª´ kh√¥ng c√≤n c·∫£m gi√°c ƒëau n·ªØa. Kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác l·ªõn trong khi ƒë√≥ y√™u c·∫ßu ti·∫øn ƒë·ªô l·∫°i ƒë√≤i h·ªèi g·∫Øt gao n√™n ai c≈©ng x√°c ƒë·ªãnh ph·∫£i tƒÉng t·ªëc. Trong l√≤ng k√™nh n√†y kh√¥ng ch·ªâ c√≥ b√πn ƒë·∫•t, r√°c th·∫£i, ƒë√° s·ªèi, x√°c s√∫c v·∫≠t ch·∫øt m√† c√≤n l·∫´n nhi·ªÅu m·∫£nh s√†nh, s·∫Øt g·ªâ n√™n ch√∫ng t√¥i v·ª´a l√†m v·ª´a nh·∫Øc nh·ªü nhau b·∫£o ƒë·∫£m an to√†n‚Äù.\n",
      "\n",
      "ƒê·ªÉ h·∫°n ch·∫ø t√°c ƒë·ªông c·ªßa n·∫Øng n√≥ng gay g·∫Øt v√†o bu·ªïi tr∆∞a, m·ªói s√°ng ƒë∆°n v·ªã l√†m vi·ªác t·ª´ 6 gi·ªù ƒë·∫øn 10 gi·ªù 15, chi·ªÅu t·ª´ 14 gi·ªù ƒë·∫øn 18 gi·ªù. C√°c ti·ªÉu ƒëo√†n c√≥ s√°ng ki·∫øn kho√°n s·∫£n ph·∫©m ƒë·∫øn t·ª´ng ng√†y lao ƒë·ªông. C√°n b·ªô b√°m b·ªô ƒë·ªôi, b√°m \"c√¥ng tr∆∞·ªùng\" v√† tr·ª±c ti·∫øp x·∫Øn tay v√†o c√πng l√†m n√™n h·∫ßu h·∫øt c√°c ca ƒë·ªÅu v∆∞·ª£t ti·∫øn ƒë·ªô ƒë·ªÅ ra. G·∫°t nh·ªØng d√≤ng m·ªì h√¥i ƒë·∫ßm ƒë√¨a tr√™n m·∫∑t, Trung sƒ©-Kh·∫©u ƒë·ªôi tr∆∞·ªüng Nguy·ªÖn VƒÉn Ch√¢u chia s·∫ª: ‚ÄúL·∫ßn n√†o ƒëi gi√∫p d√¢n ch√∫ng t√¥i c≈©ng d·ªëc s·ª©cƒê·ªÉ g√≥p ph·∫ßn ch·ªëng h·∫°n cho h√†ng ngh√¨n h√©c-ta l√∫a, hoa m√†u c·ªßa nh√¢n d√¢n v√πng h·∫° l∆∞u th·ªã x√£ An Nh∆°n v√† 2 x√£ T√¢y Giang, T√¢y Xu√¢n, huy·ªán T√¢y S∆°n, t·ª´ ng√†y 4 ƒë·∫øn ng√†y 12-4-2013, h∆°n 100 c√°n b·ªô, chi·∫øn sƒ© c·ªßa Ti·ªÉu ƒëo√†n 1 v√† Ti·ªÉu ƒëo√†n 3 ƒë√£ kh·∫©n tr∆∞∆°ng h√†nh qu√¢n v·ªÅ x√£ Nh∆°n T√¢n, th·ªã x√£ An Nh∆°n n·∫°o v√©t tuy·∫øn k√™nh tr·ª•c ch√≠nh c·ªßa h·ªì N√∫i M·ªôt.\n",
      "Tr∆∞·ªõc y√™u c·∫ßu b·ª©c thi·∫øt c·ªßa ƒë·ªãa ph∆∞∆°ng ph·∫£i g·∫•p r√∫t khai th√¥ng l√≤ng k√™nh ƒë·ªÉ ng√†y 15-4 s·∫Ω m·ªü c·ª≠a h·ªì ƒë∆∞a n∆∞·ªõc v·ªÅ c√°c c√°nh ƒë·ªìng, ƒë∆°n v·ªã ƒë√£ t·∫°m g√°c vi·ªác hu·∫•n luy·ªán, ra qu√¢n gi√∫p d√¢n l√†m th·ªßy l·ª£i.\n",
      "Ch·ªâ trong 8 ng√†y, ho√†n th√†nh n·∫°o v√©t 2.000m3 ƒë·∫•t c√°t b·ªìi l·∫•p, l√†m s·∫°ch tuy·∫øn k√™nh d√†i 5km, nhi·ªÅu ƒëo·∫°n b√πn ƒë·∫•t ng·∫≠p s√¢u ƒë·∫øn 0,8m, v∆∞·ª£t 2 ng√†y so v·ªõi ti·∫øn ƒë·ªô ƒë·ªÅ ra. Trong nh·ªØng b·ªô qu√¢n ph·ª•c d√£ chi·∫øn v·ªõi chi·∫øc m≈© c·ªëi tr√™n ƒë·∫ßu, c√°n b·ªô, chi·∫øn sƒ© l√†m vi·ªác kh√¥ng ng∆°i tay. T·ªëp ƒë√†o x√∫c ƒë·∫•t c√°t, t·ªëp v·∫≠n chuy·ªÉn ƒëi ƒë·ªï hi·ªáp ƒë·ªìng ƒÉn √Ω. Tr√™n c√¥ng tr∆∞·ªùng, nhi·ªÅu chi·∫øn sƒ© xu·∫•t th√¢n t·ª´ con em th√†nh ph·ªë v·∫´n thao t√°c r·∫•t thu·∫ßn th·ª•c. H·ªèi ra m·ªõi bi·∫øt, m√¥i tr∆∞·ªùng qu√¢n ng≈© ƒë√£ r√®n cho c√°c anh kh√¥ng nh·ªØng ch·∫Øc tay s√∫ng m√† c√≤n v·ªØng tay cu·ªëc, hu·∫•n luy·ªán gi·ªèi m√† tƒÉng gia s·∫£n xu·∫•t c≈©ng c·ª´.\n",
      "Binh nh·∫•t D∆∞∆°ng Duy Th·ª©c x\n",
      "\n",
      "--- Sample 4 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøCu·ªën s√°ch c·ªßa nƒÉm 2014\n",
      "\n",
      "Sau khi thu th·∫≠p √Ω ki·∫øn t·ª´ nhi·ªÅu nh√† xu·∫•t b·∫£n tr√™n th·∫ø gi·ªõi, t·ªù Guardian nh·∫≠n ƒë·ªãnh cu·ªën h·ªìi k√Ω s·∫Øp xu·∫•t b·∫£n c·ªßa b√† Hillary Clinton s·∫Ω l√† m·ªôt hi·ªán t∆∞·ª£ng ƒë√¨nh ƒë√°m ƒë·ªëi v·ªõi c√°c nh√† xu·∫•t b·∫£n v√† nh·ªØng ng∆∞·ªùi y√™u s√°ch trong nƒÉm 2014.\n",
      "M·ªói khi s·∫Øp cho ra ƒë·ªùi m·ªôt ƒë·∫ßu s√°ch h·ª©a h·∫πn s·∫Ω b√°n ch·∫°y, c√°c nh√† xu·∫•t b·∫£n lu√¥n h·ªìi h·ªôp, h√°o h·ª©c ch·ªù ƒë·ª£i. H·ªç ch√≠nh l√† nh·ªØng nh√† ƒë√°nh gi√° tinh t∆∞·ªùng nh·∫•t ƒë·ªëi v·ªõi m·ª©c ƒë·ªô tri·ªÉn v·ªçng v·ªÅ doanh s·ªë b√°n ra c·ªßa m·ªôt cu·ªën s√°ch.\n",
      "V·ªÅ cu·ªën h·ªìi k√Ω m√† b√† Hillary Clinton s·∫Ω s·ªõm ho√†n t·∫•t v√† cho ra m·∫Øt trong nƒÉm 2014. C√°c nh√† xu·∫•t b·∫£n ƒë·ªÅu t·ªè ra l·∫°c quan tr∆∞·ªõc kh·∫£ nƒÉng b√°n ch·∫°y c·ªßa s√°ch. ƒê√¢y l√† cu·ªën s√°ch th·ª© 5 m√† v·ªã c·ª±u Ngo·∫°i tr∆∞·ªüng M·ªπ ch·∫Øp b√∫t, n√≥ h·ª©a h·∫πn s·∫Ω l√† ‚Äúbom t·∫•n‚Äù c·ªßa nƒÉm 2014.\n",
      "Cu·ªën s√°ch ch·ªß y·∫øu vi·∫øt v·ªÅ nh·ªØng s·ª± ki·ªán, bi·∫øn c·ªë, nh·ªØng k·ª∑ ni·ªám c·ªßa b√† Hillary Clinton trong nhi·ªám k·ª≥ l√†m Ngo·∫°i tr∆∞·ªüng M·ªπ.\n",
      "Trong ƒë√≥, c√≥ nh·ªØng chi ti·∫øt v·ªÅ s·ª± ki·ªán t√¨m di·ªát Osama Bin Laden, l√†n s√≥ng c√°ch m·∫°ng v√† c√°c cu·ªôc n·ªïi d·∫≠y ·ªü th·∫ø gi·ªõi ·∫¢ R·∫≠p, ƒë·∫•t n∆∞·ªõc ph√°t tri·ªÉn \"n√≥ng\" t·∫°i Ch√¢u √Å ‚Äì Trung Qu·ªëc...\n",
      "Trong c·∫£ cu·ªën s√°ch, c·ª±u Ngo·∫°i tr∆∞·ªüng Clinton s·∫Ω ti·∫øt l·ªô cho ƒë·ªôc gi·∫£ nh·ªØng c√¢u chuy·ªán nh·ªè th√∫ v·ªã m√† ch∆∞a c√≥ m·ªôt b√°o ƒë√†i n√†o ƒë∆∞a tin.\n",
      "ƒê√≥ l√† nh·ªØng s·ª± ki·ªán ƒë∆∞·ª£c nh√¨n nh·∫≠n qua lƒÉng k√≠nh c√° nh√¢n s·ªëng ƒë·ªông c·ªßa b√†, nh·ªØng k·ª∑ ni·ªám khi h·ª£p t√°c v·ªõi T·ªïng th·ªëng Obama c≈©ng nh∆∞ nh·ªØng c√¢u chuy·ªán th√∫ v·ªã gi·ªØa b√† v√† c√°c v·ªã ch√≠nh tr·ªã gia ƒë·∫øn t·ª´ kh·∫Øp c√°c n∆∞·ªõc tr√™n th·∫ø gi·ªõi‚Ä¶\n",
      "Nh√† xu·∫•t b·∫£n Simon & Schuster c·ªßa M·ªπ cho r·∫±ng b√† Hillary Clinton v·ªõi t∆∞ c√°ch l√† m·ªôt ch√≠nh tr·ªã gia ƒë√£ \"ƒëem l·∫°i m·ªôt ƒë·ªãnh nghƒ©a m·ªõi v·ªÅ h√¨nh ·∫£nh ng∆∞·ªùi ph·ª• n·ªØ ƒëi ti√™n phong tr√™n ch√≠nh tr∆∞·ªùng\".\n",
      "\"S·ª± nghi·ªáp c·ªßa b√† ƒë∆∞·ª£c chia ra l√†m nhi·ªÅu ch·∫∑ng v√† d√π ·ªü th·ªùi k·ª≥ n√†o, b√† c≈©ng ƒë·ªÅu l√† ng∆∞·ªùi ph·ª• n·ªØ c√≥ s·ª©c ·∫£nh h∆∞·ªüng mang t·∫ßm th·∫ø gi·ªõi. Khi l√† m·ªôt phu nh√¢n T·ªïng th·ªëng, khi l√† m·ªôt th∆∞·ª£ng ngh·ªã sƒ©, khi l√† Ngo·∫°i tr∆∞·ªüng v√† khi l√† m·ªôt nh√† vƒÉn, b√† ƒë·ªÅu ho√†n th√†nh xu·∫•t s·∫Øc m·ªçi vai tr√≤.\"\n",
      "Nh√† xu·∫•t b·∫£n Waterstones c·ªßa Anh coi vi·ªác b√† Clinton vi·∫øt s√°ch m·ªõi l√† \"tin tr·ªçng ƒë·∫°i, tuy·ªát v·ªùi\" c·ªßa c√°c nh√† xu·∫•t b·∫£n.\n",
      "Cu·ªën h·ªìi k√Ω tr∆∞·ªõc ƒë√≥ c·ªßa b√† Clinton ‚Äì \"Living History\" (L·ªãch s·ª≠ s·ªëng) ƒë√£ b√°n ƒë∆∞·ª£c 200.000 b·∫£n ngay trong ng√†y ƒë·∫ßu ti√™n ra m·∫Øt t·∫°i th·ªã tr∆∞·ªùng M·ªπ h·ªìi nƒÉm 2003. \n",
      "\"Danh ti·∫øng c·ªßa b√† b√¢y gi·ªù th·∫≠m ch√≠ c√≤n l·ªõn h∆°n tr∆∞·ªõc nhi·ªÅu nh·ªù nhi·ªám k·ª≥ Ngo·∫°i tr∆∞·ªüng m√† b√† ƒë√£ ƒë·∫£m nhi·ªám r·∫•t th√†nh c√¥ng d∆∞·ªõi th·ªùi T·ªïng th·ªëng Obama. B√† l√† ng∆∞·ªùi n·ªïi ti·∫øng, ƒë∆∞·ª£c y√™u m·∫øn v√† l√† m·ªôt nh√¢n v·∫≠t quan tr·ªçng mang t√≠nh then ch·ªët t·∫°i m·ªôt s·ªë s·ª± ki·ªán th·∫ø gi·ªõi d·ªãp g·∫ßn ƒë√¢y.\n",
      "V√¨ nh·ªØng l√Ω do n√†y, cu·ªën h·ªìi k√Ω s·∫Øp ƒë∆∞·ª£c xu·∫•t b·∫£n v√†o nƒÉm 2014 c·ªßa b√† ch·∫Øc ch·∫Øn s·∫Ω l√† m·ªôt trong nh·ªØng cu·ªën s√°ch ti√™u ƒëi·ªÉm\", ƒë·∫°i di·ªán nh√† xu·∫•t b·∫£n Waterstones nh·∫≠n ƒë·ªãnh.\n",
      "Nh√† xu·∫•t b·∫£n Foyles c·ªßa Anh th√¨ cho r·∫±ng s·∫Ω kh√≥ c√≥ cu·ªën s√°ch n√†o mang ch·ªß ƒë·ªÅ ch√≠nh tr·ªã v∆∞·ª£t qua ƒë∆∞·ª£c cu·ªën t·ª± truy·ªán c·ªßa b√† Hillary trong nƒÉm 2014.\n",
      "\"Y·∫øu t·ªë g√¢y b·∫•t ng·ªù nh·∫•t l√∫c n√†y l√† li·ªáu b√† c√≥ quy·∫øt ƒë·ªãnh tham gia tranh c·ª≠ T·ªïng th·ªëng trong nhi·ªám k·ª≥ m·ªõi b·∫Øt ƒë·∫ßu v√†o nƒÉm 2016. N·∫øu c√¢u tr·∫£ l·ªùi l√† c√≥, ƒë√≥ s·∫Ω l√† m·ªôt qu·∫£ bom k√≠ch n·ªï v√¥ c√πngSau khi thu th·∫≠p √Ω ki·∫øn t·ª´ nhi·ªÅu nh√† xu·∫•t b·∫£n tr√™n th·∫ø gi·ªõi, t·ªù Guardian nh·∫≠n ƒë·ªãnh cu·ªën h·ªìi k√Ω s·∫Øp xu·∫•t b·∫£n c·ªßa b√† Hillary Clinton s·∫Ω l√† m·ªôt hi·ªán t∆∞·ª£ng ƒë√¨nh ƒë√°m ƒë·ªëi v·ªõi c√°c nh√† xu·∫•t b·∫£n v√† nh·ªØng ng∆∞·ªùi y√™u s√°ch trong nƒÉm 2014.V·ªÅ cu·ªën h·ªìi k√Ω m√† b√† Hillary Clinton s·∫Ω s·ªõm ho√†n t·∫•t v√† cho ra m·∫Øt trong nƒÉm 2014, c√°c nh√† xu·∫•t b·∫£n ƒë·ªÅu t·ªè ra l·∫°c quan tr∆∞·ªõc kh·∫£ nƒÉng b√°n ch·∫°y c·ªßa s√°ch.ƒê√¢y l√† cu·ªën s√°ch th·ª© 5 m√† v·ªã c·ª±u Ngo·∫°i tr∆∞·ªüng M·ªπ ch·∫Øp b√∫t, n√≥ h·ª©a h·∫πn s·∫Ω l√† bom t·∫•n c·ªßa nƒÉm 2014. Trong c·∫£ cu·ªën s√°ch, c·ª±u Ngo·∫°i tr∆∞·ªüng Clinton s·∫Ω ti·∫øt l·ªô cho ƒë·ªôc gi·∫£ nh·ªØng c√¢u chuy·ªán nh·ªè th√∫ v·ªã m√† ch∆∞a c√≥ m·ªôt b√°o ƒë√†i n√†o ƒë∆∞a tin.Cu·ªën h·ªìi k√Ω tr∆∞·ªõc ƒë√≥ c·ªßa b√† Clinton ƒë√£ b√°n ƒë∆∞·ª£c 200.000 b·∫£n ngay trong ng√†y ƒë·∫ßu ti√™n ra m·∫Øt t·∫°i th·ªã tr∆∞·ªùng M·ªπ h·ªìi nƒÉm 2003.\n",
      "[Reference] Sau khi thu th·∫≠p √Ω ki·∫øn t·ª´ nhi·ªÅu nh√† xu·∫•t b·∫£n tr√™n th·∫ø gi·ªõi, t·ªù Guardian nh·∫≠n ƒë·ªãnh cu·ªën h·ªìi k√Ω s·∫Øp xu·∫•t b·∫£n c·ªßa b√† Hillary Clinton s·∫Ω l√† m·ªôt hi·ªán t∆∞·ª£ng ƒë√¨nh ƒë√°m ƒë·ªëi v·ªõi c√°c nh√† xu·∫•t b·∫£n v√† nh·ªØng ng∆∞·ªùi y√™u s√°ch trong nƒÉm 2014.V·ªÅ cu·ªën h·ªìi k√Ω m√† b√† Hillary Clinton s·∫Ω s·ªõm ho√†n t·∫•t v√† cho ra m·∫Øt trong nƒÉm 2014, c√°c nh√† xu·∫•t b·∫£n ƒë·ªÅu t·ªè ra l·∫°c quan tr∆∞·ªõc kh·∫£ nƒÉng b√°n ch·∫°y c·ªßa s√°ch.ƒê√¢y l√† cu·ªën s√°ch th·ª© 5 m√† v·ªã c·ª±u Ngo·∫°i tr∆∞·ªüng M·ªπ ch·∫Øp b√∫t, n√≥ h·ª©a h·∫πn s·∫Ω l√† bom t·∫•n c·ªßa nƒÉm 2014. Trong c·∫£ cu·ªën s√°ch, c·ª±u Ngo·∫°i tr∆∞·ªüng Clinton s·∫Ω ti·∫øt l·ªô cho ƒë·ªôc gi·∫£ nh·ªØng c√¢u chuy·ªán nh·ªè th√∫ v·ªã m√† ch∆∞a c√≥ m·ªôt b√°o ƒë√†i n√†o ƒë∆∞a tin.Cu·ªën h·ªìi k√Ω tr∆∞·ªõc ƒë√≥ c·ªßa b√† Clinton ƒë√£ b√°n ƒë∆∞·ª£c 200.000 b·∫£n ngay trong ng√†y ƒë·∫ßu ti√™n ra m·∫Øt t·∫°i th·ªã tr∆∞·ªùng M·ªπ h·ªìi nƒÉm 2003.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøCu·ªën s√°ch c·ªßa nƒÉm 2014\n",
      "\n",
      "Sau khi thu th·∫≠p √Ω ki·∫øn t·ª´ nhi·ªÅu nh√† xu·∫•t b·∫£n tr√™n th·∫ø gi·ªõi, t·ªù Guardian nh·∫≠n ƒë·ªãnh cu·ªën h·ªìi k√Ω s·∫Øp xu·∫•t b·∫£n c·ªßa b√† Hillary Clinton s·∫Ω l√† m·ªôt hi·ªán t∆∞·ª£ng ƒë√¨nh ƒë√°m ƒë·ªëi v·ªõi c√°c nh√† xu·∫•t b·∫£n v√† nh·ªØng ng∆∞·ªùi y√™u s√°ch trong nƒÉm 2014.\n",
      "M·ªói khi s·∫Øp cho ra ƒë·ªùi m·ªôt ƒë·∫ßu s√°ch h·ª©a h·∫πn s·∫Ω b√°n ch·∫°y, c√°c nh√† xu·∫•t b·∫£n lu√¥n h·ªìi h·ªôp, h√°o h·ª©c ch·ªù ƒë·ª£i. H·ªç ch√≠nh l√† nh·ªØng nh√† ƒë√°nh gi√° tinh t∆∞·ªùng nh·∫•t ƒë·ªëi v·ªõi m·ª©c ƒë·ªô tri·ªÉn v·ªçng v·ªÅ doanh s·ªë b√°n ra c·ªßa m·ªôt cu·ªën s√°ch.\n",
      "V·ªÅ cu·ªën h·ªìi k√Ω m√† b√† Hillary Clinton s·∫Ω s·ªõm ho√†n t·∫•t v√† cho ra m·∫Øt trong nƒÉm 2014. C√°c nh√† xu·∫•t b·∫£n ƒë·ªÅu t·ªè ra l·∫°c quan tr∆∞·ªõc kh·∫£ nƒÉng b√°n ch·∫°y c·ªßa s√°ch. ƒê√¢y l√† cu·ªën s√°ch th·ª© 5 m√† v·ªã c·ª±u Ngo·∫°i tr∆∞·ªüng M·ªπ ch·∫Øp b√∫t, n√≥ h·ª©a h·∫πn s·∫Ω l√† ‚Äúbom t·∫•n‚Äù c·ªßa nƒÉm 2014.\n",
      "Cu·ªën s√°ch ch·ªß y·∫øu vi·∫øt v·ªÅ nh·ªØng s·ª± ki·ªán, bi·∫øn c·ªë, nh·ªØng k·ª∑ ni·ªám c·ªßa b√† Hillary Clinton trong nhi·ªám k·ª≥ l√†m Ngo·∫°i tr∆∞·ªüng M·ªπ.\n",
      "Trong ƒë√≥, c√≥ nh·ªØng chi ti·∫øt v·ªÅ s·ª± ki·ªán t√¨m di·ªát Osama Bin Laden, l√†n s√≥ng c√°ch m·∫°ng v√† c√°c cu·ªôc n·ªïi d·∫≠y ·ªü th·∫ø gi·ªõi ·∫¢ R·∫≠p, ƒë·∫•t n∆∞·ªõc ph√°t tri·ªÉn \"n√≥ng\" t·∫°i Ch√¢u √Å ‚Äì Trung Qu·ªëc...\n",
      "Trong c·∫£ cu·ªën s√°ch, c·ª±u Ngo·∫°i tr∆∞·ªüng Clinton s·∫Ω ti·∫øt l·ªô cho ƒë·ªôc gi·∫£ nh·ªØng c√¢u chuy·ªán nh·ªè th√∫ v·ªã m√† ch∆∞a c√≥ m·ªôt b√°o ƒë√†i n√†o ƒë∆∞a tin.\n",
      "ƒê√≥ l√† nh·ªØng s·ª± ki·ªán ƒë∆∞·ª£c nh√¨n nh·∫≠n qua lƒÉng k√≠nh c√° nh√¢n s·ªëng ƒë·ªông c·ªßa b√†, nh·ªØng k·ª∑ ni·ªám khi h·ª£p t√°c v·ªõi T·ªïng th·ªëng Obama c≈©ng nh∆∞ nh·ªØng c√¢u chuy·ªán th√∫ v·ªã gi·ªØa b√† v√† c√°c v·ªã ch√≠nh tr·ªã gia ƒë·∫øn t·ª´ kh·∫Øp c√°c n∆∞·ªõc tr√™n th·∫ø gi·ªõi‚Ä¶\n",
      "Nh√† xu·∫•t b·∫£n Simon & Schuster c·ªßa M·ªπ cho r·∫±ng b√† Hillary Clinton v·ªõi t∆∞ c√°ch l√† m·ªôt ch√≠nh tr·ªã gia ƒë√£ \"ƒëem l·∫°i m·ªôt ƒë·ªãnh nghƒ©a m·ªõi v·ªÅ h√¨nh ·∫£nh ng∆∞·ªùi ph·ª• n·ªØ ƒëi ti√™n phong tr√™n ch√≠nh tr∆∞·ªùng\".\n",
      "\"S·ª± nghi·ªáp c·ªßa b√† ƒë∆∞·ª£c chia ra l√†m nhi·ªÅu ch·∫∑ng v√† d√π ·ªü th·ªùi k·ª≥ n√†o, b√† c≈©ng ƒë·ªÅu l√† ng∆∞·ªùi ph·ª• n·ªØ c√≥ s·ª©c ·∫£nh h∆∞·ªüng mang t·∫ßm th·∫ø gi·ªõi. Khi l√† m·ªôt phu nh√¢n T·ªïng th·ªëng, khi l√† m·ªôt th∆∞·ª£ng ngh·ªã sƒ©, khi l√† Ngo·∫°i tr∆∞·ªüng v√† khi l√† m·ªôt nh√† vƒÉn, b√† ƒë·ªÅu ho√†n th√†nh xu·∫•t s·∫Øc m·ªçi vai tr√≤.\"\n",
      "Nh√† xu·∫•t b·∫£n Waterstones c·ªßa Anh coi vi·ªác b√† Clinton vi·∫øt s√°ch m·ªõi l√† \"tin tr·ªçng ƒë·∫°i, tuy·ªát v·ªùi\" c·ªßa c√°c nh√† xu·∫•t b·∫£n.\n",
      "Cu·ªën h·ªìi k√Ω tr∆∞·ªõc ƒë√≥ c·ªßa b√† Clinton ‚Äì \"Living History\" (L·ªãch s·ª≠ s·ªëng) ƒë√£ b√°n ƒë∆∞·ª£c 200.000 b·∫£n ngay trong ng√†y ƒë·∫ßu ti√™n ra m·∫Øt t·∫°i th·ªã tr∆∞·ªùng M·ªπ h·ªìi nƒÉm 2003. \n",
      "\"Danh ti·∫øng c·ªßa b√† b√¢y gi·ªù th·∫≠m ch√≠ c√≤n l·ªõn h∆°n tr∆∞·ªõc nhi·ªÅu nh·ªù nhi·ªám k·ª≥ Ngo·∫°i tr∆∞·ªüng m√† b√† ƒë√£ ƒë·∫£m nhi·ªám r·∫•t th√†nh c√¥ng d∆∞·ªõi th·ªùi T·ªïng th·ªëng Obama. B√† l√† ng∆∞·ªùi n·ªïi ti·∫øng, ƒë∆∞·ª£c y√™u m·∫øn v√† l√† m·ªôt nh√¢n v·∫≠t quan tr·ªçng mang t√≠nh then ch·ªët t·∫°i m·ªôt s·ªë s·ª± ki·ªán th·∫ø gi·ªõi d·ªãp g·∫ßn ƒë√¢y.\n",
      "V√¨ nh·ªØng l√Ω do n√†y, cu·ªën h·ªìi k√Ω s·∫Øp ƒë∆∞·ª£c xu·∫•t b·∫£n v√†o nƒÉm 2014 c·ªßa b√† ch·∫Øc ch·∫Øn s·∫Ω l√† m·ªôt trong nh·ªØng cu·ªën s√°ch ti√™u ƒëi·ªÉm\", ƒë·∫°i di·ªán nh√† xu·∫•t b·∫£n Waterstones nh·∫≠n ƒë·ªãnh.\n",
      "Nh√† xu·∫•t b·∫£n Foyles c·ªßa Anh th√¨ cho r·∫±ng s·∫Ω kh√≥ c√≥ cu·ªën s√°ch n√†o mang ch·ªß ƒë·ªÅ ch√≠nh tr·ªã v∆∞·ª£t qua ƒë∆∞·ª£c cu·ªën t·ª± truy·ªán c·ªßa b√† Hillary trong nƒÉm 2014.\n",
      "\"Y·∫øu t·ªë g√¢y b·∫•t ng·ªù nh·∫•t l√∫c n√†y l√† li·ªáu b√† c√≥ quy·∫øt ƒë·ªãnh tham gia tranh c·ª≠ T·ªïng th·ªëng trong nhi·ªám k·ª≥ m·ªõi b·∫Øt ƒë·∫ßu v√†o nƒÉm 2016. N·∫øu c√¢u tr·∫£ l·ªùi l√† c√≥, ƒë√≥ s·∫Ω l√† m·ªôt qu·∫£ bom k√≠ch n·ªï v√¥ c√πngSau khi thu th·∫≠p √Ω ki·∫øn t·ª´ nhi·ªÅu nh√† xu·∫•t b·∫£n tr√™n th·∫ø gi·ªõi, t·ªù Guardian nh·∫≠n ƒë·ªãnh cu·ªën h·ªìi k√Ω s·∫Øp xu·∫•t b·∫£n c·ªßa b√† Hillary Clinton s·∫Ω l√† m·ªôt hi·ªán t∆∞·ª£ng ƒë√¨nh ƒë√°m ƒë·ªëi v·ªõi c√°c nh√† xu·∫•t b·∫£n v√† nh·ªØng ng∆∞·ªùi y√™u s√°ch trong nƒÉm 2014.V·ªÅ cu·ªën h·ªìi k√Ω m√† b√† Hillary Clinton s·∫Ω s·ªõm ho√†n t·∫•t v√† cho ra m·∫Øt trong nƒÉm 2014, c√°c nh√† xu·∫•t b·∫£n ƒë·ªÅu t·ªè ra l·∫°c quan tr∆∞·ªõc kh·∫£ nƒÉng b√°n ch·∫°y c·ªßa s√°ch.ƒê√¢y l√† cu·ªën s√°ch th·ª© 5 m√† v·ªã c·ª±u Ngo·∫°i tr∆∞·ªüng M·ªπ ch·∫Øp b√∫t, n√≥ h·ª©a h·∫πn s·∫Ω l√† bom t·∫•n c·ªßa nƒÉm 2014. Trong c·∫£ cu·ªën s√°ch, c·ª±u Ngo·∫°i tr∆∞·ªüng Clinton s·∫Ω ti·∫øt l·ªô cho ƒë·ªôc gi·∫£ nh·ªØng c√¢u chuy·ªán nh·ªè th√∫ v·ªã m√† ch∆∞a c√≥ m·ªôt b√°o ƒë√†i n√†o ƒë∆∞a tin.Cu·ªën h·ªìi k√Ω tr∆∞·ªõc ƒë√≥ c·ªßa b√† Clinton ƒë√£ b√°n ƒë∆∞·ª£c 200.000 b·∫£n ngay trong ng√†y ƒë·∫ßu ti√™n ra m·∫Øt t·∫°i th·ªã tr∆∞·ªùng M·ªπ h·ªìi nƒÉm 2003. Cu·ªën s√°ch ch·ªß y·∫øu vi·∫øt v·ªÅ nh·ªØng s·ª± ki·ªán, bi·∫øn c·ªë, nh·ªØng k·ª∑ ni·ªám c·ªßa b√† Hillary Clinton trong nhi·ªám k·ª≥ l√†m Ngo·∫°i tr∆∞·ªüng M·ªπ.Danh ti·∫øng c·ªßa b√† b√¢y gi·ªù th·∫≠m ch√≠ c√≤n l·ªõn h∆°n tr∆∞·ªõc nhi·ªÅu nh·ªù nhi·ªám k·ª≥ Ngo·∫°i tr∆∞·ªüng m√† b√† ƒë√£ ƒë·∫£m nhi·ªám r·∫•t th√†nh c√¥ng d∆∞·ªõi th·ªùi T·ªïng th·ªëng Obama. B√† l√† ng∆∞·ªùi n·ªïi ti·∫øng, ƒë∆∞·ª£c y√™u m·∫øn v√† l√† m·ªôt nh√¢n v·∫≠t quan tr·ªçng mang t√≠nh then ch·ªët t·∫°i m·ªôt s·ªë s·ª± ki·ªán th·∫ø gi·ªõi d·ªãp g·∫ßn ƒë√¢y.V√¨ nh·ªØng l√Ω do n√†y, cu·ªën h·ªìi k√Ω s·∫Øp ƒë∆∞·ª£c xu·∫•t b·∫£n v√†o nƒÉm 2014 c·ªßa b√† ch·∫Øc ch·∫Øn s·∫Ω l√† m·ªôt trong nh·ªØng cu·ªën\n",
      "\n",
      "--- Sample 5 ---\n",
      "[Prompt]    ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøB·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë Quy·∫øt ƒë·ªãnh ki·ªÉm to√°n \n",
      "Ng√†y 09/7/2013 VƒÉn ph√≤ng B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá (KH&CN) ƒë√£ t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë Quy·∫øt ƒë·ªãnh ki·ªÉm to√°n. Tham d·ª± H·ªôi ngh·ªã c√≥ Th·ª© tr∆∞·ªüng B·ªô KH&CN Tr·∫ßn Vi·ªát Thanh, V·ª• tr∆∞·ªüng V·ª• T√†i ch√≠nh Nguy·ªÖn Ng·ªçc Song v√† ƒë·∫°i di·ªán l√£nh ƒë·∫°o c√°c ƒë∆°n v·ªã thu·ªôc B·ªô c√≥ li√™n quan.\n",
      "V·ªÅ ph√≠a ƒêo√†n Ki·ªÉm to√°n nh√† n∆∞·ªõc c√≥ Ph√≥ T·ªïng Ki·ªÉm to√°n nh√† n∆∞·ªõc V≈© VƒÉn H·ªça, Ph√≥ Ki·ªÉm to√°n tr∆∞·ªüng Ki·ªÉm to√°n nh√† n∆∞·ªõc chuy√™n ngh√†nh III Tr·∫ßn Ng·ªçc Qu√Ω (Tr∆∞·ªüng ƒëo√†n) v√† c√°c th√†nh vi√™n trong ƒêo√†n.\n",
      "Ph√°t bi·ªÉu t·∫°i H·ªôi ngh·ªã, √¥ng Tr·∫ßn Ng·ªçc Qu√Ω cho bi·∫øt, m·ª•c ti√™u ki·ªÉm to√°n nh·∫±m x√°c ƒë·ªãnh t√≠nh ƒë√∫ng ƒë·∫Øn, trung th·ª±c h·ª£p l√Ω c·ªßa B√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN; ƒë√°nh gi√° t√≠nh kinh t·∫ø, hi·ªáu l·ª±c v√† hi·ªáu qu·∫£ trong qu·∫£n l√Ω, s·ª≠ d·ª•ng ng√¢n s√°ch, ti·ªÅn, t√†i s·∫£n nh√† n∆∞·ªõc t·∫°i c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n, trong ƒë√≥ ƒëi s√¢u v√†o ƒë√°nh gi√° vi·ªác tri·ªÉn khai th·ª±c hi·ªán c√°c Ngh·ªã quy·∫øt c·ªßa Qu·ªëc h·ªôi, Ch√≠nh ph·ªß v·ªÅ ph√°t tri·ªÉn kinh t·∫ø - x√£ h·ªôi v√† c√°c gi·∫£i ph√°p ch·ªß y·∫øu t·∫≠p trung ki·ªÅm ch·∫ø l·∫°m ph√°t, ·ªïn ƒë·ªãnh kinh t·∫ø vƒ© m√¥, b·∫£o ƒë·∫£m an sinh x√£ h·ªôi; x√°c ƒë·ªãnh r√µ tr√°ch nhi·ªám c·ªßa t·∫≠p th·ªÉ v√† c√° nh√¢n, ki·∫øn ngh·ªã x·ª≠ l√Ω vi ph·∫°m theo quy ƒë·ªãnh c·ªßa ph√°p lu·∫≠t.\n",
      "Ngo√†i ra, n·ªôi dung ki·ªÉm to√°n c≈©ng t·∫≠p trung v√†o vi·ªác l·∫≠p, ph√¢n b·ªï, qu·∫£n l√Ω v√† s·ª≠ d·ª•ng c√°c kho·∫£n thu, chi ng√¢n s√°ch, ti·ªÅn v√† t√†i s·∫£n nh√† n∆∞·ªõc; vi·ªác mua s·∫Øm, qu·∫£n l√Ω, s·ª≠ d·ª•ng t√†i s·∫£n; vi·ªác ch·∫•p h√†nh ph√°p lu·∫≠t, ch√≠nh s√°ch, ch·∫ø ƒë·ªô qu·∫£n l√Ω t√†i ch√≠nh ‚Äì k·∫ø to√°n, ch·∫ø ƒë·ªô qu·∫£n l√Ω ƒë·∫ßu t∆∞ c·ªßa nh√† n∆∞·ªõc; vi·ªác huy ƒë·ªông ngu·ªìn v·ªën, x√©t ch·ªçn, ph√™ duy·ªát, h·ª£p ƒë·ªìng nghi√™n c·ª©u khoa h·ªçc, nghi·ªám thu, c√¥ng nh·∫≠n k·∫øt qu·∫£ nghi√™n c·ª©u, quy·∫øt to√°n kinh ph√≠ th·ª±c hi·ªán ƒë·ªÅ t√†i ƒë∆∞·ª£c Qu·ªπ ph√°t tri·ªÉn KH&CN t√†i tr·ª£ theo quy ƒë·ªãnh. Ph·∫°m vi ki·ªÉm to√°n l√† b√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN, b√°o c√°o quy·∫øt to√°n nƒÉm 2011, 2012 c·ªßa Qu·ªπ ph√°t tri·ªÉn KH&CN v√† c√°c th·ªùi k·ª≥ tr∆∞·ªõc, sau c√≥ li√™n quan c·ªßa c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "Thay m·∫∑t Ki·ªÉm to√°n nh√† n∆∞·ªõc, Ph√≥ T·ªïng Ki·ªÉm to√°n V≈© VƒÉn H·ªça ƒë√°nh gi√° cao s·ª± h·ª£p t√°c c·ªßa B·ªô KH&CN trong th·ªùi gian qua v√† mong mu·ªën ti·∫øp t·ª•c nh·∫≠n ƒë∆∞·ª£c s·ª± ph·ªëi h·ª£p ch·∫∑t ch·∫Ω h∆°n n·ªØa t·ª´ ph√≠a ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n trong vi·ªác ph·∫£n ·∫£nh t√¨nh h√¨nh th·ª±c t·∫ø, r√† so√°t c√°c c∆° ch·∫ø ch√≠nh s√°ch, c∆° ch·∫ø t·ª± ch·ªß t√†i ch√≠nh, nh·ªØng b·∫•t c·∫≠p trong c√°c c∆° ch·∫ø hi·ªán nay,‚Ä¶ Qua ƒë√≥, c√°c b√™n s·∫Ω c√πng ƒë∆∞a ra c√°c gi·∫£i ph√°p t·ªët nh·∫•t ƒë·ªÉ th√°o g·ª° nh·ªØng kh√≥ khƒÉn, v∆∞·ªõng m·∫Øc trong qu√° tr√¨nh tri·ªÉn khai ki·ªÉm to√°n ng√¢n s√°ch, ti·ªÅn v√† t√†i s·∫£n nh√† n∆∞·ªõc nƒÉm 2012 c·ªßa B·ªô KH&CN v√† c√¥ng t√°c qu·∫£n l√Ω, s·ª≠ d·ª•ng Qu·ªπ ph√°t tri·ªÉn KH&CN qu·ªëc gia giai ƒëo·∫°n 2011 - 2012.\n",
      "T·∫°i H·ªôi ngh·ªã, Th·ª© tr∆∞·ªüng Tr·∫ßn Vi·ªát Thanh ƒë√£ th√¥ng b√°o m·ªôt s·ªë th√†nh t·ª±u quan tr·ªçng trong nƒÉm 2012 c·ªßa B·ªô KH&CN t·ªõi c√°c ƒë·∫°i bi·ªÉu tham d·ª± nh∆∞: Vi·ªác ban h√†nh Chi·∫øn l∆∞·ª£c ph√°t tri·ªÉn KH&CN t·ª´ nƒÉm 2011 - 2020 c·ªßa Th·ªß t∆∞·ªõng Ch√≠nh ph·ªß; Ngh·ªã quy·∫øt s·ªë 20-NQ/TW v·ªÅ ph√°t tri·ªÉn KH&CN; Lu·∫≠t KH&CN (s·ª≠a ƒë·ªïi) ƒë√£ ƒë∆∞·ª£c Qu·ªëc h·ªôi th√¥ng qua v√† s·∫Ω c√≥ hi·ªáu l·ª±c v√†o ng√†y 01/01/2014,‚Ä¶ Th·ª© tr∆∞·ªüngÔªø B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá ƒë√£ t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë Quy·∫øt ƒë·ªãnh ki·ªÉm to√°n.\n",
      "M·ª•c ti√™u ki·ªÉm to√°n nh·∫±m x√°c ƒë·ªãnh t√≠nh ƒë√∫ng ƒë·∫Øn, trung th·ª±c h·ª£p l√Ω c·ªßa B√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN; ƒë√°nh gi√° t√≠nh kinh t·∫ø, hi·ªáu l·ª±c v√† hi·ªáu qu·∫£ trong qu·∫£n l√Ω, s·ª≠ d·ª•ng ng√¢n s√°ch, ti·ªÅn, t√†i s·∫£n nh√† n∆∞·ªõc t·∫°i c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "Ph·∫°m vi ki·ªÉm to√°n l√† b√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN, b√°o c√°o quy·∫øt to√°n nƒÉm 2011, 2012 c·ªßa Qu·ªπ ph√°t tri·ªÉn KH&CN v√† c√°c th·ªùi k·ª≥ tr∆∞·ªõc, sau c√≥ li√™n quan c·ªßa c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "V·ª• T√†i ch√≠nh s·∫Ω l√† ƒë·∫ßu m·ªëi th√¥ng tin cho c√°c ƒë∆°n v·ªã thu·ªôc B·ªô v√† c√°c ƒë∆°n v·ªã c√≥ li√™n quan.\n",
      "Th·ªùi gian ki·ªÉm to√°n s·∫Ω b·∫Øt ƒë·∫ßu t·ª´ ng√†y 09/7 v√† k·∫øt th√∫c v√†o ng√†y 10/9/2013.\n",
      "[Reference] Ôªø B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá ƒë√£ t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë Quy·∫øt ƒë·ªãnh ki·ªÉm to√°n.\n",
      "M·ª•c ti√™u ki·ªÉm to√°n nh·∫±m x√°c ƒë·ªãnh t√≠nh ƒë√∫ng ƒë·∫Øn, trung th·ª±c h·ª£p l√Ω c·ªßa B√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN; ƒë√°nh gi√° t√≠nh kinh t·∫ø, hi·ªáu l·ª±c v√† hi·ªáu qu·∫£ trong qu·∫£n l√Ω, s·ª≠ d·ª•ng ng√¢n s√°ch, ti·ªÅn, t√†i s·∫£n nh√† n∆∞·ªõc t·∫°i c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "Ph·∫°m vi ki·ªÉm to√°n l√† b√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN, b√°o c√°o quy·∫øt to√°n nƒÉm 2011, 2012 c·ªßa Qu·ªπ ph√°t tri·ªÉn KH&CN v√† c√°c th·ªùi k·ª≥ tr∆∞·ªõc, sau c√≥ li√™n quan c·ªßa c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "V·ª• T√†i ch√≠nh s·∫Ω l√† ƒë·∫ßu m·ªëi th√¥ng tin cho c√°c ƒë∆°n v·ªã thu·ªôc B·ªô v√† c√°c ƒë∆°n v·ªã c√≥ li√™n quan.\n",
      "Th·ªùi gian ki·ªÉm to√°n s·∫Ω b·∫Øt ƒë·∫ßu t·ª´ ng√†y 09/7 v√† k·∫øt th√∫c v√†o ng√†y 10/9/2013.\n",
      "[Generated] ### Prompt:\n",
      "system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n h·ªØu √≠ch. H√£y cung c·∫•p b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn v√† ch√≠nh x√°c cho b√†i vi·∫øt sau.\n",
      "user\n",
      "H√£y t√≥m t·∫Øt b√†i vi·∫øt sau:\n",
      "ÔªøB·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë Quy·∫øt ƒë·ªãnh ki·ªÉm to√°n \n",
      "Ng√†y 09/7/2013 VƒÉn ph√≤ng B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá (KH&CN) ƒë√£ t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë Quy·∫øt ƒë·ªãnh ki·ªÉm to√°n. Tham d·ª± H·ªôi ngh·ªã c√≥ Th·ª© tr∆∞·ªüng B·ªô KH&CN Tr·∫ßn Vi·ªát Thanh, V·ª• tr∆∞·ªüng V·ª• T√†i ch√≠nh Nguy·ªÖn Ng·ªçc Song v√† ƒë·∫°i di·ªán l√£nh ƒë·∫°o c√°c ƒë∆°n v·ªã thu·ªôc B·ªô c√≥ li√™n quan.\n",
      "V·ªÅ ph√≠a ƒêo√†n Ki·ªÉm to√°n nh√† n∆∞·ªõc c√≥ Ph√≥ T·ªïng Ki·ªÉm to√°n nh√† n∆∞·ªõc V≈© VƒÉn H·ªça, Ph√≥ Ki·ªÉm to√°n tr∆∞·ªüng Ki·ªÉm to√°n nh√† n∆∞·ªõc chuy√™n ngh√†nh III Tr·∫ßn Ng·ªçc Qu√Ω (Tr∆∞·ªüng ƒëo√†n) v√† c√°c th√†nh vi√™n trong ƒêo√†n.\n",
      "Ph√°t bi·ªÉu t·∫°i H·ªôi ngh·ªã, √¥ng Tr·∫ßn Ng·ªçc Qu√Ω cho bi·∫øt, m·ª•c ti√™u ki·ªÉm to√°n nh·∫±m x√°c ƒë·ªãnh t√≠nh ƒë√∫ng ƒë·∫Øn, trung th·ª±c h·ª£p l√Ω c·ªßa B√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN; ƒë√°nh gi√° t√≠nh kinh t·∫ø, hi·ªáu l·ª±c v√† hi·ªáu qu·∫£ trong qu·∫£n l√Ω, s·ª≠ d·ª•ng ng√¢n s√°ch, ti·ªÅn, t√†i s·∫£n nh√† n∆∞·ªõc t·∫°i c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n, trong ƒë√≥ ƒëi s√¢u v√†o ƒë√°nh gi√° vi·ªác tri·ªÉn khai th·ª±c hi·ªán c√°c Ngh·ªã quy·∫øt c·ªßa Qu·ªëc h·ªôi, Ch√≠nh ph·ªß v·ªÅ ph√°t tri·ªÉn kinh t·∫ø - x√£ h·ªôi v√† c√°c gi·∫£i ph√°p ch·ªß y·∫øu t·∫≠p trung ki·ªÅm ch·∫ø l·∫°m ph√°t, ·ªïn ƒë·ªãnh kinh t·∫ø vƒ© m√¥, b·∫£o ƒë·∫£m an sinh x√£ h·ªôi; x√°c ƒë·ªãnh r√µ tr√°ch nhi·ªám c·ªßa t·∫≠p th·ªÉ v√† c√° nh√¢n, ki·∫øn ngh·ªã x·ª≠ l√Ω vi ph·∫°m theo quy ƒë·ªãnh c·ªßa ph√°p lu·∫≠t.\n",
      "Ngo√†i ra, n·ªôi dung ki·ªÉm to√°n c≈©ng t·∫≠p trung v√†o vi·ªác l·∫≠p, ph√¢n b·ªï, qu·∫£n l√Ω v√† s·ª≠ d·ª•ng c√°c kho·∫£n thu, chi ng√¢n s√°ch, ti·ªÅn v√† t√†i s·∫£n nh√† n∆∞·ªõc; vi·ªác mua s·∫Øm, qu·∫£n l√Ω, s·ª≠ d·ª•ng t√†i s·∫£n; vi·ªác ch·∫•p h√†nh ph√°p lu·∫≠t, ch√≠nh s√°ch, ch·∫ø ƒë·ªô qu·∫£n l√Ω t√†i ch√≠nh ‚Äì k·∫ø to√°n, ch·∫ø ƒë·ªô qu·∫£n l√Ω ƒë·∫ßu t∆∞ c·ªßa nh√† n∆∞·ªõc; vi·ªác huy ƒë·ªông ngu·ªìn v·ªën, x√©t ch·ªçn, ph√™ duy·ªát, h·ª£p ƒë·ªìng nghi√™n c·ª©u khoa h·ªçc, nghi·ªám thu, c√¥ng nh·∫≠n k·∫øt qu·∫£ nghi√™n c·ª©u, quy·∫øt to√°n kinh ph√≠ th·ª±c hi·ªán ƒë·ªÅ t√†i ƒë∆∞·ª£c Qu·ªπ ph√°t tri·ªÉn KH&CN t√†i tr·ª£ theo quy ƒë·ªãnh. Ph·∫°m vi ki·ªÉm to√°n l√† b√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN, b√°o c√°o quy·∫øt to√°n nƒÉm 2011, 2012 c·ªßa Qu·ªπ ph√°t tri·ªÉn KH&CN v√† c√°c th·ªùi k·ª≥ tr∆∞·ªõc, sau c√≥ li√™n quan c·ªßa c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "Thay m·∫∑t Ki·ªÉm to√°n nh√† n∆∞·ªõc, Ph√≥ T·ªïng Ki·ªÉm to√°n V≈© VƒÉn H·ªça ƒë√°nh gi√° cao s·ª± h·ª£p t√°c c·ªßa B·ªô KH&CN trong th·ªùi gian qua v√† mong mu·ªën ti·∫øp t·ª•c nh·∫≠n ƒë∆∞·ª£c s·ª± ph·ªëi h·ª£p ch·∫∑t ch·∫Ω h∆°n n·ªØa t·ª´ ph√≠a ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n trong vi·ªác ph·∫£n ·∫£nh t√¨nh h√¨nh th·ª±c t·∫ø, r√† so√°t c√°c c∆° ch·∫ø ch√≠nh s√°ch, c∆° ch·∫ø t·ª± ch·ªß t√†i ch√≠nh, nh·ªØng b·∫•t c·∫≠p trong c√°c c∆° ch·∫ø hi·ªán nay,‚Ä¶ Qua ƒë√≥, c√°c b√™n s·∫Ω c√πng ƒë∆∞a ra c√°c gi·∫£i ph√°p t·ªët nh·∫•t ƒë·ªÉ th√°o g·ª° nh·ªØng kh√≥ khƒÉn, v∆∞·ªõng m·∫Øc trong qu√° tr√¨nh tri·ªÉn khai ki·ªÉm to√°n ng√¢n s√°ch, ti·ªÅn v√† t√†i s·∫£n nh√† n∆∞·ªõc nƒÉm 2012 c·ªßa B·ªô KH&CN v√† c√¥ng t√°c qu·∫£n l√Ω, s·ª≠ d·ª•ng Qu·ªπ ph√°t tri·ªÉn KH&CN qu·ªëc gia giai ƒëo·∫°n 2011 - 2012.\n",
      "T·∫°i H·ªôi ngh·ªã, Th·ª© tr∆∞·ªüng Tr·∫ßn Vi·ªát Thanh ƒë√£ th√¥ng b√°o m·ªôt s·ªë th√†nh t·ª±u quan tr·ªçng trong nƒÉm 2012 c·ªßa B·ªô KH&CN t·ªõi c√°c ƒë·∫°i bi·ªÉu tham d·ª± nh∆∞: Vi·ªác ban h√†nh Chi·∫øn l∆∞·ª£c ph√°t tri·ªÉn KH&CN t·ª´ nƒÉm 2011 - 2020 c·ªßa Th·ªß t∆∞·ªõng Ch√≠nh ph·ªß; Ngh·ªã quy·∫øt s·ªë 20-NQ/TW v·ªÅ ph√°t tri·ªÉn KH&CN; Lu·∫≠t KH&CN (s·ª≠a ƒë·ªïi) ƒë√£ ƒë∆∞·ª£c Qu·ªëc h·ªôi th√¥ng qua v√† s·∫Ω c√≥ hi·ªáu l·ª±c v√†o ng√†y 01/01/2014,‚Ä¶ Th·ª© tr∆∞·ªüngÔªø B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá ƒë√£ t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë Quy·∫øt ƒë·ªãnh ki·ªÉm to√°n.\n",
      "M·ª•c ti√™u ki·ªÉm to√°n nh·∫±m x√°c ƒë·ªãnh t√≠nh ƒë√∫ng ƒë·∫Øn, trung th·ª±c h·ª£p l√Ω c·ªßa B√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN; ƒë√°nh gi√° t√≠nh kinh t·∫ø, hi·ªáu l·ª±c v√† hi·ªáu qu·∫£ trong qu·∫£n l√Ω, s·ª≠ d·ª•ng ng√¢n s√°ch, ti·ªÅn, t√†i s·∫£n nh√† n∆∞·ªõc t·∫°i c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "Ph·∫°m vi ki·ªÉm to√°n l√† b√°o c√°o quy·∫øt to√°n ng√¢n s√°ch nƒÉm 2012 c·ªßa B·ªô KH&CN, b√°o c√°o quy·∫øt to√°n nƒÉm 2011, 2012 c·ªßa Qu·ªπ ph√°t tri·ªÉn KH&CN v√† c√°c th·ªùi k·ª≥ tr∆∞·ªõc, sau c√≥ li√™n quan c·ªßa c√°c ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n.\n",
      "V·ª• T√†i ch√≠nh s·∫Ω l√† ƒë·∫ßu m·ªëi th√¥ng tin cho c√°c ƒë∆°n v·ªã thu·ªôc B·ªô v√† c√°c ƒë∆°n v·ªã c√≥ li√™n quan.\n",
      "Th·ªùi gian ki·ªÉm to√°n s·∫Ω b·∫Øt ƒë·∫ßu t·ª´ ng√†y 09/7 v√† k·∫øt th√∫c v√†o ng√†y 10/9/2013. Thay m·∫∑t Ki·ªÉm to√°n nh√† n∆∞·ªõc, Ph√≥ T·ªïng Ki·ªÉm to√°n V≈© VƒÉn H·ªça ƒë√°nh gi√° cao s·ª± h·ª£p t√°c c·ªßa B·ªô KH&CN trong th·ªùi gian qua v√† mong mu·ªën ti·∫øp t·ª•c nh·∫≠n ƒë∆∞·ª£c s·ª± ph·ªëi h·ª£p ch·∫∑t ch·∫Ω h∆°n n·ªØa t·ª´ ph√≠a ƒë∆°n v·ªã ƒë∆∞·ª£c ki·ªÉm to√°n trong vi·ªác ph·∫£n ·∫£nh t√¨nh h√¨nh th·ª±c t·∫ø, r√† so√°t c√°c c∆° ch·∫ø ch√≠nh s√°ch, c∆° ch·∫ø t·ª± ch·ªß t√†i ch√≠nh, nh·ªØng b·∫•t c·∫≠p trong c√°c c∆° ch·∫ø hi·ªán nay,‚Ä¶ Qua ƒë√≥, c√°c b√™n s·∫Ω c√πng ƒë∆∞a ra c√°c gi·∫£i ph√°p t·ªët nh·∫•t ƒë·ªÉ th√°o g·ª° nh·ªØng kh√≥ khƒÉn, v∆∞·ªõng m·∫Øc trong qu√° tr√¨nh tri·ªÉn khai ki·ªÉm to√°n ng√¢n s√°ch, ti·ªÅn v√† t√†i\n"
     ]
    }
   ],
   "source": [
    "evaluate_after_training(model, val_loader, tokenizer, device)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6959873,
     "sourceId": 11155081,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
