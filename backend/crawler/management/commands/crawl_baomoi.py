from django.core.management.base import BaseCommand
from crawler.crawlers.baomoi.tasks import crawl_baomoi_articles
import logging

logger = logging.getLogger(__name__)


class Command(BaseCommand):
    help = "Crawl news articles from BaoMoi and save to the database"

    def add_arguments(self, parser):
        parser.add_argument(
            '--limit',
            type=int,
            default=50,
            help='Number of articles to crawl (default: 50)'
        )
        parser.add_argument(
            '--verbose',
            action='store_true',
            help='Hiá»ƒn thá»‹ chi tiáº¿t quÃ¡ trÃ¬nh crawl'
        )

    def handle(self, *args, **options):
        limit = options['limit']
        verbose = options['verbose']
        
        # Thay Ä‘á»•i level logging náº¿u verbose=True
        if verbose:
            logging.getLogger('news').setLevel(logging.INFO)
            
        logger.info(f"ğŸ•µï¸â€â™‚ï¸ Äang báº¯t Ä‘áº§u crawl {limit} bÃ i viáº¿t tá»« BÃ¡o Má»›i...")
        try:
            count, urls_processed = crawl_baomoi_articles(limit=limit)
            logger.info(f"ÄÃ£ xá»­ lÃ½ tá»•ng cá»™ng {len(urls_processed)} URL")
            
            if verbose and urls_processed:
                self.stdout.write("\n--- URLs Ä‘Ã£ xá»­ lÃ½ ---")
                for idx, url_info in enumerate(urls_processed, 1):
                    status = "âœ…" if url_info.get("success") else "âŒ"
                    reason = f" - {url_info.get('reason', '')}" if not url_info.get("success") else ""
                    self.stdout.write(f"{idx}. {status} {url_info.get('url')}{reason}")
                self.stdout.write("---------------------\n")
                
            self.stdout.write(self.style.SUCCESS(f"âœ… ÄÃ£ lÆ°u thÃªm {count} bÃ i viáº¿t tá»« BÃ¡o Má»›i."))
        except Exception as e:
            logger.error(f"âŒ Crawl tháº¥t báº¡i: {e}")
            self.stderr.write(self.style.ERROR(f"Lá»—i: {e}"))
